{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "529f5590-609a-4554-9254-e22e8a4822ad",
   "metadata": {
    "papermill": {
     "duration": 0.006888,
     "end_time": "2025-09-03T21:55:12.133407",
     "exception": false,
     "start_time": "2025-09-03T21:55:12.126519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Why Parquet?\n",
    "\n",
    "This notebook explores the benefits or drawbacks of using the [parquet](https://parquet.apache.org/docs/) file format relative to other formats such as CSV or SQLite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ac8b5f-d7b1-43aa-9589-19890914f646",
   "metadata": {
    "papermill": {
     "duration": 1.269103,
     "end_time": "2025-09-03T21:55:13.408073",
     "exception": false,
     "start_time": "2025-09-03T21:55:12.138970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import string\n",
    "import warnings\n",
    "from typing import Literal\n",
    "\n",
    "import anndata as ad\n",
    "import duckdb\n",
    "import hdf5plugin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from anndata import ImplicitModificationWarning\n",
    "from IPython.display import Image\n",
    "from utilities import get_system_info, timer\n",
    "\n",
    "# ignore anndata warnings about index conversion\n",
    "warnings.filterwarnings(\"ignore\", category=ImplicitModificationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5af2f06c-3317-4e88-9a3a-64860879f60f",
   "metadata": {
    "papermill": {
     "duration": 0.015148,
     "end_time": "2025-09-03T21:55:13.429168",
     "exception": false,
     "start_time": "2025-09-03T21:55:13.414020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System Information:\n",
      "Operating System: Darwin\n",
      "Machine Type: arm64\n",
      "Processor: arm\n",
      "CPU Cores (Logical): 12\n",
      "CPU Cores (Physical): 12\n",
      "Total RAM (GB): 48.0\n",
      "Python Version: 3.12.2\n"
     ]
    }
   ],
   "source": [
    "# show the system information\n",
    "_ = get_system_info(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d7ac6d-3ffa-4a57-99ba-a0214c4e2753",
   "metadata": {
    "papermill": {
     "duration": 0.049587,
     "end_time": "2025-09-03T21:55:13.484421",
     "exception": false,
     "start_time": "2025-09-03T21:55:13.434834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# target file or table names\n",
    "image_dir = \"images\"\n",
    "csv_name = \"example.csv.gz\"\n",
    "parquet_noc_name = \"example.parquet\"\n",
    "parquet_snappy_name = \"example.snappy.parquet\"\n",
    "parquet_gzip_name = \"example.gzip.parquet\"\n",
    "parquet_lz4_name = \"example.lz4.parquet\"\n",
    "parquet_zstd_name = \"example.zstd.parquet\"\n",
    "sqlite_name = \"example.sqlite\"\n",
    "sqlite_tbl_name = \"tbl_example\"\n",
    "anndata_h5_noc_name = \"adata.noc.h5ad\"\n",
    "anndata_h5_gzip_name = \"adata.gzip.h5ad\"\n",
    "anndata_h5_lz4_name = \"adata.lz4.h5ad\"\n",
    "anndata_h5_zstd_name = \"adata.zstd.h5ad\"\n",
    "anndata_zarr_name = \"adata.zarr\"\n",
    "file_write_time_image = f\"{image_dir}/parquet-comparisons-file-write-time.png\"\n",
    "file_storage_size_image = f\"{image_dir}/parquet-comparisons-file-storage-size.png\"\n",
    "file_read_time_all_image = (\n",
    "    f\"{image_dir}/parquet-comparisons-file-read-time-all-columns.png\"\n",
    ")\n",
    "file_read_time_one_image = (\n",
    "    f\"{image_dir}/parquet-comparisons-file-read-time-one-column.png\"\n",
    ")\n",
    "\n",
    "\n",
    "def remove_files():\n",
    "    \"\"\"\n",
    "    Utility function to remove files as needed.\n",
    "    \"\"\"\n",
    "    for name in [\n",
    "        csv_name,\n",
    "        parquet_noc_name,\n",
    "        parquet_snappy_name,\n",
    "        parquet_gzip_name,\n",
    "        parquet_lz4_name,\n",
    "        parquet_zstd_name,\n",
    "        sqlite_name,\n",
    "        anndata_h5_noc_name,\n",
    "        anndata_h5_gzip_name,\n",
    "        anndata_h5_lz4_name,\n",
    "        anndata_h5_zstd_name,\n",
    "    ]:\n",
    "        pathlib.Path(name).unlink(missing_ok=True)\n",
    "\n",
    "    if pathlib.Path(anndata_zarr_name).is_dir():\n",
    "        shutil.rmtree(anndata_zarr_name)\n",
    "\n",
    "\n",
    "# remove all files just in case\n",
    "remove_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92ab9dfb-9b64-4e8f-9f6c-6251e800c7e4",
   "metadata": {
    "papermill": {
     "duration": 0.017819,
     "end_time": "2025-09-03T21:55:13.509355",
     "exception": false,
     "start_time": "2025-09-03T21:55:13.491536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_anndata(\n",
    "    df: pd.DataFrame,\n",
    "    write_to: Literal[\"h5ad\", \"zarr\"],\n",
    "    compression: Literal[\"gzip\", \"lz4\", \"zstd\", \"none\"],\n",
    "    dest_path: str,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Serialize a DataFrame to AnnData (h5ad or zarr).\n",
    "\n",
    "    Numeric columns are stored in ``X`` (observations Ã— variables). All\n",
    "    remaining columns are stored in ``.obs``. Variable (feature) names are taken\n",
    "    from the numeric column labels, and observation names from the DataFrame\n",
    "    index.\n",
    "\n",
    "    Args:\n",
    "        df:\n",
    "            Input table with rows as observations and columns as features.\n",
    "        write_to:\n",
    "            Output format. Either ``\"h5ad\"`` or ``\"zarr\"``.\n",
    "        compression:\n",
    "            The type of compression to use with\n",
    "        dest_path:\n",
    "            Destination file (``.h5ad``) or directory (zarr store)\n",
    "            to write to. Parent directories are created if missing.\n",
    "\n",
    "    Returns:\n",
    "        The path written to as a string.\n",
    "    \"\"\"\n",
    "    dest = pathlib.Path(dest_path)\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    numeric = df.select_dtypes(include=[\"number\"])\n",
    "    if numeric.shape[1] == 0:\n",
    "        raise ValueError(\"No numeric columns found to place in AnnData.X.\")\n",
    "\n",
    "    non_numeric = df.select_dtypes(exclude=[\"number\"])\n",
    "\n",
    "    adata = ad.AnnData(X=numeric)\n",
    "    adata.obs_names = df.index.astype(str)\n",
    "    adata.var_names = numeric.columns.astype(str)\n",
    "    # Align non-numeric obs metadata to the same index\n",
    "    adata.obs = non_numeric\n",
    "\n",
    "    if write_to == \"h5ad\":\n",
    "        # we default to use None for compression\n",
    "        # meaning no compression.\n",
    "        comp_arg = None\n",
    "        if compression == \"gzip\":\n",
    "            comp_arg = \"gzip\"\n",
    "        elif compression == \"zstd\":\n",
    "            comp_arg = hdf5plugin.FILTERS[\"zstd\"]\n",
    "        elif compression == \"lz4\":\n",
    "            comp_arg = hdf5plugin.FILTERS[\"lz4\"]\n",
    "\n",
    "        adata.write_h5ad(filename=str(dest), compression=comp_arg)\n",
    "    elif write_to == \"zarr\":\n",
    "        # For zarr, the destination is a directory-like store\n",
    "        adata.write_zarr(str(dest))\n",
    "    else:\n",
    "        raise ValueError('write_to must be \"h5ad\" or \"zarr\".')\n",
    "\n",
    "    return str(dest)\n",
    "\n",
    "\n",
    "def read_anndata(\n",
    "    path: str,\n",
    "    read_from: Literal[\"h5ad\", \"zarr\"],\n",
    "    read_one: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load an AnnData file (h5ad or zarr) as a single pandas DataFrame.\n",
    "\n",
    "    The returned DataFrame concatenates ``.obs`` (non-numeric metadata) with\n",
    "    ``X`` converted to a DataFrame using the variable names.\n",
    "\n",
    "    Args:\n",
    "        path:\n",
    "            Str path to the AnnData object. For zarr, this is a directory-like\n",
    "            store; for h5ad, a file path.\n",
    "        read_from:\n",
    "            Input format. Either ``\"h5ad\"`` or ``\"zarr\"``.\n",
    "        read_one:\n",
    "            Whether to read just one column.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame with ``.obs`` columns followed by the numeric\n",
    "        columns from ``X`` (``adata.to_df()``), indexed from 0..n-1.\n",
    "    \"\"\"\n",
    "\n",
    "    if read_from == \"h5ad\":\n",
    "        adata = ad.read_h5ad(path)\n",
    "    elif read_from == \"zarr\":\n",
    "        adata = ad.read_zarr(path)\n",
    "    else:\n",
    "        raise ValueError('read_from must be \"h5ad\" or \"zarr\".')\n",
    "\n",
    "    if read_one:\n",
    "        return adata.to_df()[\"col_2\"]\n",
    "\n",
    "    return adata.obs.join(adata.to_df(), how=\"left\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03f507b9-fe30-45cf-a439-41778124fe00",
   "metadata": {
    "papermill": {
     "duration": 0.242991,
     "end_time": "2025-09-03T21:55:13.758506",
     "exception": false,
     "start_time": "2025-09-03T21:55:13.515515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.823277</td>\n",
       "      <td>0.919434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022275</td>\n",
       "      <td>0.443438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      col_0     col_1\n",
       "0  0.823277  0.919434\n",
       "1  0.022275  0.443438"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# avoid a \"cold start\" for tested packages by using them before benchmarks\n",
    "df = pd.DataFrame(np.random.rand(2, 2), columns=[f\"col_{num}\" for num in range(0, 2)])\n",
    "# export and read using various methods\n",
    "df.to_csv(path_or_buf=csv_name, compression=\"gzip\")\n",
    "pd.read_csv(filepath_or_buffer=csv_name, compression=\"gzip\")\n",
    "df.to_sql(name=sqlite_tbl_name, con=f\"sqlite:///{sqlite_name}\")\n",
    "pd.read_sql(sql=f\"SELECT * FROM {sqlite_tbl_name}\", con=f\"sqlite:///{sqlite_name}\")\n",
    "df.to_parquet(path=parquet_gzip_name, compression=\"gzip\")\n",
    "pd.read_parquet(path=parquet_gzip_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2bada16-8022-4125-8083-c937e76d914b",
   "metadata": {
    "papermill": {
     "duration": 0.013525,
     "end_time": "2025-09-03T21:55:13.778550",
     "exception": false,
     "start_time": "2025-09-03T21:55:13.765025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove any existing prior work\n",
    "for filename in [csv_name, parquet_gzip_name, sqlite_name]:\n",
    "    pathlib.Path(filename).unlink(missing_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f9eefe2-8379-490c-9977-807b781eb168",
   "metadata": {
    "papermill": {
     "duration": 126.463193,
     "end_time": "2025-09-03T21:57:20.248198",
     "exception": false,
     "start_time": "2025-09-03T21:55:13.785005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 258)\n",
      "(1280, 506)\n",
      "(2560, 1002)\n",
      "(5120, 1994)\n",
      "(10240, 3978)\n",
      "(20480, 7946)\n",
      "(40960, 15882)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     37\u001b[39m         remove_files()\n\u001b[32m     38\u001b[39m         \u001b[38;5;66;03m# append data to the result list\u001b[39;00m\n\u001b[32m     39\u001b[39m         results.append(\n\u001b[32m     40\u001b[39m             {\n\u001b[32m     41\u001b[39m                 \u001b[38;5;66;03m# general information about the dataframe\u001b[39;00m\n\u001b[32m     42\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mdataframe_shape (rows, cols)\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(df.shape),\n\u001b[32m     43\u001b[39m                 \u001b[38;5;66;03m# information about CSV (uncompressed)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mcsv_write_time (secs)\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mtimer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcsv_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgzip\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     46\u001b[39m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     47\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mcsv_size (bytes)\u001b[39m\u001b[33m\"\u001b[39m: os.stat(csv_name).st_size,\n\u001b[32m     48\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mcsv_read_time_all (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m     49\u001b[39m                     pd.read_csv, filepath_or_buffer=csv_name, compression=\u001b[33m\"\u001b[39m\u001b[33mgzip\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     50\u001b[39m                 ),\n\u001b[32m     51\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mcsv_read_time_one (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m     52\u001b[39m                     pd.read_csv,\n\u001b[32m     53\u001b[39m                     filepath_or_buffer=csv_name,\n\u001b[32m     54\u001b[39m                     compression=\u001b[33m\"\u001b[39m\u001b[33mgzip\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     55\u001b[39m                     usecols=[\u001b[33m\"\u001b[39m\u001b[33mcol_2\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     56\u001b[39m                 ),\n\u001b[32m     57\u001b[39m                 \u001b[38;5;66;03m# information about SQLite\u001b[39;00m\n\u001b[32m     58\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33msqlite_write_time (secs)\u001b[39m\u001b[33m\"\u001b[39m: (\n\u001b[32m     59\u001b[39m                     timer(\n\u001b[32m     60\u001b[39m                         df.to_sql,\n\u001b[32m     61\u001b[39m                         name=sqlite_tbl_name,\n\u001b[32m     62\u001b[39m                         con=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msqlite:///\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msqlite_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     63\u001b[39m                     )\n\u001b[32m     64\u001b[39m                     \u001b[38;5;28;01mif\u001b[39;00m ncols < \u001b[32m2000\u001b[39m\n\u001b[32m     65\u001b[39m                     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     66\u001b[39m                 ),\n\u001b[32m     67\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33msqlite_size (bytes)\u001b[39m\u001b[33m\"\u001b[39m: (\n\u001b[32m     68\u001b[39m                     os.stat(sqlite_name).st_size \u001b[38;5;28;01mif\u001b[39;00m ncols < \u001b[32m2000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     69\u001b[39m                 ),\n\u001b[32m     70\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33msqlite_read_time_all (secs)\u001b[39m\u001b[33m\"\u001b[39m: (\n\u001b[32m     71\u001b[39m                     timer(\n\u001b[32m     72\u001b[39m                         pd.read_sql,\n\u001b[32m     73\u001b[39m                         sql=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSELECT * FROM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msqlite_tbl_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     74\u001b[39m                         con=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msqlite:///\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msqlite_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     75\u001b[39m                     )\n\u001b[32m     76\u001b[39m                     \u001b[38;5;28;01mif\u001b[39;00m ncols < \u001b[32m2000\u001b[39m\n\u001b[32m     77\u001b[39m                     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     78\u001b[39m                 ),\n\u001b[32m     79\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33msqlite_read_time_one (secs)\u001b[39m\u001b[33m\"\u001b[39m: (\n\u001b[32m     80\u001b[39m                     timer(\n\u001b[32m     81\u001b[39m                         pd.read_sql,\n\u001b[32m     82\u001b[39m                         sql=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSELECT col_2 FROM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msqlite_tbl_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     83\u001b[39m                         con=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msqlite:///\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msqlite_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     84\u001b[39m                     )\n\u001b[32m     85\u001b[39m                     \u001b[38;5;28;01mif\u001b[39;00m ncols < \u001b[32m2000\u001b[39m\n\u001b[32m     86\u001b[39m                     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     87\u001b[39m                 ),\n\u001b[32m     88\u001b[39m                 \u001b[38;5;66;03m# information about anndata h5ad (no compression)\u001b[39;00m\n\u001b[32m     89\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33manndata_h5ad_noc_write_time (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m     90\u001b[39m                     write_anndata,\n\u001b[32m     91\u001b[39m                     df=df,\n\u001b[32m     92\u001b[39m                     write_to=\u001b[33m\"\u001b[39m\u001b[33mh5ad\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     93\u001b[39m                     compression=\u001b[33m\"\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     94\u001b[39m                     dest_path=anndata_h5_noc_name,\n\u001b[32m     95\u001b[39m                 ),\n\u001b[32m     96\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33manndata_h5ad_noc_size (bytes)\u001b[39m\u001b[33m\"\u001b[39m: os.stat(anndata_h5_noc_name).st_size,\n\u001b[32m     97\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33manndata_h5ad_noc_read_time_all (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m     98\u001b[39m                     read_anndata,\n\u001b[32m     99\u001b[39m                     path=anndata_h5_noc_name,\n\u001b[32m    100\u001b[39m                     read_from=\u001b[33m\"\u001b[39m\u001b[33mh5ad\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    101\u001b[39m                     read_one=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    102\u001b[39m                 ),\n\u001b[32m    103\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33manndata_h5ad_noc_read_time_one (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    104\u001b[39m                     read_anndata,\n\u001b[32m    105\u001b[39m                     path=anndata_h5_noc_name,\n\u001b[32m    106\u001b[39m                     read_from=\u001b[33m\"\u001b[39m\u001b[33mh5ad\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    107\u001b[39m                     read_one=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    108\u001b[39m                 ),\n\u001b[32m    109\u001b[39m                 \u001b[38;5;66;03m# information about anndata h5ad (gzip)\u001b[39;00m\n\u001b[32m    110\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33manndata_h5ad_gzip_write_time (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    111\u001b[39m                     write_anndata,\n\u001b[32m    112\u001b[39m                     df=df,\n\u001b[32m    113\u001b[39m                     write_to=\u001b[33m\"\u001b[39m\u001b[33mh5ad\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    114\u001b[39m                     compression=\u001b[33m\"\u001b[39m\u001b[33mgzip\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    115\u001b[39m                     dest_path=anndata_h5_gzip_name,\n\u001b[32m    116\u001b[39m                 ),\n\u001b[32m    117\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33manndata_h5ad_gzip_size (bytes)\u001b[39m\u001b[33m\"\u001b[39m: os.stat(anndata_h5_gzip_name).st_size,\n\u001b[32m    118\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33manndata_h5ad_gzip_read_time_all (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    119\u001b[39m                     read_anndata,\n\u001b[32m    120\u001b[39m                     path=anndata_h5_gzip_name,\n\u001b[32m    121\u001b[39m                     read_from=\u001b[33m\"\u001b[39m\u001b[33mh5ad\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    122\u001b[39m                     read_one=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    123\u001b[39m                 ),\n\u001b[32m    124\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33manndata_h5ad_gzip_read_time_one (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    125\u001b[39m                     read_anndata,\n\u001b[32m    126\u001b[39m                     path=anndata_h5_gzip_name,\n\u001b[32m    127\u001b[39m                     read_from=\u001b[33m\"\u001b[39m\u001b[33mh5ad\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    128\u001b[39m                     read_one=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    129\u001b[39m                 ),\n\u001b[32m    130\u001b[39m                 \u001b[38;5;66;03m# information about anndata h5ad (lz4)\u001b[39;00m\n\u001b[32m    131\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33manndata_h5ad_lz4_write_time (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    132\u001b[39m                     write_anndata,\n\u001b[32m    133\u001b[39m                     df=df,\n\u001b[32m    134\u001b[39m                     write_to=\u001b[33m\"\u001b[39m\u001b[33mh5ad\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    135\u001b[39m                     compression=\u001b[33m\"\u001b[39m\u001b[33mlz4\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    136\u001b[39m                     dest_path=anndata_h5_lz4_name,\n\u001b[32m    137\u001b[39m                 ),\n\u001b[32m    138\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33manndata_h5ad_lz4_size (bytes)\u001b[39m\u001b[33m\"\u001b[39m: os.stat(anndata_h5_lz4_name).st_size,\n\u001b[32m    139\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33manndata_h5ad_lz4_read_time_all (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    140\u001b[39m                     read_anndata,\n\u001b[32m    141\u001b[39m                     path=anndata_h5_lz4_name,\n\u001b[32m    142\u001b[39m                     read_from=\u001b[33m\"\u001b[39m\u001b[33mh5ad\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    143\u001b[39m                     read_one=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    144\u001b[39m                 ),\n\u001b[32m    145\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33manndata_h5ad_lz4_read_time_one (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    146\u001b[39m                     read_anndata,\n\u001b[32m    147\u001b[39m                     path=anndata_h5_lz4_name,\n\u001b[32m    148\u001b[39m                     read_from=\u001b[33m\"\u001b[39m\u001b[33mh5ad\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    149\u001b[39m                     read_one=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    150\u001b[39m                 ),\n\u001b[32m    151\u001b[39m                 \u001b[38;5;66;03m# information about anndata h5ad (zstd)\u001b[39;00m\n\u001b[32m    152\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33manndata_h5ad_zstd_write_time (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    153\u001b[39m                     write_anndata,\n\u001b[32m    154\u001b[39m                     df=df,\n\u001b[32m    155\u001b[39m                     write_to=\u001b[33m\"\u001b[39m\u001b[33mh5ad\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    156\u001b[39m                     compression=\u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    157\u001b[39m                     dest_path=anndata_h5_zstd_name,\n\u001b[32m    158\u001b[39m                 ),\n\u001b[32m    159\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33manndata_h5ad_zstd_size (bytes)\u001b[39m\u001b[33m\"\u001b[39m: os.stat(anndata_h5_zstd_name).st_size,\n\u001b[32m    160\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33manndata_h5ad_zstd_read_time_all (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    161\u001b[39m                     read_anndata,\n\u001b[32m    162\u001b[39m                     path=anndata_h5_zstd_name,\n\u001b[32m    163\u001b[39m                     read_from=\u001b[33m\"\u001b[39m\u001b[33mh5ad\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    164\u001b[39m                     read_one=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    165\u001b[39m                 ),\n\u001b[32m    166\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33manndata_h5ad_zstd_read_time_one (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    167\u001b[39m                     read_anndata,\n\u001b[32m    168\u001b[39m                     path=anndata_h5_zstd_name,\n\u001b[32m    169\u001b[39m                     read_from=\u001b[33m\"\u001b[39m\u001b[33mh5ad\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    170\u001b[39m                     read_one=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    171\u001b[39m                 ),\n\u001b[32m    172\u001b[39m                 \u001b[38;5;66;03m# information about anndata zarr\u001b[39;00m\n\u001b[32m    173\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33manndata_zarr_write_time (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    174\u001b[39m                     write_anndata,\n\u001b[32m    175\u001b[39m                     df=df,\n\u001b[32m    176\u001b[39m                     write_to=\u001b[33m\"\u001b[39m\u001b[33mzarr\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    177\u001b[39m                     compression=\u001b[33m\"\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    178\u001b[39m                     dest_path=anndata_zarr_name,\n\u001b[32m    179\u001b[39m                 ),\n\u001b[32m    180\u001b[39m                 \u001b[38;5;66;03m# note: we use a comprehension below to recurse through\u001b[39;00m\n\u001b[32m    181\u001b[39m                 \u001b[38;5;66;03m# the zarr directory for a true estimate of size.\u001b[39;00m\n\u001b[32m    182\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33manndata_zarr_size (bytes)\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28msum\u001b[39m(\n\u001b[32m    183\u001b[39m                     f.stat().st_size\n\u001b[32m    184\u001b[39m                     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m pathlib.Path(anndata_zarr_name).rglob(\u001b[33m\"\u001b[39m\u001b[33m**/*\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    185\u001b[39m                     \u001b[38;5;28;01mif\u001b[39;00m f.is_file()\n\u001b[32m    186\u001b[39m                 ),\n\u001b[32m    187\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33manndata_zarr_read_time_all (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    188\u001b[39m                     read_anndata,\n\u001b[32m    189\u001b[39m                     path=anndata_zarr_name,\n\u001b[32m    190\u001b[39m                     read_from=\u001b[33m\"\u001b[39m\u001b[33mzarr\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    191\u001b[39m                     read_one=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    192\u001b[39m                 ),\n\u001b[32m    193\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33manndata_zarr_read_time_one (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    194\u001b[39m                     read_anndata,\n\u001b[32m    195\u001b[39m                     path=anndata_zarr_name,\n\u001b[32m    196\u001b[39m                     read_from=\u001b[33m\"\u001b[39m\u001b[33mzarr\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    197\u001b[39m                     read_one=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    198\u001b[39m                 ),\n\u001b[32m    199\u001b[39m                 \u001b[38;5;66;03m# information about Parquet with no compression\u001b[39;00m\n\u001b[32m    200\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparquet_noc_write_time (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    201\u001b[39m                     df.to_parquet, path=parquet_noc_name, compression=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    202\u001b[39m                 ),\n\u001b[32m    203\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparquet_noc_size (bytes)\u001b[39m\u001b[33m\"\u001b[39m: os.stat(parquet_noc_name).st_size,\n\u001b[32m    204\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparquet_noc_read_time_all (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    205\u001b[39m                     pd.read_parquet, path=parquet_noc_name\n\u001b[32m    206\u001b[39m                 ),\n\u001b[32m    207\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparquet_noc_read_time_one (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    208\u001b[39m                     pd.read_parquet, path=parquet_noc_name, columns=[\u001b[33m\"\u001b[39m\u001b[33mcol_2\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    209\u001b[39m                 ),\n\u001b[32m    210\u001b[39m                 \u001b[38;5;66;03m# information about Parquet with snappy compression\u001b[39;00m\n\u001b[32m    211\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparquet_snappy_write_time (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    212\u001b[39m                     df.to_parquet, path=parquet_snappy_name, compression=\u001b[33m\"\u001b[39m\u001b[33msnappy\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    213\u001b[39m                 ),\n\u001b[32m    214\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparquet_snappy_size (bytes)\u001b[39m\u001b[33m\"\u001b[39m: os.stat(parquet_snappy_name).st_size,\n\u001b[32m    215\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparquet_snappy_read_time_all (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    216\u001b[39m                     pd.read_parquet, path=parquet_snappy_name\n\u001b[32m    217\u001b[39m                 ),\n\u001b[32m    218\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparquet_snappy_read_time_one (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    219\u001b[39m                     pd.read_parquet, path=parquet_snappy_name, columns=[\u001b[33m\"\u001b[39m\u001b[33mcol_2\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    220\u001b[39m                 ),\n\u001b[32m    221\u001b[39m                 \u001b[38;5;66;03m# information about Parquet with gzip compression\u001b[39;00m\n\u001b[32m    222\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparquet_gzip_write_time (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    223\u001b[39m                     df.to_parquet, path=parquet_gzip_name, compression=\u001b[33m\"\u001b[39m\u001b[33mgzip\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    224\u001b[39m                 ),\n\u001b[32m    225\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparquet_gzip_size (bytes)\u001b[39m\u001b[33m\"\u001b[39m: os.stat(parquet_gzip_name).st_size,\n\u001b[32m    226\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparquet_gzip_read_time_all (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    227\u001b[39m                     pd.read_parquet, path=parquet_gzip_name\n\u001b[32m    228\u001b[39m                 ),\n\u001b[32m    229\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparquet_gzip_read_time_one (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    230\u001b[39m                     pd.read_parquet, path=parquet_gzip_name, columns=[\u001b[33m\"\u001b[39m\u001b[33mcol_2\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    231\u001b[39m                 ),\n\u001b[32m    232\u001b[39m                 \u001b[38;5;66;03m# information about Parquet with zstd compression\u001b[39;00m\n\u001b[32m    233\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparquet_zstd_write_time (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    234\u001b[39m                     df.to_parquet, path=parquet_zstd_name, compression=\u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    235\u001b[39m                 ),\n\u001b[32m    236\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparquet_zstd_size (bytes)\u001b[39m\u001b[33m\"\u001b[39m: os.stat(parquet_zstd_name).st_size,\n\u001b[32m    237\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparquet_zstd_read_time_all (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    238\u001b[39m                     pd.read_parquet, path=parquet_zstd_name\n\u001b[32m    239\u001b[39m                 ),\n\u001b[32m    240\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparquet_zstd_read_time_one (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    241\u001b[39m                     pd.read_parquet, path=parquet_zstd_name, columns=[\u001b[33m\"\u001b[39m\u001b[33mcol_2\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    242\u001b[39m                 ),\n\u001b[32m    243\u001b[39m                 \u001b[38;5;66;03m# information about Parquet with lz4 compression\u001b[39;00m\n\u001b[32m    244\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparquet_lz4_write_time (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    245\u001b[39m                     df.to_parquet, path=parquet_lz4_name, compression=\u001b[33m\"\u001b[39m\u001b[33mlz4\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    246\u001b[39m                 ),\n\u001b[32m    247\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparquet_lz4_size (bytes)\u001b[39m\u001b[33m\"\u001b[39m: os.stat(parquet_lz4_name).st_size,\n\u001b[32m    248\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparquet_lz4_read_time_all (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    249\u001b[39m                     pd.read_parquet, path=parquet_lz4_name\n\u001b[32m    250\u001b[39m                 ),\n\u001b[32m    251\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparquet_lz4_read_time_one (secs)\u001b[39m\u001b[33m\"\u001b[39m: timer(\n\u001b[32m    252\u001b[39m                     pd.read_parquet, path=parquet_lz4_name, columns=[\u001b[33m\"\u001b[39m\u001b[33mcol_2\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    253\u001b[39m                 ),\n\u001b[32m    254\u001b[39m             }\n\u001b[32m    255\u001b[39m         )\n\u001b[32m    258\u001b[39m df_results = pd.DataFrame(results)\n\u001b[32m    259\u001b[39m df_results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/work/CytoTable-benchmarks/notebooks/utilities.py:27\u001b[39m, in \u001b[36mtimer\u001b[39m\u001b[34m(func, method_chain, *args, **kwargs)\u001b[39m\n\u001b[32m     24\u001b[39m start_time = time.time()\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# run the function with given args\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# chain the result to the specified method\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method_chain \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/cytotable-benchmarks-t7y5cEfp-py3.12/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/cytotable-benchmarks-t7y5cEfp-py3.12/lib/python3.12/site-packages/pandas/core/generic.py:3967\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3956\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3958\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3959\u001b[39m     frame=df,\n\u001b[32m   3960\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3964\u001b[39m     decimal=decimal,\n\u001b[32m   3965\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3967\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3970\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3972\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3975\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3980\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3981\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3982\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3983\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3984\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/cytotable-benchmarks-t7y5cEfp-py3.12/lib/python3.12/site-packages/pandas/io/formats/format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/cytotable-benchmarks-t7y5cEfp-py3.12/lib/python3.12/site-packages/pandas/io/formats/csvs.py:270\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[32m    252\u001b[39m     \u001b[38;5;28mself\u001b[39m.filepath_or_buffer,\n\u001b[32m    253\u001b[39m     \u001b[38;5;28mself\u001b[39m.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    258\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/cytotable-benchmarks-t7y5cEfp-py3.12/lib/python3.12/site-packages/pandas/io/formats/csvs.py:275\u001b[39m, in \u001b[36mCSVFormatter._save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._need_to_save_header:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28mself\u001b[39m._save_header()\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/cytotable-benchmarks-t7y5cEfp-py3.12/lib/python3.12/site-packages/pandas/io/formats/csvs.py:313\u001b[39m, in \u001b[36mCSVFormatter._save_body\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m start_i >= end_i:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/Caches/pypoetry/virtualenvs/cytotable-benchmarks-t7y5cEfp-py3.12/lib/python3.12/site-packages/pandas/io/formats/csvs.py:324\u001b[39m, in \u001b[36mCSVFormatter._save_chunk\u001b[39m\u001b[34m(self, start_i, end_i)\u001b[39m\n\u001b[32m    321\u001b[39m data = \u001b[38;5;28mlist\u001b[39m(res._iter_column_arrays())\n\u001b[32m    323\u001b[39m ix = \u001b[38;5;28mself\u001b[39m.data_index[slicer]._get_values_for_csv(**\u001b[38;5;28mself\u001b[39m._number_format)\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m \u001b[43mlibwriters\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_csv_rows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m    \u001b[49m\u001b[43mix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mwriters.pyx:76\u001b[39m, in \u001b[36mpandas._libs.writers.write_csv_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/gzip.py:300\u001b[39m, in \u001b[36mGzipFile.write\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    298\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mwrite() on closed GzipFile object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/gzip.py:130\u001b[39m, in \u001b[36m_WriteBufferStream.write\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrite\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgzip_file\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_write_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.12/gzip.py:312\u001b[39m, in \u001b[36mGzipFile._write_raw\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    309\u001b[39m     length = data.nbytes\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m length > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m     \u001b[38;5;28mself\u001b[39m.fileobj.write(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompress\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    313\u001b[39m     \u001b[38;5;28mself\u001b[39m.size += length\n\u001b[32m    314\u001b[39m     \u001b[38;5;28mself\u001b[39m.crc = zlib.crc32(data, \u001b[38;5;28mself\u001b[39m.crc)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataframe_shape (rows, cols)</th>\n",
       "      <th>csv_write_time (secs)</th>\n",
       "      <th>csv_size (bytes)</th>\n",
       "      <th>csv_read_time_all (secs)</th>\n",
       "      <th>csv_read_time_one (secs)</th>\n",
       "      <th>sqlite_write_time (secs)</th>\n",
       "      <th>sqlite_size (bytes)</th>\n",
       "      <th>sqlite_read_time_all (secs)</th>\n",
       "      <th>sqlite_read_time_one (secs)</th>\n",
       "      <th>anndata_h5ad_write_time (secs)</th>\n",
       "      <th>anndata_h5ad_size (bytes)</th>\n",
       "      <th>anndata_h5ad_read_time_all (secs)</th>\n",
       "      <th>anndata_zarr_write_time (secs)</th>\n",
       "      <th>anndata_zarr_size (bytes)</th>\n",
       "      <th>anndata_zarr_read_time_all (secs)</th>\n",
       "      <th>parquet_write_time (secs)</th>\n",
       "      <th>parquet_size (bytes)</th>\n",
       "      <th>parquet_read_time_all (secs)</th>\n",
       "      <th>parquet_read_time_one (secs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(640, 320)</td>\n",
       "      <td>0.842291</td>\n",
       "      <td>1796776</td>\n",
       "      <td>0.051321</td>\n",
       "      <td>0.033486</td>\n",
       "      <td>0.292911</td>\n",
       "      <td>2654208</td>\n",
       "      <td>0.081895</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>0.015043</td>\n",
       "      <td>1689464</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>0.200134</td>\n",
       "      <td>1444205</td>\n",
       "      <td>0.024827</td>\n",
       "      <td>0.122654</td>\n",
       "      <td>1996960</td>\n",
       "      <td>0.040673</td>\n",
       "      <td>0.009489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(640, 320)</td>\n",
       "      <td>0.806049</td>\n",
       "      <td>1796776</td>\n",
       "      <td>0.049559</td>\n",
       "      <td>0.037302</td>\n",
       "      <td>0.281395</td>\n",
       "      <td>2654208</td>\n",
       "      <td>0.158389</td>\n",
       "      <td>0.004061</td>\n",
       "      <td>0.013186</td>\n",
       "      <td>1689464</td>\n",
       "      <td>0.008883</td>\n",
       "      <td>0.269879</td>\n",
       "      <td>1444205</td>\n",
       "      <td>0.025537</td>\n",
       "      <td>0.121052</td>\n",
       "      <td>1996960</td>\n",
       "      <td>0.040905</td>\n",
       "      <td>0.010552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(640, 320)</td>\n",
       "      <td>0.811007</td>\n",
       "      <td>1796776</td>\n",
       "      <td>0.050351</td>\n",
       "      <td>0.037784</td>\n",
       "      <td>0.289146</td>\n",
       "      <td>2654208</td>\n",
       "      <td>0.080007</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.013334</td>\n",
       "      <td>1689464</td>\n",
       "      <td>0.009278</td>\n",
       "      <td>0.224012</td>\n",
       "      <td>1444205</td>\n",
       "      <td>0.023597</td>\n",
       "      <td>0.118297</td>\n",
       "      <td>1996960</td>\n",
       "      <td>0.047455</td>\n",
       "      <td>0.008890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(640, 320)</td>\n",
       "      <td>2.815953</td>\n",
       "      <td>1796776</td>\n",
       "      <td>0.050481</td>\n",
       "      <td>0.037987</td>\n",
       "      <td>0.287124</td>\n",
       "      <td>2654208</td>\n",
       "      <td>0.078846</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>0.013307</td>\n",
       "      <td>1689464</td>\n",
       "      <td>0.008762</td>\n",
       "      <td>0.203730</td>\n",
       "      <td>1444205</td>\n",
       "      <td>0.018752</td>\n",
       "      <td>0.118394</td>\n",
       "      <td>1996960</td>\n",
       "      <td>0.046874</td>\n",
       "      <td>0.010313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1280, 640)</td>\n",
       "      <td>3.218594</td>\n",
       "      <td>7177156</td>\n",
       "      <td>0.187479</td>\n",
       "      <td>0.135454</td>\n",
       "      <td>0.975879</td>\n",
       "      <td>7909376</td>\n",
       "      <td>0.321715</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>0.023874</td>\n",
       "      <td>6648696</td>\n",
       "      <td>0.013905</td>\n",
       "      <td>0.211492</td>\n",
       "      <td>5752196</td>\n",
       "      <td>0.032643</td>\n",
       "      <td>0.310097</td>\n",
       "      <td>7686116</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>0.021087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1280, 640)</td>\n",
       "      <td>3.231007</td>\n",
       "      <td>7177156</td>\n",
       "      <td>0.171248</td>\n",
       "      <td>0.117120</td>\n",
       "      <td>1.004868</td>\n",
       "      <td>7909376</td>\n",
       "      <td>0.387579</td>\n",
       "      <td>0.005156</td>\n",
       "      <td>0.024271</td>\n",
       "      <td>6648696</td>\n",
       "      <td>0.019610</td>\n",
       "      <td>0.219477</td>\n",
       "      <td>5752196</td>\n",
       "      <td>0.036041</td>\n",
       "      <td>0.321031</td>\n",
       "      <td>7686116</td>\n",
       "      <td>0.073183</td>\n",
       "      <td>0.016686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(1280, 640)</td>\n",
       "      <td>3.278998</td>\n",
       "      <td>7177156</td>\n",
       "      <td>0.185984</td>\n",
       "      <td>0.137208</td>\n",
       "      <td>0.992581</td>\n",
       "      <td>7909376</td>\n",
       "      <td>0.315881</td>\n",
       "      <td>0.005491</td>\n",
       "      <td>0.024930</td>\n",
       "      <td>6648696</td>\n",
       "      <td>0.014585</td>\n",
       "      <td>0.232451</td>\n",
       "      <td>5752196</td>\n",
       "      <td>0.044017</td>\n",
       "      <td>0.423086</td>\n",
       "      <td>7686116</td>\n",
       "      <td>0.075099</td>\n",
       "      <td>0.021984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1280, 640)</td>\n",
       "      <td>3.257791</td>\n",
       "      <td>7177156</td>\n",
       "      <td>0.183664</td>\n",
       "      <td>0.134662</td>\n",
       "      <td>0.929014</td>\n",
       "      <td>7909376</td>\n",
       "      <td>0.317495</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.023940</td>\n",
       "      <td>6648696</td>\n",
       "      <td>0.014066</td>\n",
       "      <td>0.263685</td>\n",
       "      <td>5752196</td>\n",
       "      <td>0.039005</td>\n",
       "      <td>0.326676</td>\n",
       "      <td>7686116</td>\n",
       "      <td>0.080990</td>\n",
       "      <td>0.025437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(2560, 1280)</td>\n",
       "      <td>12.867960</td>\n",
       "      <td>28692830</td>\n",
       "      <td>0.687113</td>\n",
       "      <td>0.422292</td>\n",
       "      <td>5.484956</td>\n",
       "      <td>31543296</td>\n",
       "      <td>1.218488</td>\n",
       "      <td>0.010993</td>\n",
       "      <td>0.073147</td>\n",
       "      <td>26389368</td>\n",
       "      <td>0.036874</td>\n",
       "      <td>0.314813</td>\n",
       "      <td>22974236</td>\n",
       "      <td>0.110739</td>\n",
       "      <td>1.242740</td>\n",
       "      <td>30261412</td>\n",
       "      <td>0.175512</td>\n",
       "      <td>0.029622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2560, 1280)</td>\n",
       "      <td>13.161694</td>\n",
       "      <td>28692830</td>\n",
       "      <td>2.615864</td>\n",
       "      <td>0.437876</td>\n",
       "      <td>3.852527</td>\n",
       "      <td>31543296</td>\n",
       "      <td>1.231781</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>0.074586</td>\n",
       "      <td>26389368</td>\n",
       "      <td>0.037749</td>\n",
       "      <td>0.331743</td>\n",
       "      <td>22974236</td>\n",
       "      <td>0.085215</td>\n",
       "      <td>1.134063</td>\n",
       "      <td>30261412</td>\n",
       "      <td>0.166437</td>\n",
       "      <td>0.029078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(2560, 1280)</td>\n",
       "      <td>12.913457</td>\n",
       "      <td>28692830</td>\n",
       "      <td>0.645691</td>\n",
       "      <td>0.413389</td>\n",
       "      <td>3.688710</td>\n",
       "      <td>31543296</td>\n",
       "      <td>1.238714</td>\n",
       "      <td>0.011256</td>\n",
       "      <td>0.073416</td>\n",
       "      <td>26389368</td>\n",
       "      <td>0.036288</td>\n",
       "      <td>0.249354</td>\n",
       "      <td>22974236</td>\n",
       "      <td>0.069744</td>\n",
       "      <td>1.256516</td>\n",
       "      <td>30261412</td>\n",
       "      <td>0.159020</td>\n",
       "      <td>0.031087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(2560, 1280)</td>\n",
       "      <td>14.904914</td>\n",
       "      <td>28692830</td>\n",
       "      <td>0.680170</td>\n",
       "      <td>0.431732</td>\n",
       "      <td>3.525048</td>\n",
       "      <td>31543296</td>\n",
       "      <td>1.344094</td>\n",
       "      <td>0.012983</td>\n",
       "      <td>0.971748</td>\n",
       "      <td>26389368</td>\n",
       "      <td>2.071073</td>\n",
       "      <td>0.266843</td>\n",
       "      <td>22974236</td>\n",
       "      <td>1.205168</td>\n",
       "      <td>1.111896</td>\n",
       "      <td>30261412</td>\n",
       "      <td>0.123399</td>\n",
       "      <td>0.040086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataframe_shape (rows, cols)  csv_write_time (secs)  csv_size (bytes)  \\\n",
       "0                    (640, 320)               0.842291           1796776   \n",
       "1                    (640, 320)               0.806049           1796776   \n",
       "2                    (640, 320)               0.811007           1796776   \n",
       "3                    (640, 320)               2.815953           1796776   \n",
       "4                   (1280, 640)               3.218594           7177156   \n",
       "5                   (1280, 640)               3.231007           7177156   \n",
       "6                   (1280, 640)               3.278998           7177156   \n",
       "7                   (1280, 640)               3.257791           7177156   \n",
       "8                  (2560, 1280)              12.867960          28692830   \n",
       "9                  (2560, 1280)              13.161694          28692830   \n",
       "10                 (2560, 1280)              12.913457          28692830   \n",
       "11                 (2560, 1280)              14.904914          28692830   \n",
       "\n",
       "    csv_read_time_all (secs)  csv_read_time_one (secs)  \\\n",
       "0                   0.051321                  0.033486   \n",
       "1                   0.049559                  0.037302   \n",
       "2                   0.050351                  0.037784   \n",
       "3                   0.050481                  0.037987   \n",
       "4                   0.187479                  0.135454   \n",
       "5                   0.171248                  0.117120   \n",
       "6                   0.185984                  0.137208   \n",
       "7                   0.183664                  0.134662   \n",
       "8                   0.687113                  0.422292   \n",
       "9                   2.615864                  0.437876   \n",
       "10                  0.645691                  0.413389   \n",
       "11                  0.680170                  0.431732   \n",
       "\n",
       "    sqlite_write_time (secs)  sqlite_size (bytes)  \\\n",
       "0                   0.292911              2654208   \n",
       "1                   0.281395              2654208   \n",
       "2                   0.289146              2654208   \n",
       "3                   0.287124              2654208   \n",
       "4                   0.975879              7909376   \n",
       "5                   1.004868              7909376   \n",
       "6                   0.992581              7909376   \n",
       "7                   0.929014              7909376   \n",
       "8                   5.484956             31543296   \n",
       "9                   3.852527             31543296   \n",
       "10                  3.688710             31543296   \n",
       "11                  3.525048             31543296   \n",
       "\n",
       "    sqlite_read_time_all (secs)  sqlite_read_time_one (secs)  \\\n",
       "0                      0.081895                     0.004012   \n",
       "1                      0.158389                     0.004061   \n",
       "2                      0.080007                     0.004056   \n",
       "3                      0.078846                     0.004096   \n",
       "4                      0.321715                     0.005191   \n",
       "5                      0.387579                     0.005156   \n",
       "6                      0.315881                     0.005491   \n",
       "7                      0.317495                     0.005261   \n",
       "8                      1.218488                     0.010993   \n",
       "9                      1.231781                     0.011333   \n",
       "10                     1.238714                     0.011256   \n",
       "11                     1.344094                     0.012983   \n",
       "\n",
       "    anndata_h5ad_write_time (secs)  anndata_h5ad_size (bytes)  \\\n",
       "0                         0.015043                    1689464   \n",
       "1                         0.013186                    1689464   \n",
       "2                         0.013334                    1689464   \n",
       "3                         0.013307                    1689464   \n",
       "4                         0.023874                    6648696   \n",
       "5                         0.024271                    6648696   \n",
       "6                         0.024930                    6648696   \n",
       "7                         0.023940                    6648696   \n",
       "8                         0.073147                   26389368   \n",
       "9                         0.074586                   26389368   \n",
       "10                        0.073416                   26389368   \n",
       "11                        0.971748                   26389368   \n",
       "\n",
       "    anndata_h5ad_read_time_all (secs)  anndata_zarr_write_time (secs)  \\\n",
       "0                            0.009666                        0.200134   \n",
       "1                            0.008883                        0.269879   \n",
       "2                            0.009278                        0.224012   \n",
       "3                            0.008762                        0.203730   \n",
       "4                            0.013905                        0.211492   \n",
       "5                            0.019610                        0.219477   \n",
       "6                            0.014585                        0.232451   \n",
       "7                            0.014066                        0.263685   \n",
       "8                            0.036874                        0.314813   \n",
       "9                            0.037749                        0.331743   \n",
       "10                           0.036288                        0.249354   \n",
       "11                           2.071073                        0.266843   \n",
       "\n",
       "    anndata_zarr_size (bytes)  anndata_zarr_read_time_all (secs)  \\\n",
       "0                     1444205                           0.024827   \n",
       "1                     1444205                           0.025537   \n",
       "2                     1444205                           0.023597   \n",
       "3                     1444205                           0.018752   \n",
       "4                     5752196                           0.032643   \n",
       "5                     5752196                           0.036041   \n",
       "6                     5752196                           0.044017   \n",
       "7                     5752196                           0.039005   \n",
       "8                    22974236                           0.110739   \n",
       "9                    22974236                           0.085215   \n",
       "10                   22974236                           0.069744   \n",
       "11                   22974236                           1.205168   \n",
       "\n",
       "    parquet_write_time (secs)  parquet_size (bytes)  \\\n",
       "0                    0.122654               1996960   \n",
       "1                    0.121052               1996960   \n",
       "2                    0.118297               1996960   \n",
       "3                    0.118394               1996960   \n",
       "4                    0.310097               7686116   \n",
       "5                    0.321031               7686116   \n",
       "6                    0.423086               7686116   \n",
       "7                    0.326676               7686116   \n",
       "8                    1.242740              30261412   \n",
       "9                    1.134063              30261412   \n",
       "10                   1.256516              30261412   \n",
       "11                   1.111896              30261412   \n",
       "\n",
       "    parquet_read_time_all (secs)  parquet_read_time_one (secs)  \n",
       "0                       0.040673                      0.009489  \n",
       "1                       0.040905                      0.010552  \n",
       "2                       0.047455                      0.008890  \n",
       "3                       0.046874                      0.010313  \n",
       "4                       0.082800                      0.021087  \n",
       "5                       0.073183                      0.016686  \n",
       "6                       0.075099                      0.021984  \n",
       "7                       0.080990                      0.025437  \n",
       "8                       0.175512                      0.029622  \n",
       "9                       0.166437                      0.029078  \n",
       "10                      0.159020                      0.031087  \n",
       "11                      0.123399                      0.040086  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# starting rowcount and col count\n",
    "nrows = 320\n",
    "ncols = 124\n",
    "\n",
    "# result list for storing data\n",
    "results = []\n",
    "\n",
    "# loop for iterating over increasingly large dataframes\n",
    "# and gathering data about operations on them\n",
    "for _ in range(1, 8):\n",
    "    # increase the size of the dataframe\n",
    "    nrows *= 2\n",
    "    ncols *= 2\n",
    "\n",
    "    # form a dataframe using randomized data\n",
    "    df = pd.DataFrame(\n",
    "        np.random.rand(nrows, ncols), columns=[f\"col_{num}\" for num in range(0, ncols)]\n",
    "    )\n",
    "\n",
    "    # add some string data\n",
    "    alphabet = np.array(list(string.ascii_lowercase + string.digits))\n",
    "    df = df.assign(\n",
    "        **{\n",
    "            f\"str_{i+1}\": [\n",
    "                \"\".join(np.random.default_rng(10).choice(alphabet, 10))\n",
    "                for _ in range(len(df))\n",
    "            ]\n",
    "            for i in range(10)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(df.shape)\n",
    "\n",
    "    # run multiple times for error and average\n",
    "    for _ in range(1, 5):\n",
    "        # remove any existing files in preparation for next steps\n",
    "        remove_files()\n",
    "        # append data to the result list\n",
    "        results.append(\n",
    "            {\n",
    "                # general information about the dataframe\n",
    "                \"dataframe_shape (rows, cols)\": str(df.shape),\n",
    "                # information about CSV (uncompressed)\n",
    "                \"csv_write_time (secs)\": timer(\n",
    "                    df.to_csv, path_or_buf=csv_name, compression=\"gzip\"\n",
    "                ),\n",
    "                \"csv_size (bytes)\": os.stat(csv_name).st_size,\n",
    "                \"csv_read_time_all (secs)\": timer(\n",
    "                    pd.read_csv, filepath_or_buffer=csv_name, compression=\"gzip\"\n",
    "                ),\n",
    "                \"csv_read_time_one (secs)\": timer(\n",
    "                    pd.read_csv,\n",
    "                    filepath_or_buffer=csv_name,\n",
    "                    compression=\"gzip\",\n",
    "                    usecols=[\"col_2\"],\n",
    "                ),\n",
    "                # information about SQLite\n",
    "                \"sqlite_write_time (secs)\": (\n",
    "                    timer(\n",
    "                        df.to_sql,\n",
    "                        name=sqlite_tbl_name,\n",
    "                        con=f\"sqlite:///{sqlite_name}\",\n",
    "                    )\n",
    "                    if ncols < 2000\n",
    "                    else None\n",
    "                ),\n",
    "                \"sqlite_size (bytes)\": (\n",
    "                    os.stat(sqlite_name).st_size if ncols < 2000 else None\n",
    "                ),\n",
    "                \"sqlite_read_time_all (secs)\": (\n",
    "                    timer(\n",
    "                        pd.read_sql,\n",
    "                        sql=f\"SELECT * FROM {sqlite_tbl_name}\",\n",
    "                        con=f\"sqlite:///{sqlite_name}\",\n",
    "                    )\n",
    "                    if ncols < 2000\n",
    "                    else None\n",
    "                ),\n",
    "                \"sqlite_read_time_one (secs)\": (\n",
    "                    timer(\n",
    "                        pd.read_sql,\n",
    "                        sql=f\"SELECT col_2 FROM {sqlite_tbl_name}\",\n",
    "                        con=f\"sqlite:///{sqlite_name}\",\n",
    "                    )\n",
    "                    if ncols < 2000\n",
    "                    else None\n",
    "                ),\n",
    "                # information about anndata h5ad (no compression)\n",
    "                \"anndata_h5ad_noc_write_time (secs)\": timer(\n",
    "                    write_anndata,\n",
    "                    df=df,\n",
    "                    write_to=\"h5ad\",\n",
    "                    compression=\"none\",\n",
    "                    dest_path=anndata_h5_noc_name,\n",
    "                ),\n",
    "                \"anndata_h5ad_noc_size (bytes)\": os.stat(anndata_h5_noc_name).st_size,\n",
    "                \"anndata_h5ad_noc_read_time_all (secs)\": timer(\n",
    "                    read_anndata,\n",
    "                    path=anndata_h5_noc_name,\n",
    "                    read_from=\"h5ad\",\n",
    "                    read_one=False,\n",
    "                ),\n",
    "                \"anndata_h5ad_noc_read_time_one (secs)\": timer(\n",
    "                    read_anndata,\n",
    "                    path=anndata_h5_noc_name,\n",
    "                    read_from=\"h5ad\",\n",
    "                    read_one=True,\n",
    "                ),\n",
    "                # information about anndata h5ad (gzip)\n",
    "                \"anndata_h5ad_gzip_write_time (secs)\": timer(\n",
    "                    write_anndata,\n",
    "                    df=df,\n",
    "                    write_to=\"h5ad\",\n",
    "                    compression=\"gzip\",\n",
    "                    dest_path=anndata_h5_gzip_name,\n",
    "                ),\n",
    "                \"anndata_h5ad_gzip_size (bytes)\": os.stat(anndata_h5_gzip_name).st_size,\n",
    "                \"anndata_h5ad_gzip_read_time_all (secs)\": timer(\n",
    "                    read_anndata,\n",
    "                    path=anndata_h5_gzip_name,\n",
    "                    read_from=\"h5ad\",\n",
    "                    read_one=False,\n",
    "                ),\n",
    "                \"anndata_h5ad_gzip_read_time_one (secs)\": timer(\n",
    "                    read_anndata,\n",
    "                    path=anndata_h5_gzip_name,\n",
    "                    read_from=\"h5ad\",\n",
    "                    read_one=True,\n",
    "                ),\n",
    "                # information about anndata h5ad (lz4)\n",
    "                \"anndata_h5ad_lz4_write_time (secs)\": timer(\n",
    "                    write_anndata,\n",
    "                    df=df,\n",
    "                    write_to=\"h5ad\",\n",
    "                    compression=\"lz4\",\n",
    "                    dest_path=anndata_h5_lz4_name,\n",
    "                ),\n",
    "                \"anndata_h5ad_lz4_size (bytes)\": os.stat(anndata_h5_lz4_name).st_size,\n",
    "                \"anndata_h5ad_lz4_read_time_all (secs)\": timer(\n",
    "                    read_anndata,\n",
    "                    path=anndata_h5_lz4_name,\n",
    "                    read_from=\"h5ad\",\n",
    "                    read_one=False,\n",
    "                ),\n",
    "                \"anndata_h5ad_lz4_read_time_one (secs)\": timer(\n",
    "                    read_anndata,\n",
    "                    path=anndata_h5_lz4_name,\n",
    "                    read_from=\"h5ad\",\n",
    "                    read_one=True,\n",
    "                ),\n",
    "                # information about anndata h5ad (zstd)\n",
    "                \"anndata_h5ad_zstd_write_time (secs)\": timer(\n",
    "                    write_anndata,\n",
    "                    df=df,\n",
    "                    write_to=\"h5ad\",\n",
    "                    compression=\"zstd\",\n",
    "                    dest_path=anndata_h5_zstd_name,\n",
    "                ),\n",
    "                \"anndata_h5ad_zstd_size (bytes)\": os.stat(anndata_h5_zstd_name).st_size,\n",
    "                \"anndata_h5ad_zstd_read_time_all (secs)\": timer(\n",
    "                    read_anndata,\n",
    "                    path=anndata_h5_zstd_name,\n",
    "                    read_from=\"h5ad\",\n",
    "                    read_one=False,\n",
    "                ),\n",
    "                \"anndata_h5ad_zstd_read_time_one (secs)\": timer(\n",
    "                    read_anndata,\n",
    "                    path=anndata_h5_zstd_name,\n",
    "                    read_from=\"h5ad\",\n",
    "                    read_one=True,\n",
    "                ),\n",
    "                # information about anndata zarr\n",
    "                \"anndata_zarr_write_time (secs)\": timer(\n",
    "                    write_anndata,\n",
    "                    df=df,\n",
    "                    write_to=\"zarr\",\n",
    "                    compression=\"none\",\n",
    "                    dest_path=anndata_zarr_name,\n",
    "                ),\n",
    "                # note: we use a comprehension below to recurse through\n",
    "                # the zarr directory for a true estimate of size.\n",
    "                \"anndata_zarr_size (bytes)\": sum(\n",
    "                    f.stat().st_size\n",
    "                    for f in pathlib.Path(anndata_zarr_name).rglob(\"**/*\")\n",
    "                    if f.is_file()\n",
    "                ),\n",
    "                \"anndata_zarr_read_time_all (secs)\": timer(\n",
    "                    read_anndata,\n",
    "                    path=anndata_zarr_name,\n",
    "                    read_from=\"zarr\",\n",
    "                    read_one=False,\n",
    "                ),\n",
    "                \"anndata_zarr_read_time_one (secs)\": timer(\n",
    "                    read_anndata,\n",
    "                    path=anndata_zarr_name,\n",
    "                    read_from=\"zarr\",\n",
    "                    read_one=True,\n",
    "                ),\n",
    "                # information about Parquet with no compression\n",
    "                \"parquet_noc_write_time (secs)\": timer(\n",
    "                    df.to_parquet, path=parquet_noc_name, compression=None\n",
    "                ),\n",
    "                \"parquet_noc_size (bytes)\": os.stat(parquet_noc_name).st_size,\n",
    "                \"parquet_noc_read_time_all (secs)\": timer(\n",
    "                    pd.read_parquet, path=parquet_noc_name\n",
    "                ),\n",
    "                \"parquet_noc_read_time_one (secs)\": timer(\n",
    "                    pd.read_parquet, path=parquet_noc_name, columns=[\"col_2\"]\n",
    "                ),\n",
    "                # information about Parquet with snappy compression\n",
    "                \"parquet_snappy_write_time (secs)\": timer(\n",
    "                    df.to_parquet, path=parquet_snappy_name, compression=\"snappy\"\n",
    "                ),\n",
    "                \"parquet_snappy_size (bytes)\": os.stat(parquet_snappy_name).st_size,\n",
    "                \"parquet_snappy_read_time_all (secs)\": timer(\n",
    "                    pd.read_parquet, path=parquet_snappy_name\n",
    "                ),\n",
    "                \"parquet_snappy_read_time_one (secs)\": timer(\n",
    "                    pd.read_parquet, path=parquet_snappy_name, columns=[\"col_2\"]\n",
    "                ),\n",
    "                # information about Parquet with gzip compression\n",
    "                \"parquet_gzip_write_time (secs)\": timer(\n",
    "                    df.to_parquet, path=parquet_gzip_name, compression=\"gzip\"\n",
    "                ),\n",
    "                \"parquet_gzip_size (bytes)\": os.stat(parquet_gzip_name).st_size,\n",
    "                \"parquet_gzip_read_time_all (secs)\": timer(\n",
    "                    pd.read_parquet, path=parquet_gzip_name\n",
    "                ),\n",
    "                \"parquet_gzip_read_time_one (secs)\": timer(\n",
    "                    pd.read_parquet, path=parquet_gzip_name, columns=[\"col_2\"]\n",
    "                ),\n",
    "                # information about Parquet with zstd compression\n",
    "                \"parquet_zstd_write_time (secs)\": timer(\n",
    "                    df.to_parquet, path=parquet_zstd_name, compression=\"zstd\"\n",
    "                ),\n",
    "                \"parquet_zstd_size (bytes)\": os.stat(parquet_zstd_name).st_size,\n",
    "                \"parquet_zstd_read_time_all (secs)\": timer(\n",
    "                    pd.read_parquet, path=parquet_zstd_name\n",
    "                ),\n",
    "                \"parquet_zstd_read_time_one (secs)\": timer(\n",
    "                    pd.read_parquet, path=parquet_zstd_name, columns=[\"col_2\"]\n",
    "                ),\n",
    "                # information about Parquet with lz4 compression\n",
    "                \"parquet_lz4_write_time (secs)\": timer(\n",
    "                    df.to_parquet, path=parquet_lz4_name, compression=\"lz4\"\n",
    "                ),\n",
    "                \"parquet_lz4_size (bytes)\": os.stat(parquet_lz4_name).st_size,\n",
    "                \"parquet_lz4_read_time_all (secs)\": timer(\n",
    "                    pd.read_parquet, path=parquet_lz4_name\n",
    "                ),\n",
    "                \"parquet_lz4_read_time_one (secs)\": timer(\n",
    "                    pd.read_parquet, path=parquet_lz4_name, columns=[\"col_2\"]\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7f3b73-33ce-48e0-a726-caff51c0552a",
   "metadata": {
    "papermill": {
     "duration": 0.048407,
     "end_time": "2025-09-03T21:57:20.305775",
     "exception": false,
     "start_time": "2025-09-03T21:57:20.257368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "average = (\n",
    "    df_results.groupby(\"dataframe_shape (rows, cols)\")\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .sort_values(by=\"csv_size (bytes)\")\n",
    ")\n",
    "minimums = (\n",
    "    df_results.groupby(\"dataframe_shape (rows, cols)\")\n",
    "    .min()\n",
    "    .reset_index()\n",
    "    .sort_values(by=\"csv_size (bytes)\")\n",
    ")\n",
    "maximums = (\n",
    "    df_results.groupby(\"dataframe_shape (rows, cols)\")\n",
    "    .max()\n",
    "    .reset_index()\n",
    "    .sort_values(by=\"csv_size (bytes)\")\n",
    ")\n",
    "\n",
    "key = \"dataframe_shape (rows, cols)\"\n",
    "\n",
    "result = (\n",
    "    average.set_index(key)\n",
    "    .add_suffix(\" mean\")\n",
    "    .join(minimums.set_index(key).add_suffix(\" min\"))\n",
    "    .join(maximums.set_index(key).add_suffix(\" max\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b205495-4c5f-4811-a7f3-0dfe4d933b14",
   "metadata": {
    "papermill": {
     "duration": 1.365292,
     "end_time": "2025-09-03T21:57:21.680374",
     "exception": false,
     "start_time": "2025-09-03T21:57:20.315082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "key = \"dataframe_shape (rows, cols)\"\n",
    "\n",
    "cols = {\n",
    "    \"CSV (GZIP)\": (\n",
    "        \"csv_write_time (secs) mean\",\n",
    "        \"csv_write_time (secs) min\",\n",
    "        \"csv_write_time (secs) max\",\n",
    "    ),\n",
    "    \"SQLite\": (\n",
    "        \"sqlite_write_time (secs) mean\",\n",
    "        \"sqlite_write_time (secs) min\",\n",
    "        \"sqlite_write_time (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - uncompressed)\": (\n",
    "        \"anndata_h5ad_noc_write_time (secs) mean\",\n",
    "        \"anndata_h5ad_noc_write_time (secs) min\",\n",
    "        \"anndata_h5ad_noc_write_time (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - GZIP)\": (\n",
    "        \"anndata_h5ad_gzip_write_time (secs) mean\",\n",
    "        \"anndata_h5ad_gzip_write_time (secs) min\",\n",
    "        \"anndata_h5ad_gzip_write_time (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - ZSTD)\": (\n",
    "        \"anndata_h5ad_zstd_write_time (secs) mean\",\n",
    "        \"anndata_h5ad_zstd_write_time (secs) min\",\n",
    "        \"anndata_h5ad_zstd_write_time (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - LZ4) (\": (\n",
    "        \"anndata_h5ad_lz4_write_time (secs) mean\",\n",
    "        \"anndata_h5ad_lz4_write_time (secs) min\",\n",
    "        \"anndata_h5ad_lz4_write_time (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (Zarr)\": (\n",
    "        \"anndata_zarr_write_time (secs) mean\",\n",
    "        \"anndata_zarr_write_time (secs) min\",\n",
    "        \"anndata_zarr_write_time (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (uncompressed)\": (\n",
    "        \"parquet_noc_write_time (secs) mean\",\n",
    "        \"parquet_noc_write_time (secs) min\",\n",
    "        \"parquet_noc_write_time (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (Snappy)\": (\n",
    "        \"parquet_snappy_write_time (secs) mean\",\n",
    "        \"parquet_snappy_write_time (secs) min\",\n",
    "        \"parquet_snappy_write_time (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (GZIP)\": (\n",
    "        \"parquet_gzip_write_time (secs) mean\",\n",
    "        \"parquet_gzip_write_time (secs) min\",\n",
    "        \"parquet_gzip_write_time (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (ZSTD)\": (\n",
    "        \"parquet_zstd_write_time (secs) mean\",\n",
    "        \"parquet_zstd_write_time (secs) min\",\n",
    "        \"parquet_zstd_write_time (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (LZ4)\": (\n",
    "        \"parquet_lz4_write_time (secs) mean\",\n",
    "        \"parquet_lz4_write_time (secs) min\",\n",
    "        \"parquet_lz4_write_time (secs) max\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "parts = []\n",
    "for fmt, (mcol, mincol, maxcol) in cols.items():\n",
    "    tmp = result[[key, mcol, mincol, maxcol]].copy()\n",
    "    tmp[\"format\"] = fmt\n",
    "    tmp.rename(columns={mcol: \"mean\", mincol: \"min\", maxcol: \"max\"}, inplace=True)\n",
    "    tmp[\"err_plus\"] = tmp[\"max\"] - tmp[\"mean\"]\n",
    "    tmp[\"err_minus\"] = tmp[\"mean\"] - tmp[\"min\"]\n",
    "    parts.append(tmp[[key, \"format\", \"mean\", \"err_plus\", \"err_minus\"]])\n",
    "\n",
    "\n",
    "stats = pd.concat(parts, ignore_index=True)\n",
    "\n",
    "x_order = result[key].tolist()  # not reversed; use iloc[::-1] to reverse\n",
    "pos = {k: i for i, k in enumerate(x_order)}  # category â†’ position index\n",
    "\n",
    "# 2) give each row its x position and sort per-trace\n",
    "stats = stats.assign(xpos=stats[key].map(pos)).sort_values([\"format\", \"xpos\"])\n",
    "\n",
    "fig = px.line(\n",
    "    stats,  # already trace-sorted by xpos\n",
    "    x=key,\n",
    "    y=\"mean\",\n",
    "    color=\"format\",\n",
    "    error_y=\"err_plus\",\n",
    "    error_y_minus=\"err_minus\",\n",
    "    markers=True,\n",
    "    category_orders={key: x_order},  # sets axis order & legend hover categories\n",
    "    labels={key: \"Data Shape\", \"mean\": \"Seconds (log)\"},\n",
    "    width=1300,\n",
    "    log_y=True,\n",
    ")\n",
    "fig.update_traces(mode=\"lines+markers\")\n",
    "fig.update_traces(marker_color=None, line_color=None).update_layout(\n",
    "    colorway=px.colors.qualitative.Dark24\n",
    ")\n",
    "\n",
    "\n",
    "pio.write_image(fig, file_write_time_image)\n",
    "Image(url=file_write_time_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4827e5d-b2e4-4b8c-bff8-db96e0b76949",
   "metadata": {
    "papermill": {
     "duration": 0.313924,
     "end_time": "2025-09-03T21:57:22.005171",
     "exception": false,
     "start_time": "2025-09-03T21:57:21.691247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "key = \"dataframe_shape (rows, cols)\"\n",
    "\n",
    "size_cols = {\n",
    "    \"csv_size (bytes)\": \"CSV (GZIP)\",\n",
    "    \"sqlite_size (bytes)\": \"SQLite\",\n",
    "    \"anndata_h5ad_noc_size (bytes)\": \"AnnData (H5AD - uncompressed)\",\n",
    "    \"anndata_h5ad_gzip_size (bytes)\": \"AnnData (H5AD - GZIP)\",\n",
    "    \"anndata_h5ad_lz4_size (bytes)\": \"AnnData (H5AD - LZ4)\",\n",
    "    \"anndata_h5ad_zstd_size (bytes)\": \"AnnData (H5AD - ZSTD)\",\n",
    "    \"anndata_zarr_size (bytes)\": \"AnnData (Zarr)\",\n",
    "    \"parquet_noc_size (bytes)\": \"Parquet (uncompressed)\",\n",
    "    \"parquet_snappy_size (bytes)\": \"Parquet (Snappy)\",\n",
    "    \"parquet_gzip_size (bytes)\": \"Parquet (GZIP)\",\n",
    "    \"parquet_zstd_size (bytes)\": \"Parquet (ZSTD)\",\n",
    "    \"parquet_lz4_size (bytes)\": \"Parquet (LZ4)\",\n",
    "}\n",
    "\n",
    "# Long-form + average across repeats\n",
    "long = df_results.melt(\n",
    "    id_vars=[key],\n",
    "    value_vars=list(size_cols.keys()),\n",
    "    var_name=\"col\",\n",
    "    value_name=\"bytes\",\n",
    ").dropna(subset=[\"bytes\"])\n",
    "long[\"format\"] = long[\"col\"].map(size_cols)\n",
    "\n",
    "stats = long.groupby([key, \"format\"], as_index=False)[\"bytes\"].mean()\n",
    "\n",
    "# Choose x-axis category order (keep your current result order, reversed here).\n",
    "x_order = result[key].iloc[::-1].tolist()\n",
    "\n",
    "# Ensure each trace's points follow that order (pre-sort rows)\n",
    "pos = {cat: i for i, cat in enumerate(x_order)}\n",
    "stats_sorted = stats.assign(xpos=stats[key].map(pos)).sort_values([\"format\", \"xpos\"])\n",
    "\n",
    "fig = px.line(\n",
    "    stats_sorted,\n",
    "    x=key,\n",
    "    y=\"bytes\",\n",
    "    color=\"format\",\n",
    "    markers=True,\n",
    "    category_orders={key: x_order},\n",
    "    labels={key: \"Data Shape\", \"bytes\": \"Bytes\"},\n",
    "    width=1300,\n",
    ")\n",
    "\n",
    "fig.update_traces(mode=\"lines+markers\")\n",
    "fig.update_layout(\n",
    "    legend_title_text=\"File Size\",\n",
    "    legend=dict(x=0.72, y=0.02, bgcolor=\"rgba(255,255,255,0.8)\"),\n",
    "    font=dict(size=18),\n",
    ")\n",
    "fig.update_xaxes(autorange=\"reversed\")\n",
    "fig.update_traces(marker_color=None, line_color=None).update_layout(\n",
    "    colorway=px.colors.qualitative.Dark24\n",
    ")\n",
    "\n",
    "\n",
    "pio.write_image(fig, file_storage_size_image)\n",
    "Image(url=file_storage_size_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab638a5-e6e1-47e5-a5f9-56f156a71bc7",
   "metadata": {
    "papermill": {
     "duration": 0.250629,
     "end_time": "2025-09-03T21:57:22.266295",
     "exception": false,
     "start_time": "2025-09-03T21:57:22.015666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read time barchart (all columns)\n",
    "key = \"dataframe_shape (rows, cols)\"\n",
    "\n",
    "cols = {\n",
    "    \"CSV (GZIP)\": (\n",
    "        \"csv_read_time_all (secs) mean\",\n",
    "        \"csv_read_time_all (secs) min\",\n",
    "        \"csv_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"SQLite\": (\n",
    "        \"sqlite_read_time_all (secs) mean\",\n",
    "        \"sqlite_read_time_all (secs) min\",\n",
    "        \"sqlite_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - uncompressed)\": (\n",
    "        \"anndata_h5ad_noc_read_time_all (secs) mean\",\n",
    "        \"anndata_h5ad_noc_read_time_all (secs) min\",\n",
    "        \"anndata_h5ad_noc_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - GZIP)\": (\n",
    "        \"anndata_h5ad_gzip_read_time_all (secs) mean\",\n",
    "        \"anndata_h5ad_gzip_read_time_all (secs) min\",\n",
    "        \"anndata_h5ad_gzip_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - ZSTD)\": (\n",
    "        \"anndata_h5ad_zstd_read_time_all (secs) mean\",\n",
    "        \"anndata_h5ad_zstd_read_time_all (secs) min\",\n",
    "        \"anndata_h5ad_zstd_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - LZ4) (\": (\n",
    "        \"anndata_h5ad_lz4_read_time_all (secs) mean\",\n",
    "        \"anndata_h5ad_lz4_read_time_all (secs) min\",\n",
    "        \"anndata_h5ad_lz4_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (Zarr)\": (\n",
    "        \"anndata_zarr_read_time_all (secs) mean\",\n",
    "        \"anndata_zarr_read_time_all (secs) min\",\n",
    "        \"anndata_zarr_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (uncompressed)\": (\n",
    "        \"parquet_noc_read_time_all (secs) mean\",\n",
    "        \"parquet_noc_read_time_all (secs) min\",\n",
    "        \"parquet_noc_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (Snappy)\": (\n",
    "        \"parquet_snappy_read_time_all (secs) mean\",\n",
    "        \"parquet_snappy_read_time_all (secs) min\",\n",
    "        \"parquet_snappy_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (GZIP)\": (\n",
    "        \"parquet_gzip_read_time_all (secs) mean\",\n",
    "        \"parquet_gzip_read_time_all (secs) min\",\n",
    "        \"parquet_gzip_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (ZSTD)\": (\n",
    "        \"parquet_zstd_read_time_all (secs) mean\",\n",
    "        \"parquet_zstd_read_time_all (secs) min\",\n",
    "        \"parquet_zstd_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (LZ4)\": (\n",
    "        \"parquet_lz4_read_time_all (secs) mean\",\n",
    "        \"parquet_lz4_read_time_all (secs) min\",\n",
    "        \"parquet_lz4_read_time_all (secs) max\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "parts = []\n",
    "for fmt, (mcol, mincol, maxcol) in cols.items():\n",
    "    tmp = result[[key, mcol, mincol, maxcol]].copy()\n",
    "    tmp[\"format\"] = fmt\n",
    "    tmp.rename(columns={mcol: \"mean\", mincol: \"min\", maxcol: \"max\"}, inplace=True)\n",
    "    tmp[\"err_plus\"] = tmp[\"max\"] - tmp[\"mean\"]\n",
    "    tmp[\"err_minus\"] = tmp[\"mean\"] - tmp[\"min\"]\n",
    "    parts.append(tmp[[key, \"format\", \"mean\", \"err_plus\", \"err_minus\"]])\n",
    "\n",
    "\n",
    "stats = pd.concat(parts, ignore_index=True)\n",
    "\n",
    "x_order = result[key].tolist()  # not reversed; use iloc[::-1] to reverse\n",
    "pos = {k: i for i, k in enumerate(x_order)}  # category â†’ position index\n",
    "\n",
    "# 2) give each row its x position and sort per-trace\n",
    "stats = stats.assign(xpos=stats[key].map(pos)).sort_values([\"format\", \"xpos\"])\n",
    "\n",
    "fig = px.line(\n",
    "    stats,  # already trace-sorted by xpos\n",
    "    x=key,\n",
    "    y=\"mean\",\n",
    "    color=\"format\",\n",
    "    error_y=\"err_plus\",\n",
    "    error_y_minus=\"err_minus\",\n",
    "    markers=True,\n",
    "    category_orders={key: x_order},  # sets axis order & legend hover categories\n",
    "    labels={key: \"Data Shape\", \"mean\": \"Seconds\"},\n",
    "    width=1300,\n",
    "    log_y=True,\n",
    ")\n",
    "fig.update_traces(mode=\"lines+markers\")\n",
    "fig.update_traces(marker_color=None, line_color=None).update_layout(\n",
    "    colorway=px.colors.qualitative.Dark24\n",
    ")\n",
    "\n",
    "\n",
    "pio.write_image(fig, file_read_time_all_image)\n",
    "Image(url=file_read_time_all_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd99f232-8564-4b83-82c7-e4b0cc5cfbf4",
   "metadata": {
    "papermill": {
     "duration": 0.260285,
     "end_time": "2025-09-03T21:57:22.537386",
     "exception": false,
     "start_time": "2025-09-03T21:57:22.277101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read time barchart (one column)\n",
    "\n",
    "key = \"dataframe_shape (rows, cols)\"\n",
    "\n",
    "cols = {\n",
    "    \"CSV (GZIP)\": (\n",
    "        \"csv_read_time_one (secs) mean\",\n",
    "        \"csv_read_time_one (secs) min\",\n",
    "        \"csv_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"SQLite\": (\n",
    "        \"sqlite_read_time_one (secs) mean\",\n",
    "        \"sqlite_read_time_one (secs) min\",\n",
    "        \"sqlite_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - uncompressed)\": (\n",
    "        \"anndata_h5ad_noc_read_time_one (secs) mean\",\n",
    "        \"anndata_h5ad_noc_read_time_one (secs) min\",\n",
    "        \"anndata_h5ad_noc_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - GZIP)\": (\n",
    "        \"anndata_h5ad_gzip_read_time_one (secs) mean\",\n",
    "        \"anndata_h5ad_gzip_read_time_one (secs) min\",\n",
    "        \"anndata_h5ad_gzip_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - ZSTD)\": (\n",
    "        \"anndata_h5ad_zstd_read_time_one (secs) mean\",\n",
    "        \"anndata_h5ad_zstd_read_time_one (secs) min\",\n",
    "        \"anndata_h5ad_zstd_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - LZ4) (\": (\n",
    "        \"anndata_h5ad_lz4_read_time_one (secs) mean\",\n",
    "        \"anndata_h5ad_lz4_read_time_one (secs) min\",\n",
    "        \"anndata_h5ad_lz4_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (Zarr)\": (\n",
    "        \"anndata_zarr_read_time_one (secs) mean\",\n",
    "        \"anndata_zarr_read_time_one (secs) min\",\n",
    "        \"anndata_zarr_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (uncompressed)\": (\n",
    "        \"parquet_noc_read_time_one (secs) mean\",\n",
    "        \"parquet_noc_read_time_one (secs) min\",\n",
    "        \"parquet_noc_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (Snappy)\": (\n",
    "        \"parquet_snappy_read_time_one (secs) mean\",\n",
    "        \"parquet_snappy_read_time_one (secs) min\",\n",
    "        \"parquet_snappy_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (GZIP)\": (\n",
    "        \"parquet_gzip_read_time_one (secs) mean\",\n",
    "        \"parquet_gzip_read_time_one (secs) min\",\n",
    "        \"parquet_gzip_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (ZSTD)\": (\n",
    "        \"parquet_zstd_read_time_one (secs) mean\",\n",
    "        \"parquet_zstd_read_time_one (secs) min\",\n",
    "        \"parquet_zstd_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (LZ4)\": (\n",
    "        \"parquet_lz4_read_time_one (secs) mean\",\n",
    "        \"parquet_lz4_read_time_one (secs) min\",\n",
    "        \"parquet_lz4_read_time_one (secs) max\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "parts = []\n",
    "for fmt, (mcol, mincol, maxcol) in cols.items():\n",
    "    tmp = result[[key, mcol, mincol, maxcol]].copy()\n",
    "    tmp[\"format\"] = fmt\n",
    "    tmp.rename(columns={mcol: \"mean\", mincol: \"min\", maxcol: \"max\"}, inplace=True)\n",
    "    tmp[\"err_plus\"] = tmp[\"max\"] - tmp[\"mean\"]\n",
    "    tmp[\"err_minus\"] = tmp[\"mean\"] - tmp[\"min\"]\n",
    "    parts.append(tmp[[key, \"format\", \"mean\", \"err_plus\", \"err_minus\"]])\n",
    "\n",
    "\n",
    "stats = pd.concat(parts, ignore_index=True)\n",
    "\n",
    "x_order = result[key].tolist()  # not reversed; use iloc[::-1] to reverse\n",
    "pos = {k: i for i, k in enumerate(x_order)}  # category â†’ position index\n",
    "\n",
    "# 2) give each row its x position and sort per-trace\n",
    "stats = stats.assign(xpos=stats[key].map(pos)).sort_values([\"format\", \"xpos\"])\n",
    "\n",
    "fig = px.line(\n",
    "    stats,  # already trace-sorted by xpos\n",
    "    x=key,\n",
    "    y=\"mean\",\n",
    "    color=\"format\",\n",
    "    error_y=\"err_plus\",\n",
    "    error_y_minus=\"err_minus\",\n",
    "    markers=True,\n",
    "    category_orders={key: x_order},  # sets axis order & legend hover categories\n",
    "    labels={key: \"Data Shape\", \"mean\": \"Seconds (log)\"},\n",
    "    width=1300,\n",
    "    log_y=True,\n",
    ")\n",
    "fig.update_traces(mode=\"lines+markers\")\n",
    "fig.update_traces(marker_color=None, line_color=None).update_layout(\n",
    "    colorway=px.colors.qualitative.Dark24\n",
    ")\n",
    "\n",
    "\n",
    "pio.write_image(fig, file_read_time_one_image)\n",
    "Image(url=file_read_time_one_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cc933c-aaf1-49c1-8a6a-2242680f3bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 134.268328,
   "end_time": "2025-09-03T21:57:25.270281",
   "environment_variables": {},
   "exception": null,
   "input_path": "parquet_analysis.ipynb",
   "output_path": "parquet_analysis.ipynb",
   "parameters": {},
   "start_time": "2025-09-03T21:55:11.001953",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

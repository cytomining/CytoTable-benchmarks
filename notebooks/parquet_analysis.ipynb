{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "529f5590-609a-4554-9254-e22e8a4822ad",
   "metadata": {
    "papermill": {
     "duration": 0.006888,
     "end_time": "2025-09-03T21:55:12.133407",
     "exception": false,
     "start_time": "2025-09-03T21:55:12.126519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Why Parquet?\n",
    "\n",
    "This notebook explores the benefits or drawbacks of using the [parquet](https://parquet.apache.org/docs/) file format relative to other formats such as CSV or SQLite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ac8b5f-d7b1-43aa-9589-19890914f646",
   "metadata": {
    "papermill": {
     "duration": 1.269103,
     "end_time": "2025-09-03T21:55:13.408073",
     "exception": false,
     "start_time": "2025-09-03T21:55:12.138970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import string\n",
    "import warnings\n",
    "from typing import Literal\n",
    "\n",
    "import anndata as ad\n",
    "import duckdb\n",
    "import hdf5plugin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from anndata import ImplicitModificationWarning\n",
    "from IPython.display import Image\n",
    "from utilities import get_system_info, timer\n",
    "\n",
    "# ignore anndata warnings about index conversion\n",
    "warnings.filterwarnings(\"ignore\", category=ImplicitModificationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5af2f06c-3317-4e88-9a3a-64860879f60f",
   "metadata": {
    "papermill": {
     "duration": 0.015148,
     "end_time": "2025-09-03T21:55:13.429168",
     "exception": false,
     "start_time": "2025-09-03T21:55:13.414020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System Information:\n",
      "Operating System: Darwin\n",
      "Machine Type: arm64\n",
      "Processor: arm\n",
      "CPU Cores (Logical): 12\n",
      "CPU Cores (Physical): 12\n",
      "Total RAM (GB): 48.0\n",
      "Python Version: 3.12.2\n"
     ]
    }
   ],
   "source": [
    "# show the system information\n",
    "_ = get_system_info(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d7ac6d-3ffa-4a57-99ba-a0214c4e2753",
   "metadata": {
    "papermill": {
     "duration": 0.049587,
     "end_time": "2025-09-03T21:55:13.484421",
     "exception": false,
     "start_time": "2025-09-03T21:55:13.434834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# target file or table names\n",
    "image_dir = \"images\"\n",
    "csv_name = \"example.csv.gz\"\n",
    "parquet_noc_name = \"example.parquet\"\n",
    "parquet_snappy_name = \"example.snappy.parquet\"\n",
    "parquet_gzip_name = \"example.gzip.parquet\"\n",
    "parquet_lz4_name = \"example.lz4.parquet\"\n",
    "parquet_zstd_name = \"example.zstd.parquet\"\n",
    "sqlite_name = \"example.sqlite\"\n",
    "sqlite_tbl_name = \"tbl_example\"\n",
    "anndata_h5_noc_name = \"adata.noc.h5ad\"\n",
    "anndata_h5_gzip_name = \"adata.gzip.h5ad\"\n",
    "anndata_h5_lz4_name = \"adata.lz4.h5ad\"\n",
    "anndata_h5_zstd_name = \"adata.zstd.h5ad\"\n",
    "anndata_zarr_name = \"adata.zarr\"\n",
    "file_write_time_image = f\"{image_dir}/parquet-comparisons-file-write-time.png\"\n",
    "file_storage_size_image = f\"{image_dir}/parquet-comparisons-file-storage-size.png\"\n",
    "file_read_time_all_image = (\n",
    "    f\"{image_dir}/parquet-comparisons-file-read-time-all-columns.png\"\n",
    ")\n",
    "file_read_time_one_image = (\n",
    "    f\"{image_dir}/parquet-comparisons-file-read-time-one-column.png\"\n",
    ")\n",
    "file_read_time_write_and_read_time_image = (\n",
    "    f\"{image_dir}/parquet-comparisons-file-write-and-read-time.png\"\n",
    ")\n",
    "\n",
    "\n",
    "def remove_files():\n",
    "    \"\"\"\n",
    "    Utility function to remove files as needed.\n",
    "    \"\"\"\n",
    "    for name in [\n",
    "        csv_name,\n",
    "        parquet_noc_name,\n",
    "        parquet_snappy_name,\n",
    "        parquet_gzip_name,\n",
    "        parquet_lz4_name,\n",
    "        parquet_zstd_name,\n",
    "        sqlite_name,\n",
    "        anndata_h5_noc_name,\n",
    "        anndata_h5_gzip_name,\n",
    "        anndata_h5_lz4_name,\n",
    "        anndata_h5_zstd_name,\n",
    "    ]:\n",
    "        pathlib.Path(name).unlink(missing_ok=True)\n",
    "\n",
    "    if pathlib.Path(anndata_zarr_name).is_dir():\n",
    "        shutil.rmtree(anndata_zarr_name)\n",
    "\n",
    "\n",
    "# remove all files just in case\n",
    "remove_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92ab9dfb-9b64-4e8f-9f6c-6251e800c7e4",
   "metadata": {
    "papermill": {
     "duration": 0.017819,
     "end_time": "2025-09-03T21:55:13.509355",
     "exception": false,
     "start_time": "2025-09-03T21:55:13.491536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_anndata(\n",
    "    df: pd.DataFrame,\n",
    "    write_to: Literal[\"h5ad\", \"zarr\"],\n",
    "    compression: Literal[\"gzip\", \"lz4\", \"zstd\", \"none\"],\n",
    "    dest_path: str,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Serialize a DataFrame to AnnData (h5ad or zarr).\n",
    "\n",
    "    Numeric columns are stored in ``X`` (observations Ã— variables). All\n",
    "    remaining columns are stored in ``.obs``. Variable (feature) names are taken\n",
    "    from the numeric column labels, and observation names from the DataFrame\n",
    "    index.\n",
    "\n",
    "    Args:\n",
    "        df:\n",
    "            Input table with rows as observations and columns as features.\n",
    "        write_to:\n",
    "            Output format. Either ``\"h5ad\"`` or ``\"zarr\"``.\n",
    "        compression:\n",
    "            The type of compression to use with\n",
    "        dest_path:\n",
    "            Destination file (``.h5ad``) or directory (zarr store)\n",
    "            to write to. Parent directories are created if missing.\n",
    "\n",
    "    Returns:\n",
    "        The path written to as a string.\n",
    "    \"\"\"\n",
    "    dest = pathlib.Path(dest_path)\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    numeric = df.select_dtypes(include=[\"number\"])\n",
    "    if numeric.shape[1] == 0:\n",
    "        raise ValueError(\"No numeric columns found to place in AnnData.X.\")\n",
    "\n",
    "    non_numeric = df.select_dtypes(exclude=[\"number\"])\n",
    "\n",
    "    adata = ad.AnnData(X=numeric)\n",
    "    adata.obs_names = df.index.astype(str)\n",
    "    adata.var_names = numeric.columns.astype(str)\n",
    "    # Align non-numeric obs metadata to the same index\n",
    "    adata.obs = non_numeric\n",
    "\n",
    "    if write_to == \"h5ad\":\n",
    "        # we default to use None for compression\n",
    "        # meaning no compression.\n",
    "        comp_arg = None\n",
    "        if compression == \"gzip\":\n",
    "            comp_arg = \"gzip\"\n",
    "        elif compression == \"zstd\":\n",
    "            comp_arg = hdf5plugin.FILTERS[\"zstd\"]\n",
    "        elif compression == \"lz4\":\n",
    "            comp_arg = hdf5plugin.FILTERS[\"lz4\"]\n",
    "\n",
    "        adata.write_h5ad(filename=str(dest), compression=comp_arg)\n",
    "    elif write_to == \"zarr\":\n",
    "        # For zarr, the destination is a directory-like store\n",
    "        adata.write_zarr(str(dest))\n",
    "    else:\n",
    "        raise ValueError('write_to must be \"h5ad\" or \"zarr\".')\n",
    "\n",
    "    return str(dest)\n",
    "\n",
    "\n",
    "def read_anndata(\n",
    "    path: str,\n",
    "    read_from: Literal[\"h5ad\", \"zarr\"],\n",
    "    read_one: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load an AnnData file (h5ad or zarr) as a single pandas DataFrame.\n",
    "\n",
    "    The returned DataFrame concatenates ``.obs`` (non-numeric metadata) with\n",
    "    ``X`` converted to a DataFrame using the variable names.\n",
    "\n",
    "    Args:\n",
    "        path:\n",
    "            Str path to the AnnData object. For zarr, this is a directory-like\n",
    "            store; for h5ad, a file path.\n",
    "        read_from:\n",
    "            Input format. Either ``\"h5ad\"`` or ``\"zarr\"``.\n",
    "        read_one:\n",
    "            Whether to read just one column.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame with ``.obs`` columns followed by the numeric\n",
    "        columns from ``X`` (``adata.to_df()``), indexed from 0..n-1.\n",
    "    \"\"\"\n",
    "\n",
    "    if read_from == \"h5ad\":\n",
    "        adata = ad.read_h5ad(path)\n",
    "    elif read_from == \"zarr\":\n",
    "        adata = ad.read_zarr(path)\n",
    "    else:\n",
    "        raise ValueError('read_from must be \"h5ad\" or \"zarr\".')\n",
    "\n",
    "    if read_one:\n",
    "        return adata.to_df()[\"col_2\"]\n",
    "\n",
    "    return adata.obs.join(adata.to_df(), how=\"left\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03f507b9-fe30-45cf-a439-41778124fe00",
   "metadata": {
    "papermill": {
     "duration": 0.242991,
     "end_time": "2025-09-03T21:55:13.758506",
     "exception": false,
     "start_time": "2025-09-03T21:55:13.515515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.997581</td>\n",
       "      <td>0.043064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.962047</td>\n",
       "      <td>0.675117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      col_0     col_1\n",
       "0  0.997581  0.043064\n",
       "1  0.962047  0.675117"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# avoid a \"cold start\" for tested packages by using them before benchmarks\n",
    "df = pd.DataFrame(np.random.rand(2, 2), columns=[f\"col_{num}\" for num in range(0, 2)])\n",
    "# export and read using various methods\n",
    "df.to_csv(path_or_buf=csv_name, compression=\"gzip\")\n",
    "pd.read_csv(filepath_or_buffer=csv_name, compression=\"gzip\")\n",
    "df.to_sql(name=sqlite_tbl_name, con=f\"sqlite:///{sqlite_name}\")\n",
    "pd.read_sql(sql=f\"SELECT * FROM {sqlite_tbl_name}\", con=f\"sqlite:///{sqlite_name}\")\n",
    "df.to_parquet(path=parquet_gzip_name, compression=\"gzip\")\n",
    "pd.read_parquet(path=parquet_gzip_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2bada16-8022-4125-8083-c937e76d914b",
   "metadata": {
    "papermill": {
     "duration": 0.013525,
     "end_time": "2025-09-03T21:55:13.778550",
     "exception": false,
     "start_time": "2025-09-03T21:55:13.765025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove any existing prior work\n",
    "for filename in [csv_name, parquet_gzip_name, sqlite_name]:\n",
    "    pathlib.Path(filename).unlink(missing_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f9eefe2-8379-490c-9977-807b781eb168",
   "metadata": {
    "papermill": {
     "duration": 126.463193,
     "end_time": "2025-09-03T21:57:20.248198",
     "exception": false,
     "start_time": "2025-09-03T21:55:13.785005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 258)\n",
      "(1280, 506)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataframe_shape (rows, cols)</th>\n",
       "      <th>csv_write_time (secs)</th>\n",
       "      <th>csv_size (bytes)</th>\n",
       "      <th>csv_read_time_all (secs)</th>\n",
       "      <th>csv_read_time_one (secs)</th>\n",
       "      <th>sqlite_write_time (secs)</th>\n",
       "      <th>sqlite_size (bytes)</th>\n",
       "      <th>sqlite_read_time_all (secs)</th>\n",
       "      <th>sqlite_read_time_one (secs)</th>\n",
       "      <th>anndata_h5ad_noc_write_time (secs)</th>\n",
       "      <th>...</th>\n",
       "      <th>parquet_gzip_read_time_all (secs)</th>\n",
       "      <th>parquet_gzip_read_time_one (secs)</th>\n",
       "      <th>parquet_zstd_write_time (secs)</th>\n",
       "      <th>parquet_zstd_size (bytes)</th>\n",
       "      <th>parquet_zstd_read_time_all (secs)</th>\n",
       "      <th>parquet_zstd_read_time_one (secs)</th>\n",
       "      <th>parquet_lz4_write_time (secs)</th>\n",
       "      <th>parquet_lz4_size (bytes)</th>\n",
       "      <th>parquet_lz4_read_time_all (secs)</th>\n",
       "      <th>parquet_lz4_read_time_one (secs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(640, 258)</td>\n",
       "      <td>0.349953</td>\n",
       "      <td>1396981</td>\n",
       "      <td>0.022983</td>\n",
       "      <td>0.012464</td>\n",
       "      <td>0.059292</td>\n",
       "      <td>2654208</td>\n",
       "      <td>0.019890</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.010072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013968</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.016212</td>\n",
       "      <td>1544104</td>\n",
       "      <td>0.010330</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.020523</td>\n",
       "      <td>1614678</td>\n",
       "      <td>0.010476</td>\n",
       "      <td>0.002485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(640, 258)</td>\n",
       "      <td>0.351754</td>\n",
       "      <td>1396981</td>\n",
       "      <td>0.021227</td>\n",
       "      <td>0.012075</td>\n",
       "      <td>0.084762</td>\n",
       "      <td>2654208</td>\n",
       "      <td>0.018693</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.008209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014986</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.016406</td>\n",
       "      <td>1544104</td>\n",
       "      <td>0.014450</td>\n",
       "      <td>0.002691</td>\n",
       "      <td>0.013303</td>\n",
       "      <td>1614678</td>\n",
       "      <td>0.011502</td>\n",
       "      <td>0.002360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(640, 258)</td>\n",
       "      <td>0.351233</td>\n",
       "      <td>1396981</td>\n",
       "      <td>0.023342</td>\n",
       "      <td>0.012204</td>\n",
       "      <td>0.059437</td>\n",
       "      <td>2654208</td>\n",
       "      <td>0.018680</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.007888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029883</td>\n",
       "      <td>0.002723</td>\n",
       "      <td>0.016545</td>\n",
       "      <td>1544104</td>\n",
       "      <td>0.010852</td>\n",
       "      <td>0.002484</td>\n",
       "      <td>0.014456</td>\n",
       "      <td>1614678</td>\n",
       "      <td>0.010260</td>\n",
       "      <td>0.002453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(640, 258)</td>\n",
       "      <td>0.346648</td>\n",
       "      <td>1396981</td>\n",
       "      <td>0.021386</td>\n",
       "      <td>0.011990</td>\n",
       "      <td>0.059665</td>\n",
       "      <td>2654208</td>\n",
       "      <td>0.020119</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.008608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016492</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.038157</td>\n",
       "      <td>1544104</td>\n",
       "      <td>0.012178</td>\n",
       "      <td>0.002707</td>\n",
       "      <td>0.014095</td>\n",
       "      <td>1614678</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>0.002517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1280, 506)</td>\n",
       "      <td>1.412493</td>\n",
       "      <td>5570915</td>\n",
       "      <td>0.067012</td>\n",
       "      <td>0.047149</td>\n",
       "      <td>0.230795</td>\n",
       "      <td>5935104</td>\n",
       "      <td>0.322953</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.010725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045651</td>\n",
       "      <td>0.004461</td>\n",
       "      <td>0.039083</td>\n",
       "      <td>5940796</td>\n",
       "      <td>0.023398</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>0.032480</td>\n",
       "      <td>6254016</td>\n",
       "      <td>0.019308</td>\n",
       "      <td>0.004416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1280, 506)</td>\n",
       "      <td>1.497883</td>\n",
       "      <td>5570915</td>\n",
       "      <td>0.070433</td>\n",
       "      <td>0.049668</td>\n",
       "      <td>0.241143</td>\n",
       "      <td>5935104</td>\n",
       "      <td>0.327791</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>0.010235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020539</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>0.041362</td>\n",
       "      <td>5940796</td>\n",
       "      <td>0.022216</td>\n",
       "      <td>0.005096</td>\n",
       "      <td>0.034012</td>\n",
       "      <td>6254016</td>\n",
       "      <td>0.023383</td>\n",
       "      <td>0.004539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(1280, 506)</td>\n",
       "      <td>1.426151</td>\n",
       "      <td>5570915</td>\n",
       "      <td>0.069020</td>\n",
       "      <td>0.049306</td>\n",
       "      <td>0.212177</td>\n",
       "      <td>5935104</td>\n",
       "      <td>0.325189</td>\n",
       "      <td>0.003523</td>\n",
       "      <td>0.011475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022789</td>\n",
       "      <td>0.005154</td>\n",
       "      <td>0.050196</td>\n",
       "      <td>5940796</td>\n",
       "      <td>0.023186</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.033548</td>\n",
       "      <td>6254016</td>\n",
       "      <td>0.021356</td>\n",
       "      <td>0.004486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1280, 506)</td>\n",
       "      <td>1.413185</td>\n",
       "      <td>5570915</td>\n",
       "      <td>0.068670</td>\n",
       "      <td>0.046842</td>\n",
       "      <td>0.243153</td>\n",
       "      <td>5935104</td>\n",
       "      <td>0.320029</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>0.010782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023692</td>\n",
       "      <td>0.004838</td>\n",
       "      <td>0.053404</td>\n",
       "      <td>5940796</td>\n",
       "      <td>0.019320</td>\n",
       "      <td>0.004425</td>\n",
       "      <td>0.032654</td>\n",
       "      <td>6254016</td>\n",
       "      <td>0.019063</td>\n",
       "      <td>0.004653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataframe_shape (rows, cols)  csv_write_time (secs)  csv_size (bytes)  \\\n",
       "0                   (640, 258)               0.349953           1396981   \n",
       "1                   (640, 258)               0.351754           1396981   \n",
       "2                   (640, 258)               0.351233           1396981   \n",
       "3                   (640, 258)               0.346648           1396981   \n",
       "4                  (1280, 506)               1.412493           5570915   \n",
       "5                  (1280, 506)               1.497883           5570915   \n",
       "6                  (1280, 506)               1.426151           5570915   \n",
       "7                  (1280, 506)               1.413185           5570915   \n",
       "\n",
       "   csv_read_time_all (secs)  csv_read_time_one (secs)  \\\n",
       "0                  0.022983                  0.012464   \n",
       "1                  0.021227                  0.012075   \n",
       "2                  0.023342                  0.012204   \n",
       "3                  0.021386                  0.011990   \n",
       "4                  0.067012                  0.047149   \n",
       "5                  0.070433                  0.049668   \n",
       "6                  0.069020                  0.049306   \n",
       "7                  0.068670                  0.046842   \n",
       "\n",
       "   sqlite_write_time (secs)  sqlite_size (bytes)  sqlite_read_time_all (secs)  \\\n",
       "0                  0.059292              2654208                     0.019890   \n",
       "1                  0.084762              2654208                     0.018693   \n",
       "2                  0.059437              2654208                     0.018680   \n",
       "3                  0.059665              2654208                     0.020119   \n",
       "4                  0.230795              5935104                     0.322953   \n",
       "5                  0.241143              5935104                     0.327791   \n",
       "6                  0.212177              5935104                     0.325189   \n",
       "7                  0.243153              5935104                     0.320029   \n",
       "\n",
       "   sqlite_read_time_one (secs)  anndata_h5ad_noc_write_time (secs)  ...  \\\n",
       "0                     0.001546                            0.010072  ...   \n",
       "1                     0.001738                            0.008209  ...   \n",
       "2                     0.001578                            0.007888  ...   \n",
       "3                     0.001443                            0.008608  ...   \n",
       "4                     0.003445                            0.010725  ...   \n",
       "5                     0.003308                            0.010235  ...   \n",
       "6                     0.003523                            0.011475  ...   \n",
       "7                     0.004440                            0.010782  ...   \n",
       "\n",
       "   parquet_gzip_read_time_all (secs)  parquet_gzip_read_time_one (secs)  \\\n",
       "0                           0.013968                           0.002548   \n",
       "1                           0.014986                           0.002828   \n",
       "2                           0.029883                           0.002723   \n",
       "3                           0.016492                           0.002554   \n",
       "4                           0.045651                           0.004461   \n",
       "5                           0.020539                           0.004645   \n",
       "6                           0.022789                           0.005154   \n",
       "7                           0.023692                           0.004838   \n",
       "\n",
       "   parquet_zstd_write_time (secs)  parquet_zstd_size (bytes)  \\\n",
       "0                        0.016212                    1544104   \n",
       "1                        0.016406                    1544104   \n",
       "2                        0.016545                    1544104   \n",
       "3                        0.038157                    1544104   \n",
       "4                        0.039083                    5940796   \n",
       "5                        0.041362                    5940796   \n",
       "6                        0.050196                    5940796   \n",
       "7                        0.053404                    5940796   \n",
       "\n",
       "   parquet_zstd_read_time_all (secs)  parquet_zstd_read_time_one (secs)  \\\n",
       "0                           0.010330                           0.004700   \n",
       "1                           0.014450                           0.002691   \n",
       "2                           0.010852                           0.002484   \n",
       "3                           0.012178                           0.002707   \n",
       "4                           0.023398                           0.004540   \n",
       "5                           0.022216                           0.005096   \n",
       "6                           0.023186                           0.004357   \n",
       "7                           0.019320                           0.004425   \n",
       "\n",
       "   parquet_lz4_write_time (secs)  parquet_lz4_size (bytes)  \\\n",
       "0                       0.020523                   1614678   \n",
       "1                       0.013303                   1614678   \n",
       "2                       0.014456                   1614678   \n",
       "3                       0.014095                   1614678   \n",
       "4                       0.032480                   6254016   \n",
       "5                       0.034012                   6254016   \n",
       "6                       0.033548                   6254016   \n",
       "7                       0.032654                   6254016   \n",
       "\n",
       "   parquet_lz4_read_time_all (secs)  parquet_lz4_read_time_one (secs)  \n",
       "0                          0.010476                          0.002485  \n",
       "1                          0.011502                          0.002360  \n",
       "2                          0.010260                          0.002453  \n",
       "3                          0.010190                          0.002517  \n",
       "4                          0.019308                          0.004416  \n",
       "5                          0.023383                          0.004539  \n",
       "6                          0.021356                          0.004486  \n",
       "7                          0.019063                          0.004653  \n",
       "\n",
       "[8 rows x 49 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataframe_shape (rows, cols)</th>\n",
       "      <th>csv_write_time (secs)</th>\n",
       "      <th>csv_size (bytes)</th>\n",
       "      <th>csv_read_time_all (secs)</th>\n",
       "      <th>csv_read_time_one (secs)</th>\n",
       "      <th>sqlite_write_time (secs)</th>\n",
       "      <th>sqlite_size (bytes)</th>\n",
       "      <th>sqlite_read_time_all (secs)</th>\n",
       "      <th>sqlite_read_time_one (secs)</th>\n",
       "      <th>anndata_h5ad_write_time (secs)</th>\n",
       "      <th>anndata_h5ad_size (bytes)</th>\n",
       "      <th>anndata_h5ad_read_time_all (secs)</th>\n",
       "      <th>anndata_zarr_write_time (secs)</th>\n",
       "      <th>anndata_zarr_size (bytes)</th>\n",
       "      <th>anndata_zarr_read_time_all (secs)</th>\n",
       "      <th>parquet_write_time (secs)</th>\n",
       "      <th>parquet_size (bytes)</th>\n",
       "      <th>parquet_read_time_all (secs)</th>\n",
       "      <th>parquet_read_time_one (secs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(640, 320)</td>\n",
       "      <td>0.842291</td>\n",
       "      <td>1796776</td>\n",
       "      <td>0.051321</td>\n",
       "      <td>0.033486</td>\n",
       "      <td>0.292911</td>\n",
       "      <td>2654208</td>\n",
       "      <td>0.081895</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>0.015043</td>\n",
       "      <td>1689464</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>0.200134</td>\n",
       "      <td>1444205</td>\n",
       "      <td>0.024827</td>\n",
       "      <td>0.122654</td>\n",
       "      <td>1996960</td>\n",
       "      <td>0.040673</td>\n",
       "      <td>0.009489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(640, 320)</td>\n",
       "      <td>0.806049</td>\n",
       "      <td>1796776</td>\n",
       "      <td>0.049559</td>\n",
       "      <td>0.037302</td>\n",
       "      <td>0.281395</td>\n",
       "      <td>2654208</td>\n",
       "      <td>0.158389</td>\n",
       "      <td>0.004061</td>\n",
       "      <td>0.013186</td>\n",
       "      <td>1689464</td>\n",
       "      <td>0.008883</td>\n",
       "      <td>0.269879</td>\n",
       "      <td>1444205</td>\n",
       "      <td>0.025537</td>\n",
       "      <td>0.121052</td>\n",
       "      <td>1996960</td>\n",
       "      <td>0.040905</td>\n",
       "      <td>0.010552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(640, 320)</td>\n",
       "      <td>0.811007</td>\n",
       "      <td>1796776</td>\n",
       "      <td>0.050351</td>\n",
       "      <td>0.037784</td>\n",
       "      <td>0.289146</td>\n",
       "      <td>2654208</td>\n",
       "      <td>0.080007</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.013334</td>\n",
       "      <td>1689464</td>\n",
       "      <td>0.009278</td>\n",
       "      <td>0.224012</td>\n",
       "      <td>1444205</td>\n",
       "      <td>0.023597</td>\n",
       "      <td>0.118297</td>\n",
       "      <td>1996960</td>\n",
       "      <td>0.047455</td>\n",
       "      <td>0.008890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(640, 320)</td>\n",
       "      <td>2.815953</td>\n",
       "      <td>1796776</td>\n",
       "      <td>0.050481</td>\n",
       "      <td>0.037987</td>\n",
       "      <td>0.287124</td>\n",
       "      <td>2654208</td>\n",
       "      <td>0.078846</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>0.013307</td>\n",
       "      <td>1689464</td>\n",
       "      <td>0.008762</td>\n",
       "      <td>0.203730</td>\n",
       "      <td>1444205</td>\n",
       "      <td>0.018752</td>\n",
       "      <td>0.118394</td>\n",
       "      <td>1996960</td>\n",
       "      <td>0.046874</td>\n",
       "      <td>0.010313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1280, 640)</td>\n",
       "      <td>3.218594</td>\n",
       "      <td>7177156</td>\n",
       "      <td>0.187479</td>\n",
       "      <td>0.135454</td>\n",
       "      <td>0.975879</td>\n",
       "      <td>7909376</td>\n",
       "      <td>0.321715</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>0.023874</td>\n",
       "      <td>6648696</td>\n",
       "      <td>0.013905</td>\n",
       "      <td>0.211492</td>\n",
       "      <td>5752196</td>\n",
       "      <td>0.032643</td>\n",
       "      <td>0.310097</td>\n",
       "      <td>7686116</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>0.021087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1280, 640)</td>\n",
       "      <td>3.231007</td>\n",
       "      <td>7177156</td>\n",
       "      <td>0.171248</td>\n",
       "      <td>0.117120</td>\n",
       "      <td>1.004868</td>\n",
       "      <td>7909376</td>\n",
       "      <td>0.387579</td>\n",
       "      <td>0.005156</td>\n",
       "      <td>0.024271</td>\n",
       "      <td>6648696</td>\n",
       "      <td>0.019610</td>\n",
       "      <td>0.219477</td>\n",
       "      <td>5752196</td>\n",
       "      <td>0.036041</td>\n",
       "      <td>0.321031</td>\n",
       "      <td>7686116</td>\n",
       "      <td>0.073183</td>\n",
       "      <td>0.016686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(1280, 640)</td>\n",
       "      <td>3.278998</td>\n",
       "      <td>7177156</td>\n",
       "      <td>0.185984</td>\n",
       "      <td>0.137208</td>\n",
       "      <td>0.992581</td>\n",
       "      <td>7909376</td>\n",
       "      <td>0.315881</td>\n",
       "      <td>0.005491</td>\n",
       "      <td>0.024930</td>\n",
       "      <td>6648696</td>\n",
       "      <td>0.014585</td>\n",
       "      <td>0.232451</td>\n",
       "      <td>5752196</td>\n",
       "      <td>0.044017</td>\n",
       "      <td>0.423086</td>\n",
       "      <td>7686116</td>\n",
       "      <td>0.075099</td>\n",
       "      <td>0.021984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1280, 640)</td>\n",
       "      <td>3.257791</td>\n",
       "      <td>7177156</td>\n",
       "      <td>0.183664</td>\n",
       "      <td>0.134662</td>\n",
       "      <td>0.929014</td>\n",
       "      <td>7909376</td>\n",
       "      <td>0.317495</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.023940</td>\n",
       "      <td>6648696</td>\n",
       "      <td>0.014066</td>\n",
       "      <td>0.263685</td>\n",
       "      <td>5752196</td>\n",
       "      <td>0.039005</td>\n",
       "      <td>0.326676</td>\n",
       "      <td>7686116</td>\n",
       "      <td>0.080990</td>\n",
       "      <td>0.025437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(2560, 1280)</td>\n",
       "      <td>12.867960</td>\n",
       "      <td>28692830</td>\n",
       "      <td>0.687113</td>\n",
       "      <td>0.422292</td>\n",
       "      <td>5.484956</td>\n",
       "      <td>31543296</td>\n",
       "      <td>1.218488</td>\n",
       "      <td>0.010993</td>\n",
       "      <td>0.073147</td>\n",
       "      <td>26389368</td>\n",
       "      <td>0.036874</td>\n",
       "      <td>0.314813</td>\n",
       "      <td>22974236</td>\n",
       "      <td>0.110739</td>\n",
       "      <td>1.242740</td>\n",
       "      <td>30261412</td>\n",
       "      <td>0.175512</td>\n",
       "      <td>0.029622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2560, 1280)</td>\n",
       "      <td>13.161694</td>\n",
       "      <td>28692830</td>\n",
       "      <td>2.615864</td>\n",
       "      <td>0.437876</td>\n",
       "      <td>3.852527</td>\n",
       "      <td>31543296</td>\n",
       "      <td>1.231781</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>0.074586</td>\n",
       "      <td>26389368</td>\n",
       "      <td>0.037749</td>\n",
       "      <td>0.331743</td>\n",
       "      <td>22974236</td>\n",
       "      <td>0.085215</td>\n",
       "      <td>1.134063</td>\n",
       "      <td>30261412</td>\n",
       "      <td>0.166437</td>\n",
       "      <td>0.029078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(2560, 1280)</td>\n",
       "      <td>12.913457</td>\n",
       "      <td>28692830</td>\n",
       "      <td>0.645691</td>\n",
       "      <td>0.413389</td>\n",
       "      <td>3.688710</td>\n",
       "      <td>31543296</td>\n",
       "      <td>1.238714</td>\n",
       "      <td>0.011256</td>\n",
       "      <td>0.073416</td>\n",
       "      <td>26389368</td>\n",
       "      <td>0.036288</td>\n",
       "      <td>0.249354</td>\n",
       "      <td>22974236</td>\n",
       "      <td>0.069744</td>\n",
       "      <td>1.256516</td>\n",
       "      <td>30261412</td>\n",
       "      <td>0.159020</td>\n",
       "      <td>0.031087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(2560, 1280)</td>\n",
       "      <td>14.904914</td>\n",
       "      <td>28692830</td>\n",
       "      <td>0.680170</td>\n",
       "      <td>0.431732</td>\n",
       "      <td>3.525048</td>\n",
       "      <td>31543296</td>\n",
       "      <td>1.344094</td>\n",
       "      <td>0.012983</td>\n",
       "      <td>0.971748</td>\n",
       "      <td>26389368</td>\n",
       "      <td>2.071073</td>\n",
       "      <td>0.266843</td>\n",
       "      <td>22974236</td>\n",
       "      <td>1.205168</td>\n",
       "      <td>1.111896</td>\n",
       "      <td>30261412</td>\n",
       "      <td>0.123399</td>\n",
       "      <td>0.040086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataframe_shape (rows, cols)  csv_write_time (secs)  csv_size (bytes)  \\\n",
       "0                    (640, 320)               0.842291           1796776   \n",
       "1                    (640, 320)               0.806049           1796776   \n",
       "2                    (640, 320)               0.811007           1796776   \n",
       "3                    (640, 320)               2.815953           1796776   \n",
       "4                   (1280, 640)               3.218594           7177156   \n",
       "5                   (1280, 640)               3.231007           7177156   \n",
       "6                   (1280, 640)               3.278998           7177156   \n",
       "7                   (1280, 640)               3.257791           7177156   \n",
       "8                  (2560, 1280)              12.867960          28692830   \n",
       "9                  (2560, 1280)              13.161694          28692830   \n",
       "10                 (2560, 1280)              12.913457          28692830   \n",
       "11                 (2560, 1280)              14.904914          28692830   \n",
       "\n",
       "    csv_read_time_all (secs)  csv_read_time_one (secs)  \\\n",
       "0                   0.051321                  0.033486   \n",
       "1                   0.049559                  0.037302   \n",
       "2                   0.050351                  0.037784   \n",
       "3                   0.050481                  0.037987   \n",
       "4                   0.187479                  0.135454   \n",
       "5                   0.171248                  0.117120   \n",
       "6                   0.185984                  0.137208   \n",
       "7                   0.183664                  0.134662   \n",
       "8                   0.687113                  0.422292   \n",
       "9                   2.615864                  0.437876   \n",
       "10                  0.645691                  0.413389   \n",
       "11                  0.680170                  0.431732   \n",
       "\n",
       "    sqlite_write_time (secs)  sqlite_size (bytes)  \\\n",
       "0                   0.292911              2654208   \n",
       "1                   0.281395              2654208   \n",
       "2                   0.289146              2654208   \n",
       "3                   0.287124              2654208   \n",
       "4                   0.975879              7909376   \n",
       "5                   1.004868              7909376   \n",
       "6                   0.992581              7909376   \n",
       "7                   0.929014              7909376   \n",
       "8                   5.484956             31543296   \n",
       "9                   3.852527             31543296   \n",
       "10                  3.688710             31543296   \n",
       "11                  3.525048             31543296   \n",
       "\n",
       "    sqlite_read_time_all (secs)  sqlite_read_time_one (secs)  \\\n",
       "0                      0.081895                     0.004012   \n",
       "1                      0.158389                     0.004061   \n",
       "2                      0.080007                     0.004056   \n",
       "3                      0.078846                     0.004096   \n",
       "4                      0.321715                     0.005191   \n",
       "5                      0.387579                     0.005156   \n",
       "6                      0.315881                     0.005491   \n",
       "7                      0.317495                     0.005261   \n",
       "8                      1.218488                     0.010993   \n",
       "9                      1.231781                     0.011333   \n",
       "10                     1.238714                     0.011256   \n",
       "11                     1.344094                     0.012983   \n",
       "\n",
       "    anndata_h5ad_write_time (secs)  anndata_h5ad_size (bytes)  \\\n",
       "0                         0.015043                    1689464   \n",
       "1                         0.013186                    1689464   \n",
       "2                         0.013334                    1689464   \n",
       "3                         0.013307                    1689464   \n",
       "4                         0.023874                    6648696   \n",
       "5                         0.024271                    6648696   \n",
       "6                         0.024930                    6648696   \n",
       "7                         0.023940                    6648696   \n",
       "8                         0.073147                   26389368   \n",
       "9                         0.074586                   26389368   \n",
       "10                        0.073416                   26389368   \n",
       "11                        0.971748                   26389368   \n",
       "\n",
       "    anndata_h5ad_read_time_all (secs)  anndata_zarr_write_time (secs)  \\\n",
       "0                            0.009666                        0.200134   \n",
       "1                            0.008883                        0.269879   \n",
       "2                            0.009278                        0.224012   \n",
       "3                            0.008762                        0.203730   \n",
       "4                            0.013905                        0.211492   \n",
       "5                            0.019610                        0.219477   \n",
       "6                            0.014585                        0.232451   \n",
       "7                            0.014066                        0.263685   \n",
       "8                            0.036874                        0.314813   \n",
       "9                            0.037749                        0.331743   \n",
       "10                           0.036288                        0.249354   \n",
       "11                           2.071073                        0.266843   \n",
       "\n",
       "    anndata_zarr_size (bytes)  anndata_zarr_read_time_all (secs)  \\\n",
       "0                     1444205                           0.024827   \n",
       "1                     1444205                           0.025537   \n",
       "2                     1444205                           0.023597   \n",
       "3                     1444205                           0.018752   \n",
       "4                     5752196                           0.032643   \n",
       "5                     5752196                           0.036041   \n",
       "6                     5752196                           0.044017   \n",
       "7                     5752196                           0.039005   \n",
       "8                    22974236                           0.110739   \n",
       "9                    22974236                           0.085215   \n",
       "10                   22974236                           0.069744   \n",
       "11                   22974236                           1.205168   \n",
       "\n",
       "    parquet_write_time (secs)  parquet_size (bytes)  \\\n",
       "0                    0.122654               1996960   \n",
       "1                    0.121052               1996960   \n",
       "2                    0.118297               1996960   \n",
       "3                    0.118394               1996960   \n",
       "4                    0.310097               7686116   \n",
       "5                    0.321031               7686116   \n",
       "6                    0.423086               7686116   \n",
       "7                    0.326676               7686116   \n",
       "8                    1.242740              30261412   \n",
       "9                    1.134063              30261412   \n",
       "10                   1.256516              30261412   \n",
       "11                   1.111896              30261412   \n",
       "\n",
       "    parquet_read_time_all (secs)  parquet_read_time_one (secs)  \n",
       "0                       0.040673                      0.009489  \n",
       "1                       0.040905                      0.010552  \n",
       "2                       0.047455                      0.008890  \n",
       "3                       0.046874                      0.010313  \n",
       "4                       0.082800                      0.021087  \n",
       "5                       0.073183                      0.016686  \n",
       "6                       0.075099                      0.021984  \n",
       "7                       0.080990                      0.025437  \n",
       "8                       0.175512                      0.029622  \n",
       "9                       0.166437                      0.029078  \n",
       "10                      0.159020                      0.031087  \n",
       "11                      0.123399                      0.040086  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# capture primary data metrics on file format performance\n",
    "\n",
    "# avoid a rewrite of the data if we already have it\n",
    "if not pathlib.Path(\"parquet_analysis.parquet\").is_file():\n",
    "    # starting rowcount and col count\n",
    "    nrows = 320\n",
    "    ncols = 124\n",
    "    \n",
    "    # result list for storing data\n",
    "    results = []\n",
    "    \n",
    "    # loop for iterating over increasingly large dataframes\n",
    "    # and gathering data about operations on them\n",
    "    for _ in range(1, 6):\n",
    "        # increase the size of the dataframe\n",
    "        nrows *= 2\n",
    "        ncols *= 2\n",
    "    \n",
    "        # form a dataframe using randomized data\n",
    "        df = pd.DataFrame(\n",
    "            np.random.rand(nrows, ncols), columns=[f\"col_{num}\" for num in range(0, ncols)]\n",
    "        )\n",
    "    \n",
    "        # add some string data\n",
    "        alphabet = np.array(list(string.ascii_lowercase + string.digits))\n",
    "        df = df.assign(\n",
    "            **{\n",
    "                f\"str_{i+1}\": [\n",
    "                    \"\".join(np.random.default_rng(10).choice(alphabet, 10))\n",
    "                    for _ in range(len(df))\n",
    "                ]\n",
    "                for i in range(10)\n",
    "            }\n",
    "        )\n",
    "    \n",
    "        print(df.shape)\n",
    "    \n",
    "        # run multiple times for error and average\n",
    "        for _ in range(1, 5):\n",
    "            # remove any existing files in preparation for next steps\n",
    "            remove_files()\n",
    "            # append data to the result list\n",
    "            results.append(\n",
    "                {\n",
    "                    # general information about the dataframe\n",
    "                    \"dataframe_shape (rows, cols)\": str(df.shape),\n",
    "                    # information about CSV (uncompressed)\n",
    "                    \"csv_write_time (secs)\": timer(\n",
    "                        df.to_csv, path_or_buf=csv_name, compression=\"gzip\"\n",
    "                    ),\n",
    "                    \"csv_size (bytes)\": os.stat(csv_name).st_size,\n",
    "                    \"csv_read_time_all (secs)\": timer(\n",
    "                        pd.read_csv, filepath_or_buffer=csv_name, compression=\"gzip\"\n",
    "                    ),\n",
    "                    \"csv_read_time_one (secs)\": timer(\n",
    "                        pd.read_csv,\n",
    "                        filepath_or_buffer=csv_name,\n",
    "                        compression=\"gzip\",\n",
    "                        usecols=[\"col_2\"],\n",
    "                    ),\n",
    "                    # information about SQLite\n",
    "                    \"sqlite_write_time (secs)\": (\n",
    "                        timer(\n",
    "                            df.to_sql,\n",
    "                            name=sqlite_tbl_name,\n",
    "                            con=f\"sqlite:///{sqlite_name}\",\n",
    "                        )\n",
    "                        if ncols < 2000\n",
    "                        else None\n",
    "                    ),\n",
    "                    \"sqlite_size (bytes)\": (\n",
    "                        os.stat(sqlite_name).st_size if ncols < 2000 else None\n",
    "                    ),\n",
    "                    \"sqlite_read_time_all (secs)\": (\n",
    "                        timer(\n",
    "                            pd.read_sql,\n",
    "                            sql=f\"SELECT * FROM {sqlite_tbl_name}\",\n",
    "                            con=f\"sqlite:///{sqlite_name}\",\n",
    "                        )\n",
    "                        if ncols < 2000\n",
    "                        else None\n",
    "                    ),\n",
    "                    \"sqlite_read_time_one (secs)\": (\n",
    "                        timer(\n",
    "                            pd.read_sql,\n",
    "                            sql=f\"SELECT col_2 FROM {sqlite_tbl_name}\",\n",
    "                            con=f\"sqlite:///{sqlite_name}\",\n",
    "                        )\n",
    "                        if ncols < 2000\n",
    "                        else None\n",
    "                    ),\n",
    "                    # information about anndata h5ad (no compression)\n",
    "                    \"anndata_h5ad_noc_write_time (secs)\": timer(\n",
    "                        write_anndata,\n",
    "                        df=df,\n",
    "                        write_to=\"h5ad\",\n",
    "                        compression=\"none\",\n",
    "                        dest_path=anndata_h5_noc_name,\n",
    "                    ),\n",
    "                    \"anndata_h5ad_noc_size (bytes)\": os.stat(anndata_h5_noc_name).st_size,\n",
    "                    \"anndata_h5ad_noc_read_time_all (secs)\": timer(\n",
    "                        read_anndata,\n",
    "                        path=anndata_h5_noc_name,\n",
    "                        read_from=\"h5ad\",\n",
    "                        read_one=False,\n",
    "                    ),\n",
    "                    \"anndata_h5ad_noc_read_time_one (secs)\": timer(\n",
    "                        read_anndata,\n",
    "                        path=anndata_h5_noc_name,\n",
    "                        read_from=\"h5ad\",\n",
    "                        read_one=True,\n",
    "                    ),\n",
    "                    # information about anndata h5ad (gzip)\n",
    "                    \"anndata_h5ad_gzip_write_time (secs)\": timer(\n",
    "                        write_anndata,\n",
    "                        df=df,\n",
    "                        write_to=\"h5ad\",\n",
    "                        compression=\"gzip\",\n",
    "                        dest_path=anndata_h5_gzip_name,\n",
    "                    ),\n",
    "                    \"anndata_h5ad_gzip_size (bytes)\": os.stat(anndata_h5_gzip_name).st_size,\n",
    "                    \"anndata_h5ad_gzip_read_time_all (secs)\": timer(\n",
    "                        read_anndata,\n",
    "                        path=anndata_h5_gzip_name,\n",
    "                        read_from=\"h5ad\",\n",
    "                        read_one=False,\n",
    "                    ),\n",
    "                    \"anndata_h5ad_gzip_read_time_one (secs)\": timer(\n",
    "                        read_anndata,\n",
    "                        path=anndata_h5_gzip_name,\n",
    "                        read_from=\"h5ad\",\n",
    "                        read_one=True,\n",
    "                    ),\n",
    "                    # information about anndata h5ad (lz4)\n",
    "                    \"anndata_h5ad_lz4_write_time (secs)\": timer(\n",
    "                        write_anndata,\n",
    "                        df=df,\n",
    "                        write_to=\"h5ad\",\n",
    "                        compression=\"lz4\",\n",
    "                        dest_path=anndata_h5_lz4_name,\n",
    "                    ),\n",
    "                    \"anndata_h5ad_lz4_size (bytes)\": os.stat(anndata_h5_lz4_name).st_size,\n",
    "                    \"anndata_h5ad_lz4_read_time_all (secs)\": timer(\n",
    "                        read_anndata,\n",
    "                        path=anndata_h5_lz4_name,\n",
    "                        read_from=\"h5ad\",\n",
    "                        read_one=False,\n",
    "                    ),\n",
    "                    \"anndata_h5ad_lz4_read_time_one (secs)\": timer(\n",
    "                        read_anndata,\n",
    "                        path=anndata_h5_lz4_name,\n",
    "                        read_from=\"h5ad\",\n",
    "                        read_one=True,\n",
    "                    ),\n",
    "                    # information about anndata h5ad (zstd)\n",
    "                    \"anndata_h5ad_zstd_write_time (secs)\": timer(\n",
    "                        write_anndata,\n",
    "                        df=df,\n",
    "                        write_to=\"h5ad\",\n",
    "                        compression=\"zstd\",\n",
    "                        dest_path=anndata_h5_zstd_name,\n",
    "                    ),\n",
    "                    \"anndata_h5ad_zstd_size (bytes)\": os.stat(anndata_h5_zstd_name).st_size,\n",
    "                    \"anndata_h5ad_zstd_read_time_all (secs)\": timer(\n",
    "                        read_anndata,\n",
    "                        path=anndata_h5_zstd_name,\n",
    "                        read_from=\"h5ad\",\n",
    "                        read_one=False,\n",
    "                    ),\n",
    "                    \"anndata_h5ad_zstd_read_time_one (secs)\": timer(\n",
    "                        read_anndata,\n",
    "                        path=anndata_h5_zstd_name,\n",
    "                        read_from=\"h5ad\",\n",
    "                        read_one=True,\n",
    "                    ),\n",
    "                    # information about anndata zarr\n",
    "                    \"anndata_zarr_write_time (secs)\": timer(\n",
    "                        write_anndata,\n",
    "                        df=df,\n",
    "                        write_to=\"zarr\",\n",
    "                        compression=\"none\",\n",
    "                        dest_path=anndata_zarr_name,\n",
    "                    ),\n",
    "                    # note: we use a comprehension below to recurse through\n",
    "                    # the zarr directory for a true estimate of size.\n",
    "                    \"anndata_zarr_size (bytes)\": sum(\n",
    "                        f.stat().st_size\n",
    "                        for f in pathlib.Path(anndata_zarr_name).rglob(\"**/*\")\n",
    "                        if f.is_file()\n",
    "                    ),\n",
    "                    \"anndata_zarr_read_time_all (secs)\": timer(\n",
    "                        read_anndata,\n",
    "                        path=anndata_zarr_name,\n",
    "                        read_from=\"zarr\",\n",
    "                        read_one=False,\n",
    "                    ),\n",
    "                    \"anndata_zarr_read_time_one (secs)\": timer(\n",
    "                        read_anndata,\n",
    "                        path=anndata_zarr_name,\n",
    "                        read_from=\"zarr\",\n",
    "                        read_one=True,\n",
    "                    ),\n",
    "                    # information about Parquet with no compression\n",
    "                    \"parquet_noc_write_time (secs)\": timer(\n",
    "                        df.to_parquet, path=parquet_noc_name, compression=None\n",
    "                    ),\n",
    "                    \"parquet_noc_size (bytes)\": os.stat(parquet_noc_name).st_size,\n",
    "                    \"parquet_noc_read_time_all (secs)\": timer(\n",
    "                        pd.read_parquet, path=parquet_noc_name\n",
    "                    ),\n",
    "                    \"parquet_noc_read_time_one (secs)\": timer(\n",
    "                        pd.read_parquet, path=parquet_noc_name, columns=[\"col_2\"]\n",
    "                    ),\n",
    "                    # information about Parquet with snappy compression\n",
    "                    \"parquet_snappy_write_time (secs)\": timer(\n",
    "                        df.to_parquet, path=parquet_snappy_name, compression=\"snappy\"\n",
    "                    ),\n",
    "                    \"parquet_snappy_size (bytes)\": os.stat(parquet_snappy_name).st_size,\n",
    "                    \"parquet_snappy_read_time_all (secs)\": timer(\n",
    "                        pd.read_parquet, path=parquet_snappy_name\n",
    "                    ),\n",
    "                    \"parquet_snappy_read_time_one (secs)\": timer(\n",
    "                        pd.read_parquet, path=parquet_snappy_name, columns=[\"col_2\"]\n",
    "                    ),\n",
    "                    # information about Parquet with gzip compression\n",
    "                    \"parquet_gzip_write_time (secs)\": timer(\n",
    "                        df.to_parquet, path=parquet_gzip_name, compression=\"gzip\"\n",
    "                    ),\n",
    "                    \"parquet_gzip_size (bytes)\": os.stat(parquet_gzip_name).st_size,\n",
    "                    \"parquet_gzip_read_time_all (secs)\": timer(\n",
    "                        pd.read_parquet, path=parquet_gzip_name\n",
    "                    ),\n",
    "                    \"parquet_gzip_read_time_one (secs)\": timer(\n",
    "                        pd.read_parquet, path=parquet_gzip_name, columns=[\"col_2\"]\n",
    "                    ),\n",
    "                    # information about Parquet with zstd compression\n",
    "                    \"parquet_zstd_write_time (secs)\": timer(\n",
    "                        df.to_parquet, path=parquet_zstd_name, compression=\"zstd\"\n",
    "                    ),\n",
    "                    \"parquet_zstd_size (bytes)\": os.stat(parquet_zstd_name).st_size,\n",
    "                    \"parquet_zstd_read_time_all (secs)\": timer(\n",
    "                        pd.read_parquet, path=parquet_zstd_name\n",
    "                    ),\n",
    "                    \"parquet_zstd_read_time_one (secs)\": timer(\n",
    "                        pd.read_parquet, path=parquet_zstd_name, columns=[\"col_2\"]\n",
    "                    ),\n",
    "                    # information about Parquet with lz4 compression\n",
    "                    \"parquet_lz4_write_time (secs)\": timer(\n",
    "                        df.to_parquet, path=parquet_lz4_name, compression=\"lz4\"\n",
    "                    ),\n",
    "                    \"parquet_lz4_size (bytes)\": os.stat(parquet_lz4_name).st_size,\n",
    "                    \"parquet_lz4_read_time_all (secs)\": timer(\n",
    "                        pd.read_parquet, path=parquet_lz4_name\n",
    "                    ),\n",
    "                    \"parquet_lz4_read_time_one (secs)\": timer(\n",
    "                        pd.read_parquet, path=parquet_lz4_name, columns=[\"col_2\"]\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "    \n",
    "    \n",
    "    df_results = pd.DataFrame(results)\n",
    "else:\n",
    "    df_results = pd.read_parquet(\"parquet_analysis.parquet\")\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15efc85e-1d5e-4d5b-bb39-322a1eb2fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate full write + read time for each format\n",
    "if not pathlib.Path(\"parquet_analysis.parquet\").is_file():\n",
    "    df_results[\"csv_write_and_read_time (secs)\"] = (\n",
    "        df_results[\"csv_write_time (secs)\"] + df_results[\"csv_read_time_all (secs)\"]\n",
    "    )\n",
    "    df_results[\"sqlite_write_and_read_time (secs)\"] = (\n",
    "        df_results[\"sqlite_write_time (secs)\"] + df_results[\"sqlite_read_time_all (secs)\"]\n",
    "    )\n",
    "    \n",
    "    df_results[\"anndata_h5ad_noc_write_and_read_time (secs)\"] = (\n",
    "        df_results[\"anndata_h5ad_noc_write_time (secs)\"]\n",
    "        + df_results[\"anndata_h5ad_noc_read_time_all (secs)\"]\n",
    "    )\n",
    "    df_results[\"anndata_h5ad_gzip_write_and_read_time (secs)\"] = (\n",
    "        df_results[\"anndata_h5ad_gzip_write_time (secs)\"]\n",
    "        + df_results[\"anndata_h5ad_gzip_read_time_all (secs)\"]\n",
    "    )\n",
    "    df_results[\"anndata_h5ad_lz4_write_and_read_time (secs)\"] = (\n",
    "        df_results[\"anndata_h5ad_lz4_write_time (secs)\"]\n",
    "        + df_results[\"anndata_h5ad_lz4_read_time_all (secs)\"]\n",
    "    )\n",
    "    \n",
    "    df_results[\"anndata_h5ad_zstd_write_and_read_time (secs)\"] = (\n",
    "        df_results[\"anndata_h5ad_zstd_write_time (secs)\"]\n",
    "        + df_results[\"anndata_h5ad_zstd_read_time_all (secs)\"]\n",
    "    )\n",
    "    df_results[\"anndata_zarr_write_and_read_time (secs)\"] = (\n",
    "        df_results[\"anndata_zarr_write_time (secs)\"]\n",
    "        + df_results[\"anndata_zarr_read_time_all (secs)\"]\n",
    "    )\n",
    "    \n",
    "    df_results[\"parquet_noc_write_and_read_time (secs)\"] = (\n",
    "        df_results[\"parquet_noc_write_time (secs)\"]\n",
    "        + df_results[\"parquet_noc_read_time_all (secs)\"]\n",
    "    )\n",
    "    df_results[\"parquet_snappy_write_and_read_time (secs)\"] = (\n",
    "        df_results[\"parquet_snappy_write_time (secs)\"]\n",
    "        + df_results[\"parquet_snappy_read_time_all (secs)\"]\n",
    "    )\n",
    "    df_results[\"parquet_gzip_write_and_read_time (secs)\"] = (\n",
    "        df_results[\"parquet_gzip_write_time (secs)\"]\n",
    "        + df_results[\"parquet_gzip_read_time_all (secs)\"]\n",
    "    )\n",
    "    df_results[\"parquet_zstd_write_and_read_time (secs)\"] = (\n",
    "        df_results[\"parquet_zstd_write_time (secs)\"]\n",
    "        + df_results[\"parquet_zstd_read_time_all (secs)\"]\n",
    "    )\n",
    "    df_results[\"parquet_lz4_write_and_read_time (secs)\"] = (\n",
    "        df_results[\"parquet_lz4_write_time (secs)\"]\n",
    "        + df_results[\"parquet_lz4_read_time_all (secs)\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c16a71ac-e67b-4024-a5b5-ff0f8133a542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data to file\n",
    "if not pathlib.Path(\"parquet_analysis.parquet\").is_file():\n",
    "    df_results.to_parquet(\"parquet_analysis.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd7f3b73-33ce-48e0-a726-caff51c0552a",
   "metadata": {
    "papermill": {
     "duration": 0.048407,
     "end_time": "2025-09-03T21:57:20.305775",
     "exception": false,
     "start_time": "2025-09-03T21:57:20.257368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataframe_shape (rows, cols)</th>\n",
       "      <th>csv_write_time (secs) mean</th>\n",
       "      <th>csv_size (bytes) mean</th>\n",
       "      <th>csv_read_time_all (secs) mean</th>\n",
       "      <th>csv_read_time_one (secs) mean</th>\n",
       "      <th>sqlite_write_time (secs) mean</th>\n",
       "      <th>sqlite_size (bytes) mean</th>\n",
       "      <th>sqlite_read_time_all (secs) mean</th>\n",
       "      <th>sqlite_read_time_one (secs) mean</th>\n",
       "      <th>anndata_h5ad_noc_write_time (secs) mean</th>\n",
       "      <th>...</th>\n",
       "      <th>anndata_h5ad_noc_write_and_read_time (secs) max</th>\n",
       "      <th>anndata_h5ad_gzip_write_and_read_time (secs) max</th>\n",
       "      <th>anndata_h5ad_lz4_write_and_read_time (secs) max</th>\n",
       "      <th>anndata_h5ad_zstd_write_and_read_time (secs) max</th>\n",
       "      <th>anndata_zarr_write_and_read_time (secs) max</th>\n",
       "      <th>parquet_noc_write_and_read_time (secs) max</th>\n",
       "      <th>parquet_snappy_write_and_read_time (secs) max</th>\n",
       "      <th>parquet_gzip_write_and_read_time (secs) max</th>\n",
       "      <th>parquet_zstd_write_and_read_time (secs) max</th>\n",
       "      <th>parquet_lz4_write_and_read_time (secs) max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(640, 258)</td>\n",
       "      <td>0.349897</td>\n",
       "      <td>1396981.0</td>\n",
       "      <td>0.022234</td>\n",
       "      <td>0.012183</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>2654208.0</td>\n",
       "      <td>0.019346</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.008694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016972</td>\n",
       "      <td>0.040427</td>\n",
       "      <td>0.019582</td>\n",
       "      <td>0.020601</td>\n",
       "      <td>1.113573</td>\n",
       "      <td>0.033067</td>\n",
       "      <td>0.029633</td>\n",
       "      <td>0.063741</td>\n",
       "      <td>0.050335</td>\n",
       "      <td>0.030999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1280, 506)</td>\n",
       "      <td>1.437428</td>\n",
       "      <td>5570915.0</td>\n",
       "      <td>0.068784</td>\n",
       "      <td>0.048241</td>\n",
       "      <td>0.231817</td>\n",
       "      <td>5935104.0</td>\n",
       "      <td>0.323991</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>0.010804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022354</td>\n",
       "      <td>0.109140</td>\n",
       "      <td>0.025818</td>\n",
       "      <td>0.042029</td>\n",
       "      <td>1.240568</td>\n",
       "      <td>0.062581</td>\n",
       "      <td>0.056412</td>\n",
       "      <td>0.158858</td>\n",
       "      <td>0.073382</td>\n",
       "      <td>0.057395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 181 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataframe_shape (rows, cols)  csv_write_time (secs) mean  \\\n",
       "0                   (640, 258)                    0.349897   \n",
       "1                  (1280, 506)                    1.437428   \n",
       "\n",
       "   csv_size (bytes) mean  csv_read_time_all (secs) mean  \\\n",
       "0              1396981.0                       0.022234   \n",
       "1              5570915.0                       0.068784   \n",
       "\n",
       "   csv_read_time_one (secs) mean  sqlite_write_time (secs) mean  \\\n",
       "0                       0.012183                       0.065789   \n",
       "1                       0.048241                       0.231817   \n",
       "\n",
       "   sqlite_size (bytes) mean  sqlite_read_time_all (secs) mean  \\\n",
       "0                 2654208.0                          0.019346   \n",
       "1                 5935104.0                          0.323991   \n",
       "\n",
       "   sqlite_read_time_one (secs) mean  anndata_h5ad_noc_write_time (secs) mean  \\\n",
       "0                          0.001576                                 0.008694   \n",
       "1                          0.003679                                 0.010804   \n",
       "\n",
       "   ...  anndata_h5ad_noc_write_and_read_time (secs) max  \\\n",
       "0  ...                                         0.016972   \n",
       "1  ...                                         0.022354   \n",
       "\n",
       "   anndata_h5ad_gzip_write_and_read_time (secs) max  \\\n",
       "0                                          0.040427   \n",
       "1                                          0.109140   \n",
       "\n",
       "   anndata_h5ad_lz4_write_and_read_time (secs) max  \\\n",
       "0                                         0.019582   \n",
       "1                                         0.025818   \n",
       "\n",
       "   anndata_h5ad_zstd_write_and_read_time (secs) max  \\\n",
       "0                                          0.020601   \n",
       "1                                          0.042029   \n",
       "\n",
       "   anndata_zarr_write_and_read_time (secs) max  \\\n",
       "0                                     1.113573   \n",
       "1                                     1.240568   \n",
       "\n",
       "   parquet_noc_write_and_read_time (secs) max  \\\n",
       "0                                    0.033067   \n",
       "1                                    0.062581   \n",
       "\n",
       "   parquet_snappy_write_and_read_time (secs) max  \\\n",
       "0                                       0.029633   \n",
       "1                                       0.056412   \n",
       "\n",
       "   parquet_gzip_write_and_read_time (secs) max  \\\n",
       "0                                     0.063741   \n",
       "1                                     0.158858   \n",
       "\n",
       "   parquet_zstd_write_and_read_time (secs) max  \\\n",
       "0                                     0.050335   \n",
       "1                                     0.073382   \n",
       "\n",
       "   parquet_lz4_write_and_read_time (secs) max  \n",
       "0                                    0.030999  \n",
       "1                                    0.057395  \n",
       "\n",
       "[2 rows x 181 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gather average, min, and max for error bar implementation\n",
    "average = (\n",
    "    df_results.groupby(\"dataframe_shape (rows, cols)\")\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .sort_values(by=\"csv_size (bytes)\")\n",
    ")\n",
    "minimums = (\n",
    "    df_results.groupby(\"dataframe_shape (rows, cols)\")\n",
    "    .min()\n",
    "    .reset_index()\n",
    "    .sort_values(by=\"csv_size (bytes)\")\n",
    ")\n",
    "maximums = (\n",
    "    df_results.groupby(\"dataframe_shape (rows, cols)\")\n",
    "    .max()\n",
    "    .reset_index()\n",
    "    .sort_values(by=\"csv_size (bytes)\")\n",
    ")\n",
    "\n",
    "key = \"dataframe_shape (rows, cols)\"\n",
    "\n",
    "result = (\n",
    "    average.set_index(key)\n",
    "    .add_suffix(\" mean\")\n",
    "    .join(minimums.set_index(key).add_suffix(\" min\"))\n",
    "    .join(maximums.set_index(key).add_suffix(\" max\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b205495-4c5f-4811-a7f3-0dfe4d933b14",
   "metadata": {
    "papermill": {
     "duration": 1.365292,
     "end_time": "2025-09-03T21:57:21.680374",
     "exception": false,
     "start_time": "2025-09-03T21:57:20.315082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/parquet-comparisons-file-write-time.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write time plot\n",
    "\n",
    "key = \"dataframe_shape (rows, cols)\"\n",
    "\n",
    "cols = {\n",
    "    \"CSV (GZIP)\": (\n",
    "        \"csv_write_time (secs) mean\",\n",
    "        \"csv_write_time (secs) min\",\n",
    "        \"csv_write_time (secs) max\",\n",
    "    ),\n",
    "    \"SQLite\": (\n",
    "        \"sqlite_write_time (secs) mean\",\n",
    "        \"sqlite_write_time (secs) min\",\n",
    "        \"sqlite_write_time (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - uncompressed)\": (\n",
    "        \"anndata_h5ad_noc_write_time (secs) mean\",\n",
    "        \"anndata_h5ad_noc_write_time (secs) min\",\n",
    "        \"anndata_h5ad_noc_write_time (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - GZIP)\": (\n",
    "        \"anndata_h5ad_gzip_write_time (secs) mean\",\n",
    "        \"anndata_h5ad_gzip_write_time (secs) min\",\n",
    "        \"anndata_h5ad_gzip_write_time (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - ZSTD)\": (\n",
    "        \"anndata_h5ad_zstd_write_time (secs) mean\",\n",
    "        \"anndata_h5ad_zstd_write_time (secs) min\",\n",
    "        \"anndata_h5ad_zstd_write_time (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - LZ4)\": (\n",
    "        \"anndata_h5ad_lz4_write_time (secs) mean\",\n",
    "        \"anndata_h5ad_lz4_write_time (secs) min\",\n",
    "        \"anndata_h5ad_lz4_write_time (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (Zarr)\": (\n",
    "        \"anndata_zarr_write_time (secs) mean\",\n",
    "        \"anndata_zarr_write_time (secs) min\",\n",
    "        \"anndata_zarr_write_time (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (uncompressed)\": (\n",
    "        \"parquet_noc_write_time (secs) mean\",\n",
    "        \"parquet_noc_write_time (secs) min\",\n",
    "        \"parquet_noc_write_time (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (Snappy)\": (\n",
    "        \"parquet_snappy_write_time (secs) mean\",\n",
    "        \"parquet_snappy_write_time (secs) min\",\n",
    "        \"parquet_snappy_write_time (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (GZIP)\": (\n",
    "        \"parquet_gzip_write_time (secs) mean\",\n",
    "        \"parquet_gzip_write_time (secs) min\",\n",
    "        \"parquet_gzip_write_time (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (ZSTD)\": (\n",
    "        \"parquet_zstd_write_time (secs) mean\",\n",
    "        \"parquet_zstd_write_time (secs) min\",\n",
    "        \"parquet_zstd_write_time (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (LZ4)\": (\n",
    "        \"parquet_lz4_write_time (secs) mean\",\n",
    "        \"parquet_lz4_write_time (secs) min\",\n",
    "        \"parquet_lz4_write_time (secs) max\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "parts = []\n",
    "for fmt, (mcol, mincol, maxcol) in cols.items():\n",
    "    tmp = result[[key, mcol, mincol, maxcol]].copy()\n",
    "    tmp[\"format\"] = fmt\n",
    "    tmp.rename(columns={mcol: \"mean\", mincol: \"min\", maxcol: \"max\"}, inplace=True)\n",
    "    tmp[\"err_plus\"] = tmp[\"max\"] - tmp[\"mean\"]\n",
    "    tmp[\"err_minus\"] = tmp[\"mean\"] - tmp[\"min\"]\n",
    "    parts.append(tmp[[key, \"format\", \"mean\", \"err_plus\", \"err_minus\"]])\n",
    "\n",
    "\n",
    "stats = pd.concat(parts, ignore_index=True)\n",
    "\n",
    "x_order = result[key].tolist()  # not reversed; use iloc[::-1] to reverse\n",
    "pos = {k: i for i, k in enumerate(x_order)}  # category â†’ position index\n",
    "\n",
    "# 2) give each row its x position and sort per-trace\n",
    "stats = stats.assign(xpos=stats[key].map(pos)).sort_values([\"format\", \"xpos\"])\n",
    "\n",
    "fig = px.line(\n",
    "    stats,  # already trace-sorted by xpos\n",
    "    x=key,\n",
    "    y=\"mean\",\n",
    "    color=\"format\",\n",
    "    error_y=\"err_plus\",\n",
    "    error_y_minus=\"err_minus\",\n",
    "    markers=True,\n",
    "    category_orders={key: x_order},  # sets axis order & legend hover categories\n",
    "    labels={key: \"Data Shape\", \"mean\": \"Seconds (log)\"},\n",
    "    width=1300,\n",
    "    log_y=True,\n",
    "    title=\"File format write time duration (seconds)\",\n",
    ")\n",
    "fig.update_traces(mode=\"lines+markers\")\n",
    "fig.update_traces(marker_color=None, line_color=None).update_layout(\n",
    "    colorway=px.colors.qualitative.Dark24\n",
    ")\n",
    "fig.update_layout(legend_title_text=\"Format\")\n",
    "\n",
    "\n",
    "pio.write_image(fig, file_write_time_image)\n",
    "Image(url=file_write_time_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4827e5d-b2e4-4b8c-bff8-db96e0b76949",
   "metadata": {
    "papermill": {
     "duration": 0.313924,
     "end_time": "2025-09-03T21:57:22.005171",
     "exception": false,
     "start_time": "2025-09-03T21:57:21.691247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/parquet-comparisons-file-storage-size.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file size plot\n",
    "\n",
    "key = \"dataframe_shape (rows, cols)\"\n",
    "\n",
    "size_cols = {\n",
    "    \"csv_size (bytes)\": \"CSV (GZIP)\",\n",
    "    \"sqlite_size (bytes)\": \"SQLite\",\n",
    "    \"anndata_h5ad_noc_size (bytes)\": \"AnnData (H5AD - uncompressed)\",\n",
    "    \"anndata_h5ad_gzip_size (bytes)\": \"AnnData (H5AD - GZIP)\",\n",
    "    \"anndata_h5ad_lz4_size (bytes)\": \"AnnData (H5AD - LZ4)\",\n",
    "    \"anndata_h5ad_zstd_size (bytes)\": \"AnnData (H5AD - ZSTD)\",\n",
    "    \"anndata_zarr_size (bytes)\": \"AnnData (Zarr)\",\n",
    "    \"parquet_noc_size (bytes)\": \"Parquet (uncompressed)\",\n",
    "    \"parquet_snappy_size (bytes)\": \"Parquet (Snappy)\",\n",
    "    \"parquet_gzip_size (bytes)\": \"Parquet (GZIP)\",\n",
    "    \"parquet_zstd_size (bytes)\": \"Parquet (ZSTD)\",\n",
    "    \"parquet_lz4_size (bytes)\": \"Parquet (LZ4)\",\n",
    "}\n",
    "\n",
    "# Long-form + average across repeats\n",
    "long = df_results.melt(\n",
    "    id_vars=[key],\n",
    "    value_vars=list(size_cols.keys()),\n",
    "    var_name=\"col\",\n",
    "    value_name=\"bytes\",\n",
    ").dropna(subset=[\"bytes\"])\n",
    "long[\"format\"] = long[\"col\"].map(size_cols)\n",
    "\n",
    "stats = long.groupby([key, \"format\"], as_index=False)[\"bytes\"].mean()\n",
    "\n",
    "# Choose x-axis category order (keep your current result order, reversed here).\n",
    "x_order = result[key].iloc[::-1].tolist()\n",
    "\n",
    "# Ensure each trace's points follow that order (pre-sort rows)\n",
    "pos = {cat: i for i, cat in enumerate(x_order)}\n",
    "stats_sorted = stats.assign(xpos=stats[key].map(pos)).sort_values([\"format\", \"xpos\"])\n",
    "\n",
    "fig = px.line(\n",
    "    stats_sorted,\n",
    "    x=key,\n",
    "    y=\"bytes\",\n",
    "    color=\"format\",\n",
    "    markers=True,\n",
    "    category_orders={key: x_order},\n",
    "    labels={key: \"Data Shape\", \"bytes\": \"Bytes\"},\n",
    "    width=1300,\n",
    "    title=\"File format size (bytes)\",\n",
    ")\n",
    "\n",
    "fig.update_traces(mode=\"lines+markers\")\n",
    "fig.update_xaxes(autorange=\"reversed\")\n",
    "fig.update_traces(marker_color=None, line_color=None).update_layout(\n",
    "    colorway=px.colors.qualitative.Dark24\n",
    ")\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=1.02,\n",
    "        y=1,  # just outside the plotting area\n",
    "        xanchor=\"left\",\n",
    "        yanchor=\"top\",\n",
    "        bgcolor=\"rgba(255,255,255,0.8)\",\n",
    "    ),\n",
    "    margin=dict(r=220),  # add right margin so legend fits\n",
    "    font=dict(size=18),\n",
    ")\n",
    "\n",
    "pio.write_image(fig, file_storage_size_image)\n",
    "Image(url=file_storage_size_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ab638a5-e6e1-47e5-a5f9-56f156a71bc7",
   "metadata": {
    "papermill": {
     "duration": 0.250629,
     "end_time": "2025-09-03T21:57:22.266295",
     "exception": false,
     "start_time": "2025-09-03T21:57:22.015666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/parquet-comparisons-file-read-time-all-columns.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read time plot (all columns)\n",
    "key = \"dataframe_shape (rows, cols)\"\n",
    "\n",
    "cols = {\n",
    "    \"CSV (GZIP)\": (\n",
    "        \"csv_read_time_all (secs) mean\",\n",
    "        \"csv_read_time_all (secs) min\",\n",
    "        \"csv_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"SQLite\": (\n",
    "        \"sqlite_read_time_all (secs) mean\",\n",
    "        \"sqlite_read_time_all (secs) min\",\n",
    "        \"sqlite_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - uncompressed)\": (\n",
    "        \"anndata_h5ad_noc_read_time_all (secs) mean\",\n",
    "        \"anndata_h5ad_noc_read_time_all (secs) min\",\n",
    "        \"anndata_h5ad_noc_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - GZIP)\": (\n",
    "        \"anndata_h5ad_gzip_read_time_all (secs) mean\",\n",
    "        \"anndata_h5ad_gzip_read_time_all (secs) min\",\n",
    "        \"anndata_h5ad_gzip_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - ZSTD)\": (\n",
    "        \"anndata_h5ad_zstd_read_time_all (secs) mean\",\n",
    "        \"anndata_h5ad_zstd_read_time_all (secs) min\",\n",
    "        \"anndata_h5ad_zstd_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - LZ4)\": (\n",
    "        \"anndata_h5ad_lz4_read_time_all (secs) mean\",\n",
    "        \"anndata_h5ad_lz4_read_time_all (secs) min\",\n",
    "        \"anndata_h5ad_lz4_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (Zarr)\": (\n",
    "        \"anndata_zarr_read_time_all (secs) mean\",\n",
    "        \"anndata_zarr_read_time_all (secs) min\",\n",
    "        \"anndata_zarr_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (uncompressed)\": (\n",
    "        \"parquet_noc_read_time_all (secs) mean\",\n",
    "        \"parquet_noc_read_time_all (secs) min\",\n",
    "        \"parquet_noc_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (Snappy)\": (\n",
    "        \"parquet_snappy_read_time_all (secs) mean\",\n",
    "        \"parquet_snappy_read_time_all (secs) min\",\n",
    "        \"parquet_snappy_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (GZIP)\": (\n",
    "        \"parquet_gzip_read_time_all (secs) mean\",\n",
    "        \"parquet_gzip_read_time_all (secs) min\",\n",
    "        \"parquet_gzip_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (ZSTD)\": (\n",
    "        \"parquet_zstd_read_time_all (secs) mean\",\n",
    "        \"parquet_zstd_read_time_all (secs) min\",\n",
    "        \"parquet_zstd_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (LZ4)\": (\n",
    "        \"parquet_lz4_read_time_all (secs) mean\",\n",
    "        \"parquet_lz4_read_time_all (secs) min\",\n",
    "        \"parquet_lz4_read_time_all (secs) max\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "parts = []\n",
    "for fmt, (mcol, mincol, maxcol) in cols.items():\n",
    "    tmp = result[[key, mcol, mincol, maxcol]].copy()\n",
    "    tmp[\"format\"] = fmt\n",
    "    tmp.rename(columns={mcol: \"mean\", mincol: \"min\", maxcol: \"max\"}, inplace=True)\n",
    "    tmp[\"err_plus\"] = tmp[\"max\"] - tmp[\"mean\"]\n",
    "    tmp[\"err_minus\"] = tmp[\"mean\"] - tmp[\"min\"]\n",
    "    parts.append(tmp[[key, \"format\", \"mean\", \"err_plus\", \"err_minus\"]])\n",
    "\n",
    "\n",
    "stats = pd.concat(parts, ignore_index=True)\n",
    "\n",
    "x_order = result[key].tolist()  # not reversed; use iloc[::-1] to reverse\n",
    "pos = {k: i for i, k in enumerate(x_order)}  # category â†’ position index\n",
    "\n",
    "# 2) give each row its x position and sort per-trace\n",
    "stats = stats.assign(xpos=stats[key].map(pos)).sort_values([\"format\", \"xpos\"])\n",
    "\n",
    "fig = px.line(\n",
    "    stats,  # already trace-sorted by xpos\n",
    "    x=key,\n",
    "    y=\"mean\",\n",
    "    color=\"format\",\n",
    "    error_y=\"err_plus\",\n",
    "    error_y_minus=\"err_minus\",\n",
    "    markers=True,\n",
    "    category_orders={key: x_order},  # sets axis order & legend hover categories\n",
    "    labels={key: \"Data Shape\", \"mean\": \"Seconds\"},\n",
    "    width=1300,\n",
    "    log_y=True,\n",
    "    title=\"File format read time duration (full dataset) (seconds)\",\n",
    ")\n",
    "fig.update_traces(mode=\"lines+markers\")\n",
    "fig.update_traces(marker_color=None, line_color=None).update_layout(\n",
    "    colorway=px.colors.qualitative.Dark24\n",
    ")\n",
    "fig.update_layout(legend_title_text=\"Format\")\n",
    "\n",
    "\n",
    "pio.write_image(fig, file_read_time_all_image)\n",
    "Image(url=file_read_time_all_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd99f232-8564-4b83-82c7-e4b0cc5cfbf4",
   "metadata": {
    "papermill": {
     "duration": 0.260285,
     "end_time": "2025-09-03T21:57:22.537386",
     "exception": false,
     "start_time": "2025-09-03T21:57:22.277101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/parquet-comparisons-file-read-time-one-column.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read time plot (one column)\n",
    "\n",
    "key = \"dataframe_shape (rows, cols)\"\n",
    "\n",
    "cols = {\n",
    "    \"CSV (GZIP)\": (\n",
    "        \"csv_read_time_one (secs) mean\",\n",
    "        \"csv_read_time_one (secs) min\",\n",
    "        \"csv_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"SQLite\": (\n",
    "        \"sqlite_read_time_one (secs) mean\",\n",
    "        \"sqlite_read_time_one (secs) min\",\n",
    "        \"sqlite_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - uncompressed)\": (\n",
    "        \"anndata_h5ad_noc_read_time_one (secs) mean\",\n",
    "        \"anndata_h5ad_noc_read_time_one (secs) min\",\n",
    "        \"anndata_h5ad_noc_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - GZIP)\": (\n",
    "        \"anndata_h5ad_gzip_read_time_one (secs) mean\",\n",
    "        \"anndata_h5ad_gzip_read_time_one (secs) min\",\n",
    "        \"anndata_h5ad_gzip_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - ZSTD)\": (\n",
    "        \"anndata_h5ad_zstd_read_time_one (secs) mean\",\n",
    "        \"anndata_h5ad_zstd_read_time_one (secs) min\",\n",
    "        \"anndata_h5ad_zstd_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - LZ4)\": (\n",
    "        \"anndata_h5ad_lz4_read_time_one (secs) mean\",\n",
    "        \"anndata_h5ad_lz4_read_time_one (secs) min\",\n",
    "        \"anndata_h5ad_lz4_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (Zarr)\": (\n",
    "        \"anndata_zarr_read_time_one (secs) mean\",\n",
    "        \"anndata_zarr_read_time_one (secs) min\",\n",
    "        \"anndata_zarr_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (uncompressed)\": (\n",
    "        \"parquet_noc_read_time_one (secs) mean\",\n",
    "        \"parquet_noc_read_time_one (secs) min\",\n",
    "        \"parquet_noc_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (Snappy)\": (\n",
    "        \"parquet_snappy_read_time_one (secs) mean\",\n",
    "        \"parquet_snappy_read_time_one (secs) min\",\n",
    "        \"parquet_snappy_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (GZIP)\": (\n",
    "        \"parquet_gzip_read_time_one (secs) mean\",\n",
    "        \"parquet_gzip_read_time_one (secs) min\",\n",
    "        \"parquet_gzip_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (ZSTD)\": (\n",
    "        \"parquet_zstd_read_time_one (secs) mean\",\n",
    "        \"parquet_zstd_read_time_one (secs) min\",\n",
    "        \"parquet_zstd_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (LZ4)\": (\n",
    "        \"parquet_lz4_read_time_one (secs) mean\",\n",
    "        \"parquet_lz4_read_time_one (secs) min\",\n",
    "        \"parquet_lz4_read_time_one (secs) max\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "parts = []\n",
    "for fmt, (mcol, mincol, maxcol) in cols.items():\n",
    "    tmp = result[[key, mcol, mincol, maxcol]].copy()\n",
    "    tmp[\"format\"] = fmt\n",
    "    tmp.rename(columns={mcol: \"mean\", mincol: \"min\", maxcol: \"max\"}, inplace=True)\n",
    "    tmp[\"err_plus\"] = tmp[\"max\"] - tmp[\"mean\"]\n",
    "    tmp[\"err_minus\"] = tmp[\"mean\"] - tmp[\"min\"]\n",
    "    parts.append(tmp[[key, \"format\", \"mean\", \"err_plus\", \"err_minus\"]])\n",
    "\n",
    "\n",
    "stats = pd.concat(parts, ignore_index=True)\n",
    "\n",
    "x_order = result[key].tolist()  # not reversed; use iloc[::-1] to reverse\n",
    "pos = {k: i for i, k in enumerate(x_order)}  # category â†’ position index\n",
    "\n",
    "# 2) give each row its x position and sort per-trace\n",
    "stats = stats.assign(xpos=stats[key].map(pos)).sort_values([\"format\", \"xpos\"])\n",
    "\n",
    "fig = px.line(\n",
    "    stats,  # already trace-sorted by xpos\n",
    "    x=key,\n",
    "    y=\"mean\",\n",
    "    color=\"format\",\n",
    "    error_y=\"err_plus\",\n",
    "    error_y_minus=\"err_minus\",\n",
    "    markers=True,\n",
    "    category_orders={key: x_order},  # sets axis order & legend hover categories\n",
    "    labels={key: \"Data Shape\", \"mean\": \"Seconds (log)\"},\n",
    "    width=1300,\n",
    "    log_y=True,\n",
    "    title=\"File format read time duration (one column) (seconds)\",\n",
    ")\n",
    "fig.update_traces(mode=\"lines+markers\")\n",
    "fig.update_traces(marker_color=None, line_color=None).update_layout(\n",
    "    colorway=px.colors.qualitative.Dark24\n",
    ")\n",
    "fig.update_layout(legend_title_text=\"Format\")\n",
    "\n",
    "\n",
    "pio.write_image(fig, file_read_time_one_image)\n",
    "Image(url=file_read_time_one_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d91b712-df84-45d9-a95d-15cd3341ec41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/parquet-comparisons-file-write-and-read-time.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write and read time plot (combined times from write and read all)\n",
    "\n",
    "key = \"dataframe_shape (rows, cols)\"\n",
    "\n",
    "cols = {\n",
    "    \"CSV (GZIP)\": (\n",
    "        \"csv_write_and_read_time (secs) mean\",\n",
    "        \"csv_write_and_read_time (secs) min\",\n",
    "        \"csv_write_and_read_time (secs) max\",\n",
    "    ),\n",
    "    \"SQLite\": (\n",
    "        \"sqlite_write_and_read_time (secs) mean\",\n",
    "        \"sqlite_write_and_read_time (secs) min\",\n",
    "        \"sqlite_write_and_read_time (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - uncompressed)\": (\n",
    "        \"anndata_h5ad_noc_write_and_read_time (secs) mean\",\n",
    "        \"anndata_h5ad_noc_write_and_read_time (secs) min\",\n",
    "        \"anndata_h5ad_noc_write_and_read_time (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - GZIP)\": (\n",
    "        \"anndata_h5ad_gzip_write_and_read_time (secs) mean\",\n",
    "        \"anndata_h5ad_gzip_write_and_read_time (secs) min\",\n",
    "        \"anndata_h5ad_gzip_write_and_read_time (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - ZSTD)\": (\n",
    "        \"anndata_h5ad_zstd_write_and_read_time (secs) mean\",\n",
    "        \"anndata_h5ad_zstd_write_and_read_time (secs) min\",\n",
    "        \"anndata_h5ad_zstd_write_and_read_time (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - LZ4)\": (\n",
    "        \"anndata_h5ad_lz4_write_and_read_time (secs) mean\",\n",
    "        \"anndata_h5ad_lz4_write_and_read_time (secs) min\",\n",
    "        \"anndata_h5ad_lz4_write_and_read_time (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (Zarr)\": (\n",
    "        \"anndata_zarr_write_and_read_time (secs) mean\",\n",
    "        \"anndata_zarr_write_and_read_time (secs) min\",\n",
    "        \"anndata_zarr_write_and_read_time (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (uncompressed)\": (\n",
    "        \"parquet_noc_write_and_read_time (secs) mean\",\n",
    "        \"parquet_noc_write_and_read_time (secs) min\",\n",
    "        \"parquet_noc_write_and_read_time (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (Snappy)\": (\n",
    "        \"parquet_snappy_write_and_read_time (secs) mean\",\n",
    "        \"parquet_snappy_write_and_read_time (secs) min\",\n",
    "        \"parquet_snappy_write_and_read_time (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (GZIP)\": (\n",
    "        \"parquet_gzip_write_and_read_time (secs) mean\",\n",
    "        \"parquet_gzip_write_and_read_time (secs) min\",\n",
    "        \"parquet_gzip_write_and_read_time (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (ZSTD)\": (\n",
    "        \"parquet_zstd_write_and_read_time (secs) mean\",\n",
    "        \"parquet_zstd_write_and_read_time (secs) min\",\n",
    "        \"parquet_zstd_write_and_read_time (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (LZ4)\": (\n",
    "        \"parquet_lz4_write_and_read_time (secs) mean\",\n",
    "        \"parquet_lz4_write_and_read_time (secs) min\",\n",
    "        \"parquet_lz4_write_and_read_time (secs) max\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "parts = []\n",
    "for fmt, (mcol, mincol, maxcol) in cols.items():\n",
    "    tmp = result[[key, mcol, mincol, maxcol]].copy()\n",
    "    tmp[\"format\"] = fmt\n",
    "    tmp.rename(columns={mcol: \"mean\", mincol: \"min\", maxcol: \"max\"}, inplace=True)\n",
    "    tmp[\"err_plus\"] = tmp[\"max\"] - tmp[\"mean\"]\n",
    "    tmp[\"err_minus\"] = tmp[\"mean\"] - tmp[\"min\"]\n",
    "    parts.append(tmp[[key, \"format\", \"mean\", \"err_plus\", \"err_minus\"]])\n",
    "\n",
    "\n",
    "stats = pd.concat(parts, ignore_index=True)\n",
    "\n",
    "x_order = result[key].tolist()  # not reversed; use iloc[::-1] to reverse\n",
    "pos = {k: i for i, k in enumerate(x_order)}  # category â†’ position index\n",
    "\n",
    "# 2) give each row its x position and sort per-trace\n",
    "stats = stats.assign(xpos=stats[key].map(pos)).sort_values([\"format\", \"xpos\"])\n",
    "\n",
    "fig = px.line(\n",
    "    stats,  # already trace-sorted by xpos\n",
    "    x=key,\n",
    "    y=\"mean\",\n",
    "    color=\"format\",\n",
    "    error_y=\"err_plus\",\n",
    "    error_y_minus=\"err_minus\",\n",
    "    markers=True,\n",
    "    category_orders={key: x_order},  # sets axis order & legend hover categories\n",
    "    labels={key: \"Data Shape\", \"mean\": \"Seconds (log)\"},\n",
    "    width=1300,\n",
    "    log_y=True,\n",
    "    title=\"File format write and read time (full dataset) (seconds)\",\n",
    ")\n",
    "fig.update_traces(mode=\"lines+markers\")\n",
    "fig.update_traces(marker_color=None, line_color=None).update_layout(\n",
    "    colorway=px.colors.qualitative.Dark24\n",
    ")\n",
    "fig.update_layout(legend_title_text=\"Format\")\n",
    "\n",
    "\n",
    "pio.write_image(fig, file_read_time_write_and_read_time_image)\n",
    "Image(url=file_read_time_write_and_read_time_image)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 134.268328,
   "end_time": "2025-09-03T21:57:25.270281",
   "environment_variables": {},
   "exception": null,
   "input_path": "parquet_analysis.ipynb",
   "output_path": "parquet_analysis.ipynb",
   "parameters": {},
   "start_time": "2025-09-03T21:55:11.001953",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "529f5590-609a-4554-9254-e22e8a4822ad",
   "metadata": {
    "papermill": {
     "duration": 0.006888,
     "end_time": "2025-09-03T21:55:12.133407",
     "exception": false,
     "start_time": "2025-09-03T21:55:12.126519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Why Parquet?\n",
    "\n",
    "This notebook explores the benefits or drawbacks of using the [parquet](https://parquet.apache.org/docs/) file format relative to other formats such as CSV or SQLite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ac8b5f-d7b1-43aa-9589-19890914f646",
   "metadata": {
    "papermill": {
     "duration": 1.269103,
     "end_time": "2025-09-03T21:55:13.408073",
     "exception": false,
     "start_time": "2025-09-03T21:55:12.138970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import shutil\n",
    "import string\n",
    "import warnings\n",
    "from typing import Literal\n",
    "\n",
    "import anndata as ad\n",
    "import duckdb\n",
    "import hdf5plugin\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from anndata import ImplicitModificationWarning\n",
    "from IPython.display import Image\n",
    "from utilities import get_system_info, timer\n",
    "\n",
    "# ignore anndata warnings about index conversion\n",
    "warnings.filterwarnings(\"ignore\", category=ImplicitModificationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5af2f06c-3317-4e88-9a3a-64860879f60f",
   "metadata": {
    "papermill": {
     "duration": 0.015148,
     "end_time": "2025-09-03T21:55:13.429168",
     "exception": false,
     "start_time": "2025-09-03T21:55:13.414020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System Information:\n",
      "Operating System: Darwin\n",
      "Machine Type: arm64\n",
      "Processor: arm\n",
      "CPU Cores (Logical): 12\n",
      "CPU Cores (Physical): 12\n",
      "Total RAM (GB): 48.0\n",
      "Python Version: 3.12.2\n"
     ]
    }
   ],
   "source": [
    "# show the system information\n",
    "_ = get_system_info(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d7ac6d-3ffa-4a57-99ba-a0214c4e2753",
   "metadata": {
    "papermill": {
     "duration": 0.049587,
     "end_time": "2025-09-03T21:55:13.484421",
     "exception": false,
     "start_time": "2025-09-03T21:55:13.434834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# target file or table names\n",
    "image_dir = \"images\"\n",
    "csv_name = \"example.csv.gz\"\n",
    "parquet_noc_name = \"example.parquet\"\n",
    "parquet_snappy_name = \"example.snappy.parquet\"\n",
    "parquet_gzip_name = \"example.gzip.parquet\"\n",
    "parquet_lz4_name = \"example.lz4.parquet\"\n",
    "parquet_zstd_name = \"example.zstd.parquet\"\n",
    "sqlite_name = \"example.sqlite\"\n",
    "sqlite_tbl_name = \"tbl_example\"\n",
    "anndata_h5_noc_name = \"adata.noc.h5ad\"\n",
    "anndata_h5_gzip_name = \"adata.gzip.h5ad\"\n",
    "anndata_h5_lz4_name = \"adata.lz4.h5ad\"\n",
    "anndata_h5_zstd_name = \"adata.zstd.h5ad\"\n",
    "anndata_zarr_name = \"adata.zarr\"\n",
    "file_write_time_image = f\"{image_dir}/parquet-comparisons-file-write-time.png\"\n",
    "file_storage_size_image = f\"{image_dir}/parquet-comparisons-file-storage-size.png\"\n",
    "file_read_time_all_image = (\n",
    "    f\"{image_dir}/parquet-comparisons-file-read-time-all-columns.png\"\n",
    ")\n",
    "file_read_time_one_image = (\n",
    "    f\"{image_dir}/parquet-comparisons-file-read-time-one-column.png\"\n",
    ")\n",
    "\n",
    "\n",
    "def remove_files():\n",
    "    \"\"\"\n",
    "    Utility function to remove files as needed.\n",
    "    \"\"\"\n",
    "    for name in [\n",
    "        csv_name,\n",
    "        parquet_noc_name,\n",
    "        parquet_snappy_name,\n",
    "        parquet_gzip_name,\n",
    "        parquet_lz4_name,\n",
    "        parquet_zstd_name,\n",
    "        sqlite_name,\n",
    "        anndata_h5_noc_name,\n",
    "        anndata_h5_gzip_name,\n",
    "        anndata_h5_lz4_name,\n",
    "        anndata_h5_zstd_name,\n",
    "    ]:\n",
    "        pathlib.Path(name).unlink(missing_ok=True)\n",
    "\n",
    "    if pathlib.Path(anndata_zarr_name).is_dir():\n",
    "        shutil.rmtree(anndata_zarr_name)\n",
    "\n",
    "\n",
    "# remove all files just in case\n",
    "remove_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92ab9dfb-9b64-4e8f-9f6c-6251e800c7e4",
   "metadata": {
    "papermill": {
     "duration": 0.017819,
     "end_time": "2025-09-03T21:55:13.509355",
     "exception": false,
     "start_time": "2025-09-03T21:55:13.491536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_anndata(\n",
    "    df: pd.DataFrame,\n",
    "    write_to: Literal[\"h5ad\", \"zarr\"],\n",
    "    compression: Literal[\"gzip\", \"lz4\", \"zstd\", \"none\"],\n",
    "    dest_path: str,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Serialize a DataFrame to AnnData (h5ad or zarr).\n",
    "\n",
    "    Numeric columns are stored in ``X`` (observations Ã— variables). All\n",
    "    remaining columns are stored in ``.obs``. Variable (feature) names are taken\n",
    "    from the numeric column labels, and observation names from the DataFrame\n",
    "    index.\n",
    "\n",
    "    Args:\n",
    "        df:\n",
    "            Input table with rows as observations and columns as features.\n",
    "        write_to:\n",
    "            Output format. Either ``\"h5ad\"`` or ``\"zarr\"``.\n",
    "        compression:\n",
    "            The type of compression to use with\n",
    "        dest_path:\n",
    "            Destination file (``.h5ad``) or directory (zarr store)\n",
    "            to write to. Parent directories are created if missing.\n",
    "\n",
    "    Returns:\n",
    "        The path written to as a string.\n",
    "    \"\"\"\n",
    "    dest = pathlib.Path(dest_path)\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    numeric = df.select_dtypes(include=[\"number\"])\n",
    "    if numeric.shape[1] == 0:\n",
    "        raise ValueError(\"No numeric columns found to place in AnnData.X.\")\n",
    "\n",
    "    non_numeric = df.select_dtypes(exclude=[\"number\"])\n",
    "\n",
    "    adata = ad.AnnData(X=numeric)\n",
    "    adata.obs_names = df.index.astype(str)\n",
    "    adata.var_names = numeric.columns.astype(str)\n",
    "    # Align non-numeric obs metadata to the same index\n",
    "    adata.obs = non_numeric\n",
    "\n",
    "    if write_to == \"h5ad\":\n",
    "        # we default to use None for compression\n",
    "        # meaning no compression.\n",
    "        comp_arg = None\n",
    "        if compression == \"gzip\":\n",
    "            comp_arg = \"gzip\"\n",
    "        elif compression == \"zstd\":\n",
    "            comp_arg = hdf5plugin.FILTERS[\"zstd\"]\n",
    "        elif compression == \"lz4\":\n",
    "            comp_arg = hdf5plugin.FILTERS[\"lz4\"]\n",
    "\n",
    "        adata.write_h5ad(filename=str(dest), compression=comp_arg)\n",
    "    elif write_to == \"zarr\":\n",
    "        # For zarr, the destination is a directory-like store\n",
    "        adata.write_zarr(str(dest))\n",
    "    else:\n",
    "        raise ValueError('write_to must be \"h5ad\" or \"zarr\".')\n",
    "\n",
    "    return str(dest)\n",
    "\n",
    "\n",
    "def read_anndata(\n",
    "    path: str,\n",
    "    read_from: Literal[\"h5ad\", \"zarr\"],\n",
    "    read_one: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load an AnnData file (h5ad or zarr) as a single pandas DataFrame.\n",
    "\n",
    "    The returned DataFrame concatenates ``.obs`` (non-numeric metadata) with\n",
    "    ``X`` converted to a DataFrame using the variable names.\n",
    "\n",
    "    Args:\n",
    "        path:\n",
    "            Str path to the AnnData object. For zarr, this is a directory-like\n",
    "            store; for h5ad, a file path.\n",
    "        read_from:\n",
    "            Input format. Either ``\"h5ad\"`` or ``\"zarr\"``.\n",
    "        read_one:\n",
    "            Whether to read just one column.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame with ``.obs`` columns followed by the numeric\n",
    "        columns from ``X`` (``adata.to_df()``), indexed from 0..n-1.\n",
    "    \"\"\"\n",
    "\n",
    "    if read_from == \"h5ad\":\n",
    "        adata = ad.read_h5ad(path)\n",
    "    elif read_from == \"zarr\":\n",
    "        adata = ad.read_zarr(path)\n",
    "    else:\n",
    "        raise ValueError('read_from must be \"h5ad\" or \"zarr\".')\n",
    "\n",
    "    if read_one:\n",
    "        return adata.to_df()[\"col_2\"]\n",
    "\n",
    "    return adata.obs.join(adata.to_df(), how=\"left\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03f507b9-fe30-45cf-a439-41778124fe00",
   "metadata": {
    "papermill": {
     "duration": 0.242991,
     "end_time": "2025-09-03T21:55:13.758506",
     "exception": false,
     "start_time": "2025-09-03T21:55:13.515515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.154316</td>\n",
       "      <td>0.796868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.737232</td>\n",
       "      <td>0.859234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      col_0     col_1\n",
       "0  0.154316  0.796868\n",
       "1  0.737232  0.859234"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# avoid a \"cold start\" for tested packages by using them before benchmarks\n",
    "df = pd.DataFrame(np.random.rand(2, 2), columns=[f\"col_{num}\" for num in range(0, 2)])\n",
    "# export and read using various methods\n",
    "df.to_csv(path_or_buf=csv_name, compression=\"gzip\")\n",
    "pd.read_csv(filepath_or_buffer=csv_name, compression=\"gzip\")\n",
    "df.to_sql(name=sqlite_tbl_name, con=f\"sqlite:///{sqlite_name}\")\n",
    "pd.read_sql(sql=f\"SELECT * FROM {sqlite_tbl_name}\", con=f\"sqlite:///{sqlite_name}\")\n",
    "df.to_parquet(path=parquet_gzip_name, compression=\"gzip\")\n",
    "pd.read_parquet(path=parquet_gzip_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2bada16-8022-4125-8083-c937e76d914b",
   "metadata": {
    "papermill": {
     "duration": 0.013525,
     "end_time": "2025-09-03T21:55:13.778550",
     "exception": false,
     "start_time": "2025-09-03T21:55:13.765025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove any existing prior work\n",
    "for filename in [csv_name, parquet_gzip_name, sqlite_name]:\n",
    "    pathlib.Path(filename).unlink(missing_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f9eefe2-8379-490c-9977-807b781eb168",
   "metadata": {
    "papermill": {
     "duration": 126.463193,
     "end_time": "2025-09-03T21:57:20.248198",
     "exception": false,
     "start_time": "2025-09-03T21:55:13.785005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(640, 258)\n",
      "(1280, 506)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataframe_shape (rows, cols)</th>\n",
       "      <th>csv_write_time (secs)</th>\n",
       "      <th>csv_size (bytes)</th>\n",
       "      <th>csv_read_time_all (secs)</th>\n",
       "      <th>csv_read_time_one (secs)</th>\n",
       "      <th>sqlite_write_time (secs)</th>\n",
       "      <th>sqlite_size (bytes)</th>\n",
       "      <th>sqlite_read_time_all (secs)</th>\n",
       "      <th>sqlite_read_time_one (secs)</th>\n",
       "      <th>anndata_h5ad_noc_write_time (secs)</th>\n",
       "      <th>...</th>\n",
       "      <th>parquet_gzip_read_time_all (secs)</th>\n",
       "      <th>parquet_gzip_read_time_one (secs)</th>\n",
       "      <th>parquet_zstd_write_time (secs)</th>\n",
       "      <th>parquet_zstd_size (bytes)</th>\n",
       "      <th>parquet_zstd_read_time_all (secs)</th>\n",
       "      <th>parquet_zstd_read_time_one (secs)</th>\n",
       "      <th>parquet_lz4_write_time (secs)</th>\n",
       "      <th>parquet_lz4_size (bytes)</th>\n",
       "      <th>parquet_lz4_read_time_all (secs)</th>\n",
       "      <th>parquet_lz4_read_time_one (secs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(640, 258)</td>\n",
       "      <td>0.355772</td>\n",
       "      <td>1396284</td>\n",
       "      <td>0.023583</td>\n",
       "      <td>0.012523</td>\n",
       "      <td>0.060731</td>\n",
       "      <td>2654208</td>\n",
       "      <td>0.018013</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>0.009688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028125</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.028946</td>\n",
       "      <td>1544136</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>0.014473</td>\n",
       "      <td>1614683</td>\n",
       "      <td>0.011104</td>\n",
       "      <td>0.002812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(640, 258)</td>\n",
       "      <td>0.373457</td>\n",
       "      <td>1396284</td>\n",
       "      <td>0.021033</td>\n",
       "      <td>0.013035</td>\n",
       "      <td>0.089561</td>\n",
       "      <td>2654208</td>\n",
       "      <td>0.019476</td>\n",
       "      <td>0.001774</td>\n",
       "      <td>0.009084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012556</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.017807</td>\n",
       "      <td>1544136</td>\n",
       "      <td>0.010388</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.013382</td>\n",
       "      <td>1614683</td>\n",
       "      <td>0.009761</td>\n",
       "      <td>0.002479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(640, 258)</td>\n",
       "      <td>0.415735</td>\n",
       "      <td>1396284</td>\n",
       "      <td>0.022612</td>\n",
       "      <td>0.016394</td>\n",
       "      <td>0.064994</td>\n",
       "      <td>2654208</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0.013014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018105</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.017724</td>\n",
       "      <td>1544136</td>\n",
       "      <td>0.013265</td>\n",
       "      <td>0.002813</td>\n",
       "      <td>0.015310</td>\n",
       "      <td>1614683</td>\n",
       "      <td>0.019062</td>\n",
       "      <td>0.002693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(640, 258)</td>\n",
       "      <td>0.368796</td>\n",
       "      <td>1396284</td>\n",
       "      <td>0.022502</td>\n",
       "      <td>0.014335</td>\n",
       "      <td>0.062763</td>\n",
       "      <td>2654208</td>\n",
       "      <td>0.023040</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>0.012158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021093</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>0.017088</td>\n",
       "      <td>1544136</td>\n",
       "      <td>0.016057</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.014475</td>\n",
       "      <td>1614683</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>0.002633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1280, 506)</td>\n",
       "      <td>1.524452</td>\n",
       "      <td>5570451</td>\n",
       "      <td>0.076728</td>\n",
       "      <td>0.053763</td>\n",
       "      <td>0.252394</td>\n",
       "      <td>5935104</td>\n",
       "      <td>0.390468</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.016109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022171</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>0.054853</td>\n",
       "      <td>5940887</td>\n",
       "      <td>0.022449</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>0.034645</td>\n",
       "      <td>6254022</td>\n",
       "      <td>0.028063</td>\n",
       "      <td>0.005024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1280, 506)</td>\n",
       "      <td>1.440919</td>\n",
       "      <td>5570451</td>\n",
       "      <td>0.069477</td>\n",
       "      <td>0.047721</td>\n",
       "      <td>0.213947</td>\n",
       "      <td>5935104</td>\n",
       "      <td>0.322420</td>\n",
       "      <td>0.007824</td>\n",
       "      <td>0.010158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051263</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>0.040757</td>\n",
       "      <td>5940887</td>\n",
       "      <td>0.023910</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.034287</td>\n",
       "      <td>6254022</td>\n",
       "      <td>0.018256</td>\n",
       "      <td>0.004432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(1280, 506)</td>\n",
       "      <td>1.671773</td>\n",
       "      <td>5570451</td>\n",
       "      <td>0.076862</td>\n",
       "      <td>0.056179</td>\n",
       "      <td>0.229379</td>\n",
       "      <td>5935104</td>\n",
       "      <td>0.362107</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.012154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025916</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.049272</td>\n",
       "      <td>5940887</td>\n",
       "      <td>0.021582</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.036969</td>\n",
       "      <td>6254022</td>\n",
       "      <td>0.021805</td>\n",
       "      <td>0.005103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1280, 506)</td>\n",
       "      <td>1.707333</td>\n",
       "      <td>5570451</td>\n",
       "      <td>0.072484</td>\n",
       "      <td>0.052590</td>\n",
       "      <td>0.267593</td>\n",
       "      <td>5935104</td>\n",
       "      <td>0.344293</td>\n",
       "      <td>0.003363</td>\n",
       "      <td>0.010884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021979</td>\n",
       "      <td>0.004538</td>\n",
       "      <td>0.040599</td>\n",
       "      <td>5940887</td>\n",
       "      <td>0.019143</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>0.034367</td>\n",
       "      <td>6254022</td>\n",
       "      <td>0.021142</td>\n",
       "      <td>0.004879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataframe_shape (rows, cols)  csv_write_time (secs)  csv_size (bytes)  \\\n",
       "0                   (640, 258)               0.355772           1396284   \n",
       "1                   (640, 258)               0.373457           1396284   \n",
       "2                   (640, 258)               0.415735           1396284   \n",
       "3                   (640, 258)               0.368796           1396284   \n",
       "4                  (1280, 506)               1.524452           5570451   \n",
       "5                  (1280, 506)               1.440919           5570451   \n",
       "6                  (1280, 506)               1.671773           5570451   \n",
       "7                  (1280, 506)               1.707333           5570451   \n",
       "\n",
       "   csv_read_time_all (secs)  csv_read_time_one (secs)  \\\n",
       "0                  0.023583                  0.012523   \n",
       "1                  0.021033                  0.013035   \n",
       "2                  0.022612                  0.016394   \n",
       "3                  0.022502                  0.014335   \n",
       "4                  0.076728                  0.053763   \n",
       "5                  0.069477                  0.047721   \n",
       "6                  0.076862                  0.056179   \n",
       "7                  0.072484                  0.052590   \n",
       "\n",
       "   sqlite_write_time (secs)  sqlite_size (bytes)  sqlite_read_time_all (secs)  \\\n",
       "0                  0.060731              2654208                     0.018013   \n",
       "1                  0.089561              2654208                     0.019476   \n",
       "2                  0.064994              2654208                     0.025093   \n",
       "3                  0.062763              2654208                     0.023040   \n",
       "4                  0.252394              5935104                     0.390468   \n",
       "5                  0.213947              5935104                     0.322420   \n",
       "6                  0.229379              5935104                     0.362107   \n",
       "7                  0.267593              5935104                     0.344293   \n",
       "\n",
       "   sqlite_read_time_one (secs)  anndata_h5ad_noc_write_time (secs)  ...  \\\n",
       "0                     0.001717                            0.009688  ...   \n",
       "1                     0.001774                            0.009084  ...   \n",
       "2                     0.002818                            0.013014  ...   \n",
       "3                     0.002444                            0.012158  ...   \n",
       "4                     0.004775                            0.016109  ...   \n",
       "5                     0.007824                            0.010158  ...   \n",
       "6                     0.003811                            0.012154  ...   \n",
       "7                     0.003363                            0.010884  ...   \n",
       "\n",
       "   parquet_gzip_read_time_all (secs)  parquet_gzip_read_time_one (secs)  \\\n",
       "0                           0.028125                           0.002779   \n",
       "1                           0.012556                           0.002649   \n",
       "2                           0.018105                           0.003096   \n",
       "3                           0.021093                           0.003093   \n",
       "4                           0.022171                           0.005242   \n",
       "5                           0.051263                           0.005441   \n",
       "6                           0.025916                           0.004868   \n",
       "7                           0.021979                           0.004538   \n",
       "\n",
       "   parquet_zstd_write_time (secs)  parquet_zstd_size (bytes)  \\\n",
       "0                        0.028946                    1544136   \n",
       "1                        0.017807                    1544136   \n",
       "2                        0.017724                    1544136   \n",
       "3                        0.017088                    1544136   \n",
       "4                        0.054853                    5940887   \n",
       "5                        0.040757                    5940887   \n",
       "6                        0.049272                    5940887   \n",
       "7                        0.040599                    5940887   \n",
       "\n",
       "   parquet_zstd_read_time_all (secs)  parquet_zstd_read_time_one (secs)  \\\n",
       "0                           0.010563                           0.002736   \n",
       "1                           0.010388                           0.002704   \n",
       "2                           0.013265                           0.002813   \n",
       "3                           0.016057                           0.002801   \n",
       "4                           0.022449                           0.004629   \n",
       "5                           0.023910                           0.004431   \n",
       "6                           0.021582                           0.004972   \n",
       "7                           0.019143                           0.004661   \n",
       "\n",
       "   parquet_lz4_write_time (secs)  parquet_lz4_size (bytes)  \\\n",
       "0                       0.014473                   1614683   \n",
       "1                       0.013382                   1614683   \n",
       "2                       0.015310                   1614683   \n",
       "3                       0.014475                   1614683   \n",
       "4                       0.034645                   6254022   \n",
       "5                       0.034287                   6254022   \n",
       "6                       0.036969                   6254022   \n",
       "7                       0.034367                   6254022   \n",
       "\n",
       "   parquet_lz4_read_time_all (secs)  parquet_lz4_read_time_one (secs)  \n",
       "0                          0.011104                          0.002812  \n",
       "1                          0.009761                          0.002479  \n",
       "2                          0.019062                          0.002693  \n",
       "3                          0.016393                          0.002633  \n",
       "4                          0.028063                          0.005024  \n",
       "5                          0.018256                          0.004432  \n",
       "6                          0.021805                          0.005103  \n",
       "7                          0.021142                          0.004879  \n",
       "\n",
       "[8 rows x 49 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n",
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/davebunten/.pyenv/versions/3.12.5/lib/python3.12/functools.py:907: ImplicitModificationWarning: Transforming to str index.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataframe_shape (rows, cols)</th>\n",
       "      <th>csv_write_time (secs)</th>\n",
       "      <th>csv_size (bytes)</th>\n",
       "      <th>csv_read_time_all (secs)</th>\n",
       "      <th>csv_read_time_one (secs)</th>\n",
       "      <th>sqlite_write_time (secs)</th>\n",
       "      <th>sqlite_size (bytes)</th>\n",
       "      <th>sqlite_read_time_all (secs)</th>\n",
       "      <th>sqlite_read_time_one (secs)</th>\n",
       "      <th>anndata_h5ad_write_time (secs)</th>\n",
       "      <th>anndata_h5ad_size (bytes)</th>\n",
       "      <th>anndata_h5ad_read_time_all (secs)</th>\n",
       "      <th>anndata_zarr_write_time (secs)</th>\n",
       "      <th>anndata_zarr_size (bytes)</th>\n",
       "      <th>anndata_zarr_read_time_all (secs)</th>\n",
       "      <th>parquet_write_time (secs)</th>\n",
       "      <th>parquet_size (bytes)</th>\n",
       "      <th>parquet_read_time_all (secs)</th>\n",
       "      <th>parquet_read_time_one (secs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(640, 320)</td>\n",
       "      <td>0.842291</td>\n",
       "      <td>1796776</td>\n",
       "      <td>0.051321</td>\n",
       "      <td>0.033486</td>\n",
       "      <td>0.292911</td>\n",
       "      <td>2654208</td>\n",
       "      <td>0.081895</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>0.015043</td>\n",
       "      <td>1689464</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>0.200134</td>\n",
       "      <td>1444205</td>\n",
       "      <td>0.024827</td>\n",
       "      <td>0.122654</td>\n",
       "      <td>1996960</td>\n",
       "      <td>0.040673</td>\n",
       "      <td>0.009489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(640, 320)</td>\n",
       "      <td>0.806049</td>\n",
       "      <td>1796776</td>\n",
       "      <td>0.049559</td>\n",
       "      <td>0.037302</td>\n",
       "      <td>0.281395</td>\n",
       "      <td>2654208</td>\n",
       "      <td>0.158389</td>\n",
       "      <td>0.004061</td>\n",
       "      <td>0.013186</td>\n",
       "      <td>1689464</td>\n",
       "      <td>0.008883</td>\n",
       "      <td>0.269879</td>\n",
       "      <td>1444205</td>\n",
       "      <td>0.025537</td>\n",
       "      <td>0.121052</td>\n",
       "      <td>1996960</td>\n",
       "      <td>0.040905</td>\n",
       "      <td>0.010552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(640, 320)</td>\n",
       "      <td>0.811007</td>\n",
       "      <td>1796776</td>\n",
       "      <td>0.050351</td>\n",
       "      <td>0.037784</td>\n",
       "      <td>0.289146</td>\n",
       "      <td>2654208</td>\n",
       "      <td>0.080007</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.013334</td>\n",
       "      <td>1689464</td>\n",
       "      <td>0.009278</td>\n",
       "      <td>0.224012</td>\n",
       "      <td>1444205</td>\n",
       "      <td>0.023597</td>\n",
       "      <td>0.118297</td>\n",
       "      <td>1996960</td>\n",
       "      <td>0.047455</td>\n",
       "      <td>0.008890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(640, 320)</td>\n",
       "      <td>2.815953</td>\n",
       "      <td>1796776</td>\n",
       "      <td>0.050481</td>\n",
       "      <td>0.037987</td>\n",
       "      <td>0.287124</td>\n",
       "      <td>2654208</td>\n",
       "      <td>0.078846</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>0.013307</td>\n",
       "      <td>1689464</td>\n",
       "      <td>0.008762</td>\n",
       "      <td>0.203730</td>\n",
       "      <td>1444205</td>\n",
       "      <td>0.018752</td>\n",
       "      <td>0.118394</td>\n",
       "      <td>1996960</td>\n",
       "      <td>0.046874</td>\n",
       "      <td>0.010313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1280, 640)</td>\n",
       "      <td>3.218594</td>\n",
       "      <td>7177156</td>\n",
       "      <td>0.187479</td>\n",
       "      <td>0.135454</td>\n",
       "      <td>0.975879</td>\n",
       "      <td>7909376</td>\n",
       "      <td>0.321715</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>0.023874</td>\n",
       "      <td>6648696</td>\n",
       "      <td>0.013905</td>\n",
       "      <td>0.211492</td>\n",
       "      <td>5752196</td>\n",
       "      <td>0.032643</td>\n",
       "      <td>0.310097</td>\n",
       "      <td>7686116</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>0.021087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1280, 640)</td>\n",
       "      <td>3.231007</td>\n",
       "      <td>7177156</td>\n",
       "      <td>0.171248</td>\n",
       "      <td>0.117120</td>\n",
       "      <td>1.004868</td>\n",
       "      <td>7909376</td>\n",
       "      <td>0.387579</td>\n",
       "      <td>0.005156</td>\n",
       "      <td>0.024271</td>\n",
       "      <td>6648696</td>\n",
       "      <td>0.019610</td>\n",
       "      <td>0.219477</td>\n",
       "      <td>5752196</td>\n",
       "      <td>0.036041</td>\n",
       "      <td>0.321031</td>\n",
       "      <td>7686116</td>\n",
       "      <td>0.073183</td>\n",
       "      <td>0.016686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(1280, 640)</td>\n",
       "      <td>3.278998</td>\n",
       "      <td>7177156</td>\n",
       "      <td>0.185984</td>\n",
       "      <td>0.137208</td>\n",
       "      <td>0.992581</td>\n",
       "      <td>7909376</td>\n",
       "      <td>0.315881</td>\n",
       "      <td>0.005491</td>\n",
       "      <td>0.024930</td>\n",
       "      <td>6648696</td>\n",
       "      <td>0.014585</td>\n",
       "      <td>0.232451</td>\n",
       "      <td>5752196</td>\n",
       "      <td>0.044017</td>\n",
       "      <td>0.423086</td>\n",
       "      <td>7686116</td>\n",
       "      <td>0.075099</td>\n",
       "      <td>0.021984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1280, 640)</td>\n",
       "      <td>3.257791</td>\n",
       "      <td>7177156</td>\n",
       "      <td>0.183664</td>\n",
       "      <td>0.134662</td>\n",
       "      <td>0.929014</td>\n",
       "      <td>7909376</td>\n",
       "      <td>0.317495</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.023940</td>\n",
       "      <td>6648696</td>\n",
       "      <td>0.014066</td>\n",
       "      <td>0.263685</td>\n",
       "      <td>5752196</td>\n",
       "      <td>0.039005</td>\n",
       "      <td>0.326676</td>\n",
       "      <td>7686116</td>\n",
       "      <td>0.080990</td>\n",
       "      <td>0.025437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(2560, 1280)</td>\n",
       "      <td>12.867960</td>\n",
       "      <td>28692830</td>\n",
       "      <td>0.687113</td>\n",
       "      <td>0.422292</td>\n",
       "      <td>5.484956</td>\n",
       "      <td>31543296</td>\n",
       "      <td>1.218488</td>\n",
       "      <td>0.010993</td>\n",
       "      <td>0.073147</td>\n",
       "      <td>26389368</td>\n",
       "      <td>0.036874</td>\n",
       "      <td>0.314813</td>\n",
       "      <td>22974236</td>\n",
       "      <td>0.110739</td>\n",
       "      <td>1.242740</td>\n",
       "      <td>30261412</td>\n",
       "      <td>0.175512</td>\n",
       "      <td>0.029622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2560, 1280)</td>\n",
       "      <td>13.161694</td>\n",
       "      <td>28692830</td>\n",
       "      <td>2.615864</td>\n",
       "      <td>0.437876</td>\n",
       "      <td>3.852527</td>\n",
       "      <td>31543296</td>\n",
       "      <td>1.231781</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>0.074586</td>\n",
       "      <td>26389368</td>\n",
       "      <td>0.037749</td>\n",
       "      <td>0.331743</td>\n",
       "      <td>22974236</td>\n",
       "      <td>0.085215</td>\n",
       "      <td>1.134063</td>\n",
       "      <td>30261412</td>\n",
       "      <td>0.166437</td>\n",
       "      <td>0.029078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(2560, 1280)</td>\n",
       "      <td>12.913457</td>\n",
       "      <td>28692830</td>\n",
       "      <td>0.645691</td>\n",
       "      <td>0.413389</td>\n",
       "      <td>3.688710</td>\n",
       "      <td>31543296</td>\n",
       "      <td>1.238714</td>\n",
       "      <td>0.011256</td>\n",
       "      <td>0.073416</td>\n",
       "      <td>26389368</td>\n",
       "      <td>0.036288</td>\n",
       "      <td>0.249354</td>\n",
       "      <td>22974236</td>\n",
       "      <td>0.069744</td>\n",
       "      <td>1.256516</td>\n",
       "      <td>30261412</td>\n",
       "      <td>0.159020</td>\n",
       "      <td>0.031087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(2560, 1280)</td>\n",
       "      <td>14.904914</td>\n",
       "      <td>28692830</td>\n",
       "      <td>0.680170</td>\n",
       "      <td>0.431732</td>\n",
       "      <td>3.525048</td>\n",
       "      <td>31543296</td>\n",
       "      <td>1.344094</td>\n",
       "      <td>0.012983</td>\n",
       "      <td>0.971748</td>\n",
       "      <td>26389368</td>\n",
       "      <td>2.071073</td>\n",
       "      <td>0.266843</td>\n",
       "      <td>22974236</td>\n",
       "      <td>1.205168</td>\n",
       "      <td>1.111896</td>\n",
       "      <td>30261412</td>\n",
       "      <td>0.123399</td>\n",
       "      <td>0.040086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataframe_shape (rows, cols)  csv_write_time (secs)  csv_size (bytes)  \\\n",
       "0                    (640, 320)               0.842291           1796776   \n",
       "1                    (640, 320)               0.806049           1796776   \n",
       "2                    (640, 320)               0.811007           1796776   \n",
       "3                    (640, 320)               2.815953           1796776   \n",
       "4                   (1280, 640)               3.218594           7177156   \n",
       "5                   (1280, 640)               3.231007           7177156   \n",
       "6                   (1280, 640)               3.278998           7177156   \n",
       "7                   (1280, 640)               3.257791           7177156   \n",
       "8                  (2560, 1280)              12.867960          28692830   \n",
       "9                  (2560, 1280)              13.161694          28692830   \n",
       "10                 (2560, 1280)              12.913457          28692830   \n",
       "11                 (2560, 1280)              14.904914          28692830   \n",
       "\n",
       "    csv_read_time_all (secs)  csv_read_time_one (secs)  \\\n",
       "0                   0.051321                  0.033486   \n",
       "1                   0.049559                  0.037302   \n",
       "2                   0.050351                  0.037784   \n",
       "3                   0.050481                  0.037987   \n",
       "4                   0.187479                  0.135454   \n",
       "5                   0.171248                  0.117120   \n",
       "6                   0.185984                  0.137208   \n",
       "7                   0.183664                  0.134662   \n",
       "8                   0.687113                  0.422292   \n",
       "9                   2.615864                  0.437876   \n",
       "10                  0.645691                  0.413389   \n",
       "11                  0.680170                  0.431732   \n",
       "\n",
       "    sqlite_write_time (secs)  sqlite_size (bytes)  \\\n",
       "0                   0.292911              2654208   \n",
       "1                   0.281395              2654208   \n",
       "2                   0.289146              2654208   \n",
       "3                   0.287124              2654208   \n",
       "4                   0.975879              7909376   \n",
       "5                   1.004868              7909376   \n",
       "6                   0.992581              7909376   \n",
       "7                   0.929014              7909376   \n",
       "8                   5.484956             31543296   \n",
       "9                   3.852527             31543296   \n",
       "10                  3.688710             31543296   \n",
       "11                  3.525048             31543296   \n",
       "\n",
       "    sqlite_read_time_all (secs)  sqlite_read_time_one (secs)  \\\n",
       "0                      0.081895                     0.004012   \n",
       "1                      0.158389                     0.004061   \n",
       "2                      0.080007                     0.004056   \n",
       "3                      0.078846                     0.004096   \n",
       "4                      0.321715                     0.005191   \n",
       "5                      0.387579                     0.005156   \n",
       "6                      0.315881                     0.005491   \n",
       "7                      0.317495                     0.005261   \n",
       "8                      1.218488                     0.010993   \n",
       "9                      1.231781                     0.011333   \n",
       "10                     1.238714                     0.011256   \n",
       "11                     1.344094                     0.012983   \n",
       "\n",
       "    anndata_h5ad_write_time (secs)  anndata_h5ad_size (bytes)  \\\n",
       "0                         0.015043                    1689464   \n",
       "1                         0.013186                    1689464   \n",
       "2                         0.013334                    1689464   \n",
       "3                         0.013307                    1689464   \n",
       "4                         0.023874                    6648696   \n",
       "5                         0.024271                    6648696   \n",
       "6                         0.024930                    6648696   \n",
       "7                         0.023940                    6648696   \n",
       "8                         0.073147                   26389368   \n",
       "9                         0.074586                   26389368   \n",
       "10                        0.073416                   26389368   \n",
       "11                        0.971748                   26389368   \n",
       "\n",
       "    anndata_h5ad_read_time_all (secs)  anndata_zarr_write_time (secs)  \\\n",
       "0                            0.009666                        0.200134   \n",
       "1                            0.008883                        0.269879   \n",
       "2                            0.009278                        0.224012   \n",
       "3                            0.008762                        0.203730   \n",
       "4                            0.013905                        0.211492   \n",
       "5                            0.019610                        0.219477   \n",
       "6                            0.014585                        0.232451   \n",
       "7                            0.014066                        0.263685   \n",
       "8                            0.036874                        0.314813   \n",
       "9                            0.037749                        0.331743   \n",
       "10                           0.036288                        0.249354   \n",
       "11                           2.071073                        0.266843   \n",
       "\n",
       "    anndata_zarr_size (bytes)  anndata_zarr_read_time_all (secs)  \\\n",
       "0                     1444205                           0.024827   \n",
       "1                     1444205                           0.025537   \n",
       "2                     1444205                           0.023597   \n",
       "3                     1444205                           0.018752   \n",
       "4                     5752196                           0.032643   \n",
       "5                     5752196                           0.036041   \n",
       "6                     5752196                           0.044017   \n",
       "7                     5752196                           0.039005   \n",
       "8                    22974236                           0.110739   \n",
       "9                    22974236                           0.085215   \n",
       "10                   22974236                           0.069744   \n",
       "11                   22974236                           1.205168   \n",
       "\n",
       "    parquet_write_time (secs)  parquet_size (bytes)  \\\n",
       "0                    0.122654               1996960   \n",
       "1                    0.121052               1996960   \n",
       "2                    0.118297               1996960   \n",
       "3                    0.118394               1996960   \n",
       "4                    0.310097               7686116   \n",
       "5                    0.321031               7686116   \n",
       "6                    0.423086               7686116   \n",
       "7                    0.326676               7686116   \n",
       "8                    1.242740              30261412   \n",
       "9                    1.134063              30261412   \n",
       "10                   1.256516              30261412   \n",
       "11                   1.111896              30261412   \n",
       "\n",
       "    parquet_read_time_all (secs)  parquet_read_time_one (secs)  \n",
       "0                       0.040673                      0.009489  \n",
       "1                       0.040905                      0.010552  \n",
       "2                       0.047455                      0.008890  \n",
       "3                       0.046874                      0.010313  \n",
       "4                       0.082800                      0.021087  \n",
       "5                       0.073183                      0.016686  \n",
       "6                       0.075099                      0.021984  \n",
       "7                       0.080990                      0.025437  \n",
       "8                       0.175512                      0.029622  \n",
       "9                       0.166437                      0.029078  \n",
       "10                      0.159020                      0.031087  \n",
       "11                      0.123399                      0.040086  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# starting rowcount and col count\n",
    "nrows = 320\n",
    "ncols = 124\n",
    "\n",
    "# result list for storing data\n",
    "results = []\n",
    "\n",
    "# loop for iterating over increasingly large dataframes\n",
    "# and gathering data about operations on them\n",
    "for _ in range(1, 6):\n",
    "    # increase the size of the dataframe\n",
    "    nrows *= 2\n",
    "    ncols *= 2\n",
    "\n",
    "    # form a dataframe using randomized data\n",
    "    df = pd.DataFrame(\n",
    "        np.random.rand(nrows, ncols), columns=[f\"col_{num}\" for num in range(0, ncols)]\n",
    "    )\n",
    "\n",
    "    # add some string data\n",
    "    alphabet = np.array(list(string.ascii_lowercase + string.digits))\n",
    "    df = df.assign(\n",
    "        **{\n",
    "            f\"str_{i+1}\": [\n",
    "                \"\".join(np.random.default_rng(10).choice(alphabet, 10))\n",
    "                for _ in range(len(df))\n",
    "            ]\n",
    "            for i in range(10)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(df.shape)\n",
    "\n",
    "    # run multiple times for error and average\n",
    "    for _ in range(1, 5):\n",
    "        # remove any existing files in preparation for next steps\n",
    "        remove_files()\n",
    "        # append data to the result list\n",
    "        results.append(\n",
    "            {\n",
    "                # general information about the dataframe\n",
    "                \"dataframe_shape (rows, cols)\": str(df.shape),\n",
    "                # information about CSV (uncompressed)\n",
    "                \"csv_write_time (secs)\": timer(\n",
    "                    df.to_csv, path_or_buf=csv_name, compression=\"gzip\"\n",
    "                ),\n",
    "                \"csv_size (bytes)\": os.stat(csv_name).st_size,\n",
    "                \"csv_read_time_all (secs)\": timer(\n",
    "                    pd.read_csv, filepath_or_buffer=csv_name, compression=\"gzip\"\n",
    "                ),\n",
    "                \"csv_read_time_one (secs)\": timer(\n",
    "                    pd.read_csv,\n",
    "                    filepath_or_buffer=csv_name,\n",
    "                    compression=\"gzip\",\n",
    "                    usecols=[\"col_2\"],\n",
    "                ),\n",
    "                # information about SQLite\n",
    "                \"sqlite_write_time (secs)\": (\n",
    "                    timer(\n",
    "                        df.to_sql,\n",
    "                        name=sqlite_tbl_name,\n",
    "                        con=f\"sqlite:///{sqlite_name}\",\n",
    "                    )\n",
    "                    if ncols < 2000\n",
    "                    else None\n",
    "                ),\n",
    "                \"sqlite_size (bytes)\": (\n",
    "                    os.stat(sqlite_name).st_size if ncols < 2000 else None\n",
    "                ),\n",
    "                \"sqlite_read_time_all (secs)\": (\n",
    "                    timer(\n",
    "                        pd.read_sql,\n",
    "                        sql=f\"SELECT * FROM {sqlite_tbl_name}\",\n",
    "                        con=f\"sqlite:///{sqlite_name}\",\n",
    "                    )\n",
    "                    if ncols < 2000\n",
    "                    else None\n",
    "                ),\n",
    "                \"sqlite_read_time_one (secs)\": (\n",
    "                    timer(\n",
    "                        pd.read_sql,\n",
    "                        sql=f\"SELECT col_2 FROM {sqlite_tbl_name}\",\n",
    "                        con=f\"sqlite:///{sqlite_name}\",\n",
    "                    )\n",
    "                    if ncols < 2000\n",
    "                    else None\n",
    "                ),\n",
    "                # information about anndata h5ad (no compression)\n",
    "                \"anndata_h5ad_noc_write_time (secs)\": timer(\n",
    "                    write_anndata,\n",
    "                    df=df,\n",
    "                    write_to=\"h5ad\",\n",
    "                    compression=\"none\",\n",
    "                    dest_path=anndata_h5_noc_name,\n",
    "                ),\n",
    "                \"anndata_h5ad_noc_size (bytes)\": os.stat(anndata_h5_noc_name).st_size,\n",
    "                \"anndata_h5ad_noc_read_time_all (secs)\": timer(\n",
    "                    read_anndata,\n",
    "                    path=anndata_h5_noc_name,\n",
    "                    read_from=\"h5ad\",\n",
    "                    read_one=False,\n",
    "                ),\n",
    "                \"anndata_h5ad_noc_read_time_one (secs)\": timer(\n",
    "                    read_anndata,\n",
    "                    path=anndata_h5_noc_name,\n",
    "                    read_from=\"h5ad\",\n",
    "                    read_one=True,\n",
    "                ),\n",
    "                # information about anndata h5ad (gzip)\n",
    "                \"anndata_h5ad_gzip_write_time (secs)\": timer(\n",
    "                    write_anndata,\n",
    "                    df=df,\n",
    "                    write_to=\"h5ad\",\n",
    "                    compression=\"gzip\",\n",
    "                    dest_path=anndata_h5_gzip_name,\n",
    "                ),\n",
    "                \"anndata_h5ad_gzip_size (bytes)\": os.stat(anndata_h5_gzip_name).st_size,\n",
    "                \"anndata_h5ad_gzip_read_time_all (secs)\": timer(\n",
    "                    read_anndata,\n",
    "                    path=anndata_h5_gzip_name,\n",
    "                    read_from=\"h5ad\",\n",
    "                    read_one=False,\n",
    "                ),\n",
    "                \"anndata_h5ad_gzip_read_time_one (secs)\": timer(\n",
    "                    read_anndata,\n",
    "                    path=anndata_h5_gzip_name,\n",
    "                    read_from=\"h5ad\",\n",
    "                    read_one=True,\n",
    "                ),\n",
    "                # information about anndata h5ad (lz4)\n",
    "                \"anndata_h5ad_lz4_write_time (secs)\": timer(\n",
    "                    write_anndata,\n",
    "                    df=df,\n",
    "                    write_to=\"h5ad\",\n",
    "                    compression=\"lz4\",\n",
    "                    dest_path=anndata_h5_lz4_name,\n",
    "                ),\n",
    "                \"anndata_h5ad_lz4_size (bytes)\": os.stat(anndata_h5_lz4_name).st_size,\n",
    "                \"anndata_h5ad_lz4_read_time_all (secs)\": timer(\n",
    "                    read_anndata,\n",
    "                    path=anndata_h5_lz4_name,\n",
    "                    read_from=\"h5ad\",\n",
    "                    read_one=False,\n",
    "                ),\n",
    "                \"anndata_h5ad_lz4_read_time_one (secs)\": timer(\n",
    "                    read_anndata,\n",
    "                    path=anndata_h5_lz4_name,\n",
    "                    read_from=\"h5ad\",\n",
    "                    read_one=True,\n",
    "                ),\n",
    "                # information about anndata h5ad (zstd)\n",
    "                \"anndata_h5ad_zstd_write_time (secs)\": timer(\n",
    "                    write_anndata,\n",
    "                    df=df,\n",
    "                    write_to=\"h5ad\",\n",
    "                    compression=\"zstd\",\n",
    "                    dest_path=anndata_h5_zstd_name,\n",
    "                ),\n",
    "                \"anndata_h5ad_zstd_size (bytes)\": os.stat(anndata_h5_zstd_name).st_size,\n",
    "                \"anndata_h5ad_zstd_read_time_all (secs)\": timer(\n",
    "                    read_anndata,\n",
    "                    path=anndata_h5_zstd_name,\n",
    "                    read_from=\"h5ad\",\n",
    "                    read_one=False,\n",
    "                ),\n",
    "                \"anndata_h5ad_zstd_read_time_one (secs)\": timer(\n",
    "                    read_anndata,\n",
    "                    path=anndata_h5_zstd_name,\n",
    "                    read_from=\"h5ad\",\n",
    "                    read_one=True,\n",
    "                ),\n",
    "                # information about anndata zarr\n",
    "                \"anndata_zarr_write_time (secs)\": timer(\n",
    "                    write_anndata,\n",
    "                    df=df,\n",
    "                    write_to=\"zarr\",\n",
    "                    compression=\"none\",\n",
    "                    dest_path=anndata_zarr_name,\n",
    "                ),\n",
    "                # note: we use a comprehension below to recurse through\n",
    "                # the zarr directory for a true estimate of size.\n",
    "                \"anndata_zarr_size (bytes)\": sum(\n",
    "                    f.stat().st_size\n",
    "                    for f in pathlib.Path(anndata_zarr_name).rglob(\"**/*\")\n",
    "                    if f.is_file()\n",
    "                ),\n",
    "                \"anndata_zarr_read_time_all (secs)\": timer(\n",
    "                    read_anndata,\n",
    "                    path=anndata_zarr_name,\n",
    "                    read_from=\"zarr\",\n",
    "                    read_one=False,\n",
    "                ),\n",
    "                \"anndata_zarr_read_time_one (secs)\": timer(\n",
    "                    read_anndata,\n",
    "                    path=anndata_zarr_name,\n",
    "                    read_from=\"zarr\",\n",
    "                    read_one=True,\n",
    "                ),\n",
    "                # information about Parquet with no compression\n",
    "                \"parquet_noc_write_time (secs)\": timer(\n",
    "                    df.to_parquet, path=parquet_noc_name, compression=None\n",
    "                ),\n",
    "                \"parquet_noc_size (bytes)\": os.stat(parquet_noc_name).st_size,\n",
    "                \"parquet_noc_read_time_all (secs)\": timer(\n",
    "                    pd.read_parquet, path=parquet_noc_name\n",
    "                ),\n",
    "                \"parquet_noc_read_time_one (secs)\": timer(\n",
    "                    pd.read_parquet, path=parquet_noc_name, columns=[\"col_2\"]\n",
    "                ),\n",
    "                # information about Parquet with snappy compression\n",
    "                \"parquet_snappy_write_time (secs)\": timer(\n",
    "                    df.to_parquet, path=parquet_snappy_name, compression=\"snappy\"\n",
    "                ),\n",
    "                \"parquet_snappy_size (bytes)\": os.stat(parquet_snappy_name).st_size,\n",
    "                \"parquet_snappy_read_time_all (secs)\": timer(\n",
    "                    pd.read_parquet, path=parquet_snappy_name\n",
    "                ),\n",
    "                \"parquet_snappy_read_time_one (secs)\": timer(\n",
    "                    pd.read_parquet, path=parquet_snappy_name, columns=[\"col_2\"]\n",
    "                ),\n",
    "                # information about Parquet with gzip compression\n",
    "                \"parquet_gzip_write_time (secs)\": timer(\n",
    "                    df.to_parquet, path=parquet_gzip_name, compression=\"gzip\"\n",
    "                ),\n",
    "                \"parquet_gzip_size (bytes)\": os.stat(parquet_gzip_name).st_size,\n",
    "                \"parquet_gzip_read_time_all (secs)\": timer(\n",
    "                    pd.read_parquet, path=parquet_gzip_name\n",
    "                ),\n",
    "                \"parquet_gzip_read_time_one (secs)\": timer(\n",
    "                    pd.read_parquet, path=parquet_gzip_name, columns=[\"col_2\"]\n",
    "                ),\n",
    "                # information about Parquet with zstd compression\n",
    "                \"parquet_zstd_write_time (secs)\": timer(\n",
    "                    df.to_parquet, path=parquet_zstd_name, compression=\"zstd\"\n",
    "                ),\n",
    "                \"parquet_zstd_size (bytes)\": os.stat(parquet_zstd_name).st_size,\n",
    "                \"parquet_zstd_read_time_all (secs)\": timer(\n",
    "                    pd.read_parquet, path=parquet_zstd_name\n",
    "                ),\n",
    "                \"parquet_zstd_read_time_one (secs)\": timer(\n",
    "                    pd.read_parquet, path=parquet_zstd_name, columns=[\"col_2\"]\n",
    "                ),\n",
    "                # information about Parquet with lz4 compression\n",
    "                \"parquet_lz4_write_time (secs)\": timer(\n",
    "                    df.to_parquet, path=parquet_lz4_name, compression=\"lz4\"\n",
    "                ),\n",
    "                \"parquet_lz4_size (bytes)\": os.stat(parquet_lz4_name).st_size,\n",
    "                \"parquet_lz4_read_time_all (secs)\": timer(\n",
    "                    pd.read_parquet, path=parquet_lz4_name\n",
    "                ),\n",
    "                \"parquet_lz4_read_time_one (secs)\": timer(\n",
    "                    pd.read_parquet, path=parquet_lz4_name, columns=[\"col_2\"]\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd7f3b73-33ce-48e0-a726-caff51c0552a",
   "metadata": {
    "papermill": {
     "duration": 0.048407,
     "end_time": "2025-09-03T21:57:20.305775",
     "exception": false,
     "start_time": "2025-09-03T21:57:20.257368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataframe_shape (rows, cols)</th>\n",
       "      <th>csv_write_time (secs) mean</th>\n",
       "      <th>csv_size (bytes) mean</th>\n",
       "      <th>csv_read_time_all (secs) mean</th>\n",
       "      <th>csv_read_time_one (secs) mean</th>\n",
       "      <th>sqlite_write_time (secs) mean</th>\n",
       "      <th>sqlite_size (bytes) mean</th>\n",
       "      <th>sqlite_read_time_all (secs) mean</th>\n",
       "      <th>sqlite_read_time_one (secs) mean</th>\n",
       "      <th>anndata_h5ad_noc_write_time (secs) mean</th>\n",
       "      <th>...</th>\n",
       "      <th>parquet_gzip_read_time_all (secs) max</th>\n",
       "      <th>parquet_gzip_read_time_one (secs) max</th>\n",
       "      <th>parquet_zstd_write_time (secs) max</th>\n",
       "      <th>parquet_zstd_size (bytes) max</th>\n",
       "      <th>parquet_zstd_read_time_all (secs) max</th>\n",
       "      <th>parquet_zstd_read_time_one (secs) max</th>\n",
       "      <th>parquet_lz4_write_time (secs) max</th>\n",
       "      <th>parquet_lz4_size (bytes) max</th>\n",
       "      <th>parquet_lz4_read_time_all (secs) max</th>\n",
       "      <th>parquet_lz4_read_time_one (secs) max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(640, 258)</td>\n",
       "      <td>0.378440</td>\n",
       "      <td>1396284.0</td>\n",
       "      <td>0.022433</td>\n",
       "      <td>0.014072</td>\n",
       "      <td>0.069512</td>\n",
       "      <td>2654208.0</td>\n",
       "      <td>0.021406</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.010986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028125</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>0.028946</td>\n",
       "      <td>1544136</td>\n",
       "      <td>0.016057</td>\n",
       "      <td>0.002813</td>\n",
       "      <td>0.015310</td>\n",
       "      <td>1614683</td>\n",
       "      <td>0.019062</td>\n",
       "      <td>0.002812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1280, 506)</td>\n",
       "      <td>1.586119</td>\n",
       "      <td>5570451.0</td>\n",
       "      <td>0.073888</td>\n",
       "      <td>0.052563</td>\n",
       "      <td>0.240828</td>\n",
       "      <td>5935104.0</td>\n",
       "      <td>0.354822</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>0.012326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051263</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>0.054853</td>\n",
       "      <td>5940887</td>\n",
       "      <td>0.023910</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>0.036969</td>\n",
       "      <td>6254022</td>\n",
       "      <td>0.028063</td>\n",
       "      <td>0.005103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataframe_shape (rows, cols)  csv_write_time (secs) mean  \\\n",
       "0                   (640, 258)                    0.378440   \n",
       "1                  (1280, 506)                    1.586119   \n",
       "\n",
       "   csv_size (bytes) mean  csv_read_time_all (secs) mean  \\\n",
       "0              1396284.0                       0.022433   \n",
       "1              5570451.0                       0.073888   \n",
       "\n",
       "   csv_read_time_one (secs) mean  sqlite_write_time (secs) mean  \\\n",
       "0                       0.014072                       0.069512   \n",
       "1                       0.052563                       0.240828   \n",
       "\n",
       "   sqlite_size (bytes) mean  sqlite_read_time_all (secs) mean  \\\n",
       "0                 2654208.0                          0.021406   \n",
       "1                 5935104.0                          0.354822   \n",
       "\n",
       "   sqlite_read_time_one (secs) mean  anndata_h5ad_noc_write_time (secs) mean  \\\n",
       "0                          0.002188                                 0.010986   \n",
       "1                          0.004943                                 0.012326   \n",
       "\n",
       "   ...  parquet_gzip_read_time_all (secs) max  \\\n",
       "0  ...                               0.028125   \n",
       "1  ...                               0.051263   \n",
       "\n",
       "   parquet_gzip_read_time_one (secs) max  parquet_zstd_write_time (secs) max  \\\n",
       "0                               0.003096                            0.028946   \n",
       "1                               0.005441                            0.054853   \n",
       "\n",
       "   parquet_zstd_size (bytes) max  parquet_zstd_read_time_all (secs) max  \\\n",
       "0                        1544136                               0.016057   \n",
       "1                        5940887                               0.023910   \n",
       "\n",
       "   parquet_zstd_read_time_one (secs) max  parquet_lz4_write_time (secs) max  \\\n",
       "0                               0.002813                           0.015310   \n",
       "1                               0.004972                           0.036969   \n",
       "\n",
       "   parquet_lz4_size (bytes) max  parquet_lz4_read_time_all (secs) max  \\\n",
       "0                       1614683                              0.019062   \n",
       "1                       6254022                              0.028063   \n",
       "\n",
       "   parquet_lz4_read_time_one (secs) max  \n",
       "0                              0.002812  \n",
       "1                              0.005103  \n",
       "\n",
       "[2 rows x 145 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average = (\n",
    "    df_results.groupby(\"dataframe_shape (rows, cols)\")\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .sort_values(by=\"csv_size (bytes)\")\n",
    ")\n",
    "minimums = (\n",
    "    df_results.groupby(\"dataframe_shape (rows, cols)\")\n",
    "    .min()\n",
    "    .reset_index()\n",
    "    .sort_values(by=\"csv_size (bytes)\")\n",
    ")\n",
    "maximums = (\n",
    "    df_results.groupby(\"dataframe_shape (rows, cols)\")\n",
    "    .max()\n",
    "    .reset_index()\n",
    "    .sort_values(by=\"csv_size (bytes)\")\n",
    ")\n",
    "\n",
    "key = \"dataframe_shape (rows, cols)\"\n",
    "\n",
    "result = (\n",
    "    average.set_index(key)\n",
    "    .add_suffix(\" mean\")\n",
    "    .join(minimums.set_index(key).add_suffix(\" min\"))\n",
    "    .join(maximums.set_index(key).add_suffix(\" max\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b205495-4c5f-4811-a7f3-0dfe4d933b14",
   "metadata": {
    "papermill": {
     "duration": 1.365292,
     "end_time": "2025-09-03T21:57:21.680374",
     "exception": false,
     "start_time": "2025-09-03T21:57:20.315082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/parquet-comparisons-file-write-time.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = \"dataframe_shape (rows, cols)\"\n",
    "\n",
    "cols = {\n",
    "    \"CSV (GZIP)\": (\n",
    "        \"csv_write_time (secs) mean\",\n",
    "        \"csv_write_time (secs) min\",\n",
    "        \"csv_write_time (secs) max\",\n",
    "    ),\n",
    "    \"SQLite\": (\n",
    "        \"sqlite_write_time (secs) mean\",\n",
    "        \"sqlite_write_time (secs) min\",\n",
    "        \"sqlite_write_time (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - uncompressed)\": (\n",
    "        \"anndata_h5ad_noc_write_time (secs) mean\",\n",
    "        \"anndata_h5ad_noc_write_time (secs) min\",\n",
    "        \"anndata_h5ad_noc_write_time (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - GZIP)\": (\n",
    "        \"anndata_h5ad_gzip_write_time (secs) mean\",\n",
    "        \"anndata_h5ad_gzip_write_time (secs) min\",\n",
    "        \"anndata_h5ad_gzip_write_time (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - ZSTD)\": (\n",
    "        \"anndata_h5ad_zstd_write_time (secs) mean\",\n",
    "        \"anndata_h5ad_zstd_write_time (secs) min\",\n",
    "        \"anndata_h5ad_zstd_write_time (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - LZ4) (\": (\n",
    "        \"anndata_h5ad_lz4_write_time (secs) mean\",\n",
    "        \"anndata_h5ad_lz4_write_time (secs) min\",\n",
    "        \"anndata_h5ad_lz4_write_time (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (Zarr)\": (\n",
    "        \"anndata_zarr_write_time (secs) mean\",\n",
    "        \"anndata_zarr_write_time (secs) min\",\n",
    "        \"anndata_zarr_write_time (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (uncompressed)\": (\n",
    "        \"parquet_noc_write_time (secs) mean\",\n",
    "        \"parquet_noc_write_time (secs) min\",\n",
    "        \"parquet_noc_write_time (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (Snappy)\": (\n",
    "        \"parquet_snappy_write_time (secs) mean\",\n",
    "        \"parquet_snappy_write_time (secs) min\",\n",
    "        \"parquet_snappy_write_time (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (GZIP)\": (\n",
    "        \"parquet_gzip_write_time (secs) mean\",\n",
    "        \"parquet_gzip_write_time (secs) min\",\n",
    "        \"parquet_gzip_write_time (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (ZSTD)\": (\n",
    "        \"parquet_zstd_write_time (secs) mean\",\n",
    "        \"parquet_zstd_write_time (secs) min\",\n",
    "        \"parquet_zstd_write_time (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (LZ4)\": (\n",
    "        \"parquet_lz4_write_time (secs) mean\",\n",
    "        \"parquet_lz4_write_time (secs) min\",\n",
    "        \"parquet_lz4_write_time (secs) max\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "parts = []\n",
    "for fmt, (mcol, mincol, maxcol) in cols.items():\n",
    "    tmp = result[[key, mcol, mincol, maxcol]].copy()\n",
    "    tmp[\"format\"] = fmt\n",
    "    tmp.rename(columns={mcol: \"mean\", mincol: \"min\", maxcol: \"max\"}, inplace=True)\n",
    "    tmp[\"err_plus\"] = tmp[\"max\"] - tmp[\"mean\"]\n",
    "    tmp[\"err_minus\"] = tmp[\"mean\"] - tmp[\"min\"]\n",
    "    parts.append(tmp[[key, \"format\", \"mean\", \"err_plus\", \"err_minus\"]])\n",
    "\n",
    "\n",
    "stats = pd.concat(parts, ignore_index=True)\n",
    "\n",
    "x_order = result[key].tolist()  # not reversed; use iloc[::-1] to reverse\n",
    "pos = {k: i for i, k in enumerate(x_order)}  # category â†’ position index\n",
    "\n",
    "# 2) give each row its x position and sort per-trace\n",
    "stats = stats.assign(xpos=stats[key].map(pos)).sort_values([\"format\", \"xpos\"])\n",
    "\n",
    "fig = px.line(\n",
    "    stats,  # already trace-sorted by xpos\n",
    "    x=key,\n",
    "    y=\"mean\",\n",
    "    color=\"format\",\n",
    "    error_y=\"err_plus\",\n",
    "    error_y_minus=\"err_minus\",\n",
    "    markers=True,\n",
    "    category_orders={key: x_order},  # sets axis order & legend hover categories\n",
    "    labels={key: \"Data Shape\", \"mean\": \"Seconds (log)\"},\n",
    "    width=1300,\n",
    "    log_y=True,\n",
    "    title=\"File format write time duration (seconds)\"\n",
    ")\n",
    "fig.update_traces(mode=\"lines+markers\")\n",
    "fig.update_traces(marker_color=None, line_color=None).update_layout(\n",
    "    colorway=px.colors.qualitative.Dark24\n",
    ")\n",
    "fig.update_layout(legend_title_text=\"Format\")\n",
    "\n",
    "\n",
    "pio.write_image(fig, file_write_time_image)\n",
    "Image(url=file_write_time_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4827e5d-b2e4-4b8c-bff8-db96e0b76949",
   "metadata": {
    "papermill": {
     "duration": 0.313924,
     "end_time": "2025-09-03T21:57:22.005171",
     "exception": false,
     "start_time": "2025-09-03T21:57:21.691247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/parquet-comparisons-file-storage-size.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = \"dataframe_shape (rows, cols)\"\n",
    "\n",
    "size_cols = {\n",
    "    \"csv_size (bytes)\": \"CSV (GZIP)\",\n",
    "    \"sqlite_size (bytes)\": \"SQLite\",\n",
    "    \"anndata_h5ad_noc_size (bytes)\": \"AnnData (H5AD - uncompressed)\",\n",
    "    \"anndata_h5ad_gzip_size (bytes)\": \"AnnData (H5AD - GZIP)\",\n",
    "    \"anndata_h5ad_lz4_size (bytes)\": \"AnnData (H5AD - LZ4)\",\n",
    "    \"anndata_h5ad_zstd_size (bytes)\": \"AnnData (H5AD - ZSTD)\",\n",
    "    \"anndata_zarr_size (bytes)\": \"AnnData (Zarr)\",\n",
    "    \"parquet_noc_size (bytes)\": \"Parquet (uncompressed)\",\n",
    "    \"parquet_snappy_size (bytes)\": \"Parquet (Snappy)\",\n",
    "    \"parquet_gzip_size (bytes)\": \"Parquet (GZIP)\",\n",
    "    \"parquet_zstd_size (bytes)\": \"Parquet (ZSTD)\",\n",
    "    \"parquet_lz4_size (bytes)\": \"Parquet (LZ4)\",\n",
    "}\n",
    "\n",
    "# Long-form + average across repeats\n",
    "long = df_results.melt(\n",
    "    id_vars=[key],\n",
    "    value_vars=list(size_cols.keys()),\n",
    "    var_name=\"col\",\n",
    "    value_name=\"bytes\",\n",
    ").dropna(subset=[\"bytes\"])\n",
    "long[\"format\"] = long[\"col\"].map(size_cols)\n",
    "\n",
    "stats = long.groupby([key, \"format\"], as_index=False)[\"bytes\"].mean()\n",
    "\n",
    "# Choose x-axis category order (keep your current result order, reversed here).\n",
    "x_order = result[key].iloc[::-1].tolist()\n",
    "\n",
    "# Ensure each trace's points follow that order (pre-sort rows)\n",
    "pos = {cat: i for i, cat in enumerate(x_order)}\n",
    "stats_sorted = stats.assign(xpos=stats[key].map(pos)).sort_values([\"format\", \"xpos\"])\n",
    "\n",
    "fig = px.line(\n",
    "    stats_sorted,\n",
    "    x=key,\n",
    "    y=\"bytes\",\n",
    "    color=\"format\",\n",
    "    markers=True,\n",
    "    category_orders={key: x_order},\n",
    "    labels={key: \"Data Shape\", \"bytes\": \"Bytes\"},\n",
    "    width=1300,\n",
    "    title=\"File format size (bytes)\"\n",
    ")\n",
    "\n",
    "fig.update_traces(mode=\"lines+markers\")\n",
    "fig.update_xaxes(autorange=\"reversed\")\n",
    "fig.update_traces(marker_color=None, line_color=None).update_layout(\n",
    "    colorway=px.colors.qualitative.Dark24\n",
    ")\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=1.02,\n",
    "        y=1,  # just outside the plotting area\n",
    "        xanchor=\"left\",\n",
    "        yanchor=\"top\",\n",
    "        bgcolor=\"rgba(255,255,255,0.8)\",\n",
    "    ),\n",
    "    margin=dict(r=220),  # add right margin so legend fits\n",
    "    font=dict(size=18),\n",
    ")\n",
    "\n",
    "pio.write_image(fig, file_storage_size_image)\n",
    "Image(url=file_storage_size_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ab638a5-e6e1-47e5-a5f9-56f156a71bc7",
   "metadata": {
    "papermill": {
     "duration": 0.250629,
     "end_time": "2025-09-03T21:57:22.266295",
     "exception": false,
     "start_time": "2025-09-03T21:57:22.015666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/parquet-comparisons-file-read-time-all-columns.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read time barchart (all columns)\n",
    "key = \"dataframe_shape (rows, cols)\"\n",
    "\n",
    "cols = {\n",
    "    \"CSV (GZIP)\": (\n",
    "        \"csv_read_time_all (secs) mean\",\n",
    "        \"csv_read_time_all (secs) min\",\n",
    "        \"csv_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"SQLite\": (\n",
    "        \"sqlite_read_time_all (secs) mean\",\n",
    "        \"sqlite_read_time_all (secs) min\",\n",
    "        \"sqlite_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - uncompressed)\": (\n",
    "        \"anndata_h5ad_noc_read_time_all (secs) mean\",\n",
    "        \"anndata_h5ad_noc_read_time_all (secs) min\",\n",
    "        \"anndata_h5ad_noc_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - GZIP)\": (\n",
    "        \"anndata_h5ad_gzip_read_time_all (secs) mean\",\n",
    "        \"anndata_h5ad_gzip_read_time_all (secs) min\",\n",
    "        \"anndata_h5ad_gzip_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - ZSTD)\": (\n",
    "        \"anndata_h5ad_zstd_read_time_all (secs) mean\",\n",
    "        \"anndata_h5ad_zstd_read_time_all (secs) min\",\n",
    "        \"anndata_h5ad_zstd_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - LZ4) (\": (\n",
    "        \"anndata_h5ad_lz4_read_time_all (secs) mean\",\n",
    "        \"anndata_h5ad_lz4_read_time_all (secs) min\",\n",
    "        \"anndata_h5ad_lz4_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (Zarr)\": (\n",
    "        \"anndata_zarr_read_time_all (secs) mean\",\n",
    "        \"anndata_zarr_read_time_all (secs) min\",\n",
    "        \"anndata_zarr_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (uncompressed)\": (\n",
    "        \"parquet_noc_read_time_all (secs) mean\",\n",
    "        \"parquet_noc_read_time_all (secs) min\",\n",
    "        \"parquet_noc_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (Snappy)\": (\n",
    "        \"parquet_snappy_read_time_all (secs) mean\",\n",
    "        \"parquet_snappy_read_time_all (secs) min\",\n",
    "        \"parquet_snappy_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (GZIP)\": (\n",
    "        \"parquet_gzip_read_time_all (secs) mean\",\n",
    "        \"parquet_gzip_read_time_all (secs) min\",\n",
    "        \"parquet_gzip_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (ZSTD)\": (\n",
    "        \"parquet_zstd_read_time_all (secs) mean\",\n",
    "        \"parquet_zstd_read_time_all (secs) min\",\n",
    "        \"parquet_zstd_read_time_all (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (LZ4)\": (\n",
    "        \"parquet_lz4_read_time_all (secs) mean\",\n",
    "        \"parquet_lz4_read_time_all (secs) min\",\n",
    "        \"parquet_lz4_read_time_all (secs) max\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "parts = []\n",
    "for fmt, (mcol, mincol, maxcol) in cols.items():\n",
    "    tmp = result[[key, mcol, mincol, maxcol]].copy()\n",
    "    tmp[\"format\"] = fmt\n",
    "    tmp.rename(columns={mcol: \"mean\", mincol: \"min\", maxcol: \"max\"}, inplace=True)\n",
    "    tmp[\"err_plus\"] = tmp[\"max\"] - tmp[\"mean\"]\n",
    "    tmp[\"err_minus\"] = tmp[\"mean\"] - tmp[\"min\"]\n",
    "    parts.append(tmp[[key, \"format\", \"mean\", \"err_plus\", \"err_minus\"]])\n",
    "\n",
    "\n",
    "stats = pd.concat(parts, ignore_index=True)\n",
    "\n",
    "x_order = result[key].tolist()  # not reversed; use iloc[::-1] to reverse\n",
    "pos = {k: i for i, k in enumerate(x_order)}  # category â†’ position index\n",
    "\n",
    "# 2) give each row its x position and sort per-trace\n",
    "stats = stats.assign(xpos=stats[key].map(pos)).sort_values([\"format\", \"xpos\"])\n",
    "\n",
    "fig = px.line(\n",
    "    stats,  # already trace-sorted by xpos\n",
    "    x=key,\n",
    "    y=\"mean\",\n",
    "    color=\"format\",\n",
    "    error_y=\"err_plus\",\n",
    "    error_y_minus=\"err_minus\",\n",
    "    markers=True,\n",
    "    category_orders={key: x_order},  # sets axis order & legend hover categories\n",
    "    labels={key: \"Data Shape\", \"mean\": \"Seconds\"},\n",
    "    width=1300,\n",
    "    log_y=True,\n",
    "    title=\"File format read time duration (full dataset) (seconds)\"\n",
    ")\n",
    "fig.update_traces(mode=\"lines+markers\")\n",
    "fig.update_traces(marker_color=None, line_color=None).update_layout(\n",
    "    colorway=px.colors.qualitative.Dark24\n",
    ")\n",
    "fig.update_layout(legend_title_text=\"Format\")\n",
    "\n",
    "\n",
    "pio.write_image(fig, file_read_time_all_image)\n",
    "Image(url=file_read_time_all_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd99f232-8564-4b83-82c7-e4b0cc5cfbf4",
   "metadata": {
    "papermill": {
     "duration": 0.260285,
     "end_time": "2025-09-03T21:57:22.537386",
     "exception": false,
     "start_time": "2025-09-03T21:57:22.277101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/parquet-comparisons-file-read-time-one-column.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read time barchart (one column)\n",
    "\n",
    "key = \"dataframe_shape (rows, cols)\"\n",
    "\n",
    "cols = {\n",
    "    \"CSV (GZIP)\": (\n",
    "        \"csv_read_time_one (secs) mean\",\n",
    "        \"csv_read_time_one (secs) min\",\n",
    "        \"csv_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"SQLite\": (\n",
    "        \"sqlite_read_time_one (secs) mean\",\n",
    "        \"sqlite_read_time_one (secs) min\",\n",
    "        \"sqlite_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - uncompressed)\": (\n",
    "        \"anndata_h5ad_noc_read_time_one (secs) mean\",\n",
    "        \"anndata_h5ad_noc_read_time_one (secs) min\",\n",
    "        \"anndata_h5ad_noc_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - GZIP)\": (\n",
    "        \"anndata_h5ad_gzip_read_time_one (secs) mean\",\n",
    "        \"anndata_h5ad_gzip_read_time_one (secs) min\",\n",
    "        \"anndata_h5ad_gzip_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - ZSTD)\": (\n",
    "        \"anndata_h5ad_zstd_read_time_one (secs) mean\",\n",
    "        \"anndata_h5ad_zstd_read_time_one (secs) min\",\n",
    "        \"anndata_h5ad_zstd_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (H5AD - LZ4) (\": (\n",
    "        \"anndata_h5ad_lz4_read_time_one (secs) mean\",\n",
    "        \"anndata_h5ad_lz4_read_time_one (secs) min\",\n",
    "        \"anndata_h5ad_lz4_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"AnnData (Zarr)\": (\n",
    "        \"anndata_zarr_read_time_one (secs) mean\",\n",
    "        \"anndata_zarr_read_time_one (secs) min\",\n",
    "        \"anndata_zarr_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (uncompressed)\": (\n",
    "        \"parquet_noc_read_time_one (secs) mean\",\n",
    "        \"parquet_noc_read_time_one (secs) min\",\n",
    "        \"parquet_noc_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (Snappy)\": (\n",
    "        \"parquet_snappy_read_time_one (secs) mean\",\n",
    "        \"parquet_snappy_read_time_one (secs) min\",\n",
    "        \"parquet_snappy_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (GZIP)\": (\n",
    "        \"parquet_gzip_read_time_one (secs) mean\",\n",
    "        \"parquet_gzip_read_time_one (secs) min\",\n",
    "        \"parquet_gzip_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (ZSTD)\": (\n",
    "        \"parquet_zstd_read_time_one (secs) mean\",\n",
    "        \"parquet_zstd_read_time_one (secs) min\",\n",
    "        \"parquet_zstd_read_time_one (secs) max\",\n",
    "    ),\n",
    "    \"Parquet (LZ4)\": (\n",
    "        \"parquet_lz4_read_time_one (secs) mean\",\n",
    "        \"parquet_lz4_read_time_one (secs) min\",\n",
    "        \"parquet_lz4_read_time_one (secs) max\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "parts = []\n",
    "for fmt, (mcol, mincol, maxcol) in cols.items():\n",
    "    tmp = result[[key, mcol, mincol, maxcol]].copy()\n",
    "    tmp[\"format\"] = fmt\n",
    "    tmp.rename(columns={mcol: \"mean\", mincol: \"min\", maxcol: \"max\"}, inplace=True)\n",
    "    tmp[\"err_plus\"] = tmp[\"max\"] - tmp[\"mean\"]\n",
    "    tmp[\"err_minus\"] = tmp[\"mean\"] - tmp[\"min\"]\n",
    "    parts.append(tmp[[key, \"format\", \"mean\", \"err_plus\", \"err_minus\"]])\n",
    "\n",
    "\n",
    "stats = pd.concat(parts, ignore_index=True)\n",
    "\n",
    "x_order = result[key].tolist()  # not reversed; use iloc[::-1] to reverse\n",
    "pos = {k: i for i, k in enumerate(x_order)}  # category â†’ position index\n",
    "\n",
    "# 2) give each row its x position and sort per-trace\n",
    "stats = stats.assign(xpos=stats[key].map(pos)).sort_values([\"format\", \"xpos\"])\n",
    "\n",
    "fig = px.line(\n",
    "    stats,  # already trace-sorted by xpos\n",
    "    x=key,\n",
    "    y=\"mean\",\n",
    "    color=\"format\",\n",
    "    error_y=\"err_plus\",\n",
    "    error_y_minus=\"err_minus\",\n",
    "    markers=True,\n",
    "    category_orders={key: x_order},  # sets axis order & legend hover categories\n",
    "    labels={key: \"Data Shape\", \"mean\": \"Seconds (log)\"},\n",
    "    width=1300,\n",
    "    log_y=True,\n",
    "    title=\"File format read time duration (one column) (seconds)\"\n",
    ")\n",
    "fig.update_traces(mode=\"lines+markers\")\n",
    "fig.update_traces(marker_color=None, line_color=None).update_layout(\n",
    "    colorway=px.colors.qualitative.Dark24\n",
    ")\n",
    "fig.update_layout(legend_title_text=\"Format\")\n",
    "\n",
    "\n",
    "pio.write_image(fig, file_read_time_one_image)\n",
    "Image(url=file_read_time_one_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cc933c-aaf1-49c1-8a6a-2242680f3bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 134.268328,
   "end_time": "2025-09-03T21:57:25.270281",
   "environment_variables": {},
   "exception": null,
   "input_path": "parquet_analysis.ipynb",
   "output_path": "parquet_analysis.ipynb",
   "parameters": {},
   "start_time": "2025-09-03T21:55:11.001953",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

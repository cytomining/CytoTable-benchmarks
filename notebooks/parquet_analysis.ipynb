{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "529f5590-609a-4554-9254-e22e8a4822ad",
   "metadata": {},
   "source": [
    "# Why parquet?\n",
    "\n",
    "This notebook explores the benefits or drawbacks of using the [parquet](https://parquet.apache.org/docs/) file format relative to other formats such as CSV or SQLite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "599a34fd-d468-40ce-aafa-671debbe9ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set ipyflow reactive mode\n",
    "%flow mode reactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2ac8b5f-d7b1-43aa-9589-19890914f646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from IPython.display import Image\n",
    "from utilities import timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d7ac6d-3ffa-4a57-99ba-a0214c4e2753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target file or table names\n",
    "image_dir = \"images\"\n",
    "csv_name = \"example.csv.gz\"\n",
    "parquet_name = \"example.parquet\"\n",
    "sqlite_name = \"example.sqlite\"\n",
    "sqlite_tbl_name = \"tbl_example\"\n",
    "file_write_time_image = f\"{image_dir}/file-write-time.png\"\n",
    "file_storage_size_image = f\"{image_dir}/file-storage-size.png\"\n",
    "file_read_time_all_image = f\"{image_dir}/file-read-time-all.png\"\n",
    "file_read_time_one_image = f\"{image_dir}/file-read-time-one.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2bada16-8022-4125-8083-c937e76d914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any existing prior work\n",
    "for filename in [csv_name, parquet_name, sqlite_name]:\n",
    "    pathlib.Path(filename).unlink(missing_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f9eefe2-8379-490c-9977-807b781eb168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataframe_shape (rows, cols)</th>\n",
       "      <th>csv_write_time (secs)</th>\n",
       "      <th>csv_size (bytes)</th>\n",
       "      <th>csv_read_time_all (secs)</th>\n",
       "      <th>csv_read_time_one (secs)</th>\n",
       "      <th>sqlite_write_time (secs)</th>\n",
       "      <th>sqlite_size (bytes)</th>\n",
       "      <th>sqlite_read_time_all (secs)</th>\n",
       "      <th>sqlite_read_time_one (secs)</th>\n",
       "      <th>parquet_write_time (secs)</th>\n",
       "      <th>parquet_size (bytes)</th>\n",
       "      <th>parquet_read_time_all (secs)</th>\n",
       "      <th>parquet_read_time_one (secs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(640, 320)</td>\n",
       "      <td>0.829287</td>\n",
       "      <td>1796557</td>\n",
       "      <td>0.108058</td>\n",
       "      <td>0.038471</td>\n",
       "      <td>0.872131</td>\n",
       "      <td>2654208</td>\n",
       "      <td>0.139296</td>\n",
       "      <td>0.005604</td>\n",
       "      <td>0.184945</td>\n",
       "      <td>2030927</td>\n",
       "      <td>0.038084</td>\n",
       "      <td>0.016967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1280, 640)</td>\n",
       "      <td>3.260699</td>\n",
       "      <td>7176649</td>\n",
       "      <td>0.341500</td>\n",
       "      <td>0.145129</td>\n",
       "      <td>1.356749</td>\n",
       "      <td>7909376</td>\n",
       "      <td>0.390404</td>\n",
       "      <td>0.006548</td>\n",
       "      <td>0.378361</td>\n",
       "      <td>7756592</td>\n",
       "      <td>0.064453</td>\n",
       "      <td>0.028462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(2560, 1280)</td>\n",
       "      <td>13.237497</td>\n",
       "      <td>28693764</td>\n",
       "      <td>0.664492</td>\n",
       "      <td>0.499940</td>\n",
       "      <td>2.298451</td>\n",
       "      <td>31543296</td>\n",
       "      <td>1.275583</td>\n",
       "      <td>0.008664</td>\n",
       "      <td>0.806497</td>\n",
       "      <td>30402800</td>\n",
       "      <td>0.123527</td>\n",
       "      <td>0.046285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataframe_shape (rows, cols)  csv_write_time (secs)  csv_size (bytes)  \\\n",
       "0                   (640, 320)               0.829287           1796557   \n",
       "1                  (1280, 640)               3.260699           7176649   \n",
       "2                 (2560, 1280)              13.237497          28693764   \n",
       "\n",
       "   csv_read_time_all (secs)  csv_read_time_one (secs)  \\\n",
       "0                  0.108058                  0.038471   \n",
       "1                  0.341500                  0.145129   \n",
       "2                  0.664492                  0.499940   \n",
       "\n",
       "   sqlite_write_time (secs)  sqlite_size (bytes)  sqlite_read_time_all (secs)  \\\n",
       "0                  0.872131              2654208                     0.139296   \n",
       "1                  1.356749              7909376                     0.390404   \n",
       "2                  2.298451             31543296                     1.275583   \n",
       "\n",
       "   sqlite_read_time_one (secs)  parquet_write_time (secs)  \\\n",
       "0                     0.005604                   0.184945   \n",
       "1                     0.006548                   0.378361   \n",
       "2                     0.008664                   0.806497   \n",
       "\n",
       "   parquet_size (bytes)  parquet_read_time_all (secs)  \\\n",
       "0               2030927                      0.038084   \n",
       "1               7756592                      0.064453   \n",
       "2              30402800                      0.123527   \n",
       "\n",
       "   parquet_read_time_one (secs)  \n",
       "0                      0.016967  \n",
       "1                      0.028462  \n",
       "2                      0.046285  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# starting rowcount and col count\n",
    "nrows = 320\n",
    "ncols = 160\n",
    "\n",
    "# result list for storing data\n",
    "results = []\n",
    "\n",
    "# loop for iterating over increasingly large dataframes\n",
    "# and gathering data about operations on them\n",
    "for _ in range(1, 4):\n",
    "    # increase the size of the dataframe\n",
    "    nrows *= 2\n",
    "    ncols *= 2\n",
    "\n",
    "    # form a dataframe using randomized data\n",
    "    df = pd.DataFrame(\n",
    "        np.random.rand(nrows, ncols), columns=[f\"col_{num}\" for num in range(0, ncols)]\n",
    "    )\n",
    "\n",
    "    # append data to the result list\n",
    "    results.append(\n",
    "        {\n",
    "            # general information about the dataframe\n",
    "            \"dataframe_shape (rows, cols)\": str(df.shape),\n",
    "            # information about CSV\n",
    "            \"csv_write_time (secs)\": timer(\n",
    "                df.to_csv, path_or_buf=csv_name, compression=\"gzip\"\n",
    "            ),\n",
    "            \"csv_size (bytes)\": os.stat(csv_name).st_size,\n",
    "            \"csv_read_time_all (secs)\": timer(\n",
    "                pd.read_csv, filepath_or_buffer=csv_name, compression=\"gzip\"\n",
    "            ),\n",
    "            \"csv_read_time_one (secs)\": timer(\n",
    "                pd.read_csv,\n",
    "                filepath_or_buffer=csv_name,\n",
    "                compression=\"gzip\",\n",
    "                usecols=[\"col_2\"],\n",
    "            ),\n",
    "            # information about SQLite\n",
    "            \"sqlite_write_time (secs)\": timer(\n",
    "                df.to_sql,\n",
    "                name=sqlite_tbl_name,\n",
    "                con=f\"sqlite:///{sqlite_name}\",\n",
    "            ),\n",
    "            \"sqlite_size (bytes)\": os.stat(sqlite_name).st_size,\n",
    "            \"sqlite_read_time_all (secs)\": timer(\n",
    "                pd.read_sql,\n",
    "                sql=f\"SELECT * FROM {sqlite_tbl_name}\",\n",
    "                con=f\"sqlite:///{sqlite_name}\",\n",
    "            ),\n",
    "            \"sqlite_read_time_one (secs)\": timer(\n",
    "                pd.read_sql,\n",
    "                sql=f\"SELECT col_2 FROM {sqlite_tbl_name}\",\n",
    "                con=f\"sqlite:///{sqlite_name}\",\n",
    "            ),\n",
    "            # information about Parquet\n",
    "            \"parquet_write_time (secs)\": timer(\n",
    "                df.to_parquet, path=parquet_name, compression=\"gzip\"\n",
    "            ),\n",
    "            \"parquet_size (bytes)\": os.stat(parquet_name).st_size,\n",
    "            \"parquet_read_time_all (secs)\": timer(pd.read_parquet, path=parquet_name),\n",
    "            \"parquet_read_time_one (secs)\": timer(\n",
    "                pd.read_parquet, path=parquet_name, columns=[\"col_2\"]\n",
    "            ),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # remove any existing files in preparation for next steps\n",
    "    for filename in [csv_name, parquet_name, sqlite_name]:\n",
    "        pathlib.Path(filename).unlink(missing_ok=True)\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a735ec26-02d4-42a4-9756-4cee2f33e69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/file-write-time.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write times barchart\n",
    "fig = px.bar(\n",
    "    df_results,\n",
    "    x=[\n",
    "        \"csv_write_time (secs)\",\n",
    "        \"sqlite_write_time (secs)\",\n",
    "        \"parquet_write_time (secs)\",\n",
    "    ],\n",
    "    y=\"dataframe_shape (rows, cols)\",\n",
    "    orientation=\"h\",\n",
    "    barmode=\"group\",\n",
    "    labels={\"dataframe_shape (rows, cols)\": \"Data Shape\", \"value\": \"Seconds\"},\n",
    "    width=1300,\n",
    "    color_discrete_sequence=px.colors.qualitative.D3,\n",
    ")\n",
    "fig.update_layout(\n",
    "    legend=dict(x=0.68, y=0.02, bgcolor=\"rgba(255,255,255,0.8)\"),\n",
    "    font=dict(\n",
    "        size=20,  # global font size\n",
    "    ),\n",
    ")\n",
    "\n",
    "pio.write_image(fig, file_write_time_image)\n",
    "Image(url=file_write_time_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4827e5d-b2e4-4b8c-bff8-db96e0b76949",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/file-storage-size.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filesize barchart\n",
    "fig = px.bar(\n",
    "    df_results,\n",
    "    x=[\n",
    "        \"csv_size (bytes)\",\n",
    "        \"sqlite_size (bytes)\",\n",
    "        \"parquet_size (bytes)\",\n",
    "    ],\n",
    "    y=\"dataframe_shape (rows, cols)\",\n",
    "    orientation=\"h\",\n",
    "    barmode=\"group\",\n",
    "    labels={\"dataframe_shape (rows, cols)\": \"Data Shape\", \"value\": \"Bytes\"},\n",
    "    width=1300,\n",
    "    color_discrete_sequence=px.colors.qualitative.D3,\n",
    ")\n",
    "fig.update_layout(\n",
    "    legend=dict(x=0.72, y=0.02, bgcolor=\"rgba(255,255,255,0.8)\"),\n",
    "    font=dict(\n",
    "        size=20,  # global font size\n",
    "    ),\n",
    ")\n",
    "\n",
    "pio.write_image(fig, file_storage_size_image)\n",
    "Image(url=file_storage_size_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ab638a5-e6e1-47e5-a5f9-56f156a71bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/file-read-time-all.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read time barchart (all columns)\n",
    "fig = px.line(\n",
    "    df_results,\n",
    "    y=[\n",
    "        \"csv_read_time_all (secs)\",\n",
    "        \"sqlite_read_time_all (secs)\",\n",
    "        \"parquet_read_time_all (secs)\",\n",
    "    ],\n",
    "    x=\"dataframe_shape (rows, cols)\",\n",
    "    labels={\"dataframe_shape (rows, cols)\": \"Data Shape\", \"value\": \"Seconds\"},\n",
    "    width=1300,\n",
    "    color_discrete_sequence=px.colors.qualitative.D3,\n",
    ")\n",
    "fig.update_layout(\n",
    "    legend=dict(x=0.01, y=0.98, bgcolor=\"rgba(255,255,255,0.8)\"),\n",
    "    font=dict(\n",
    "        size=20,  # global font size\n",
    "    ),\n",
    ")\n",
    "fig.update_xaxes(range=[0, 2.13])\n",
    "fig.update_traces(mode=\"lines+markers\")\n",
    "\n",
    "pio.write_image(fig, file_read_time_all_image)\n",
    "Image(url=file_read_time_all_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd99f232-8564-4b83-82c7-e4b0cc5cfbf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"images/file-read-time-one.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read time barchart (one column)\n",
    "fig = px.bar(\n",
    "    df_results,\n",
    "    x=[\n",
    "        \"csv_read_time_one (secs)\",\n",
    "        \"sqlite_read_time_one (secs)\",\n",
    "        \"parquet_read_time_one (secs)\",\n",
    "    ],\n",
    "    y=\"dataframe_shape (rows, cols)\",\n",
    "    orientation=\"h\",\n",
    "    barmode=\"group\",\n",
    "    labels={\"dataframe_shape (rows, cols)\": \"Data Shape\", \"value\": \"Seconds\"},\n",
    "    width=1300,\n",
    "    color_discrete_sequence=px.colors.qualitative.D3,\n",
    ")\n",
    "fig.update_layout(\n",
    "    legend=dict(x=0.65, y=0.02, bgcolor=\"rgba(255,255,255,0.8)\"),\n",
    "    font=dict(\n",
    "        size=20,  # global font size\n",
    "    ),\n",
    ")\n",
    "\n",
    "pio.write_image(fig, file_read_time_one_image)\n",
    "Image(url=file_read_time_one_image)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipyflow)",
   "language": "python",
   "name": "ipyflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
